-DOCSTART- -X- O
leam -X- _ B-MethodName
uses -X- _ O
much -X- _ O
less -X- _ O
model -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
converges -X- _ O
signiÔ¨Åcantlymodel -X- _ O
# -X- _ O
parameters -X- _ O
time -X- _ O
cost -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
cnn -X- _ O
541k -X- _ O
171 -X- _ O
lstm -X- _ O
1.8 -X- _ O
m -X- _ O
598 -X- _ O
swem -X- _ O
61 -X- _ O
k -X- _ O
63 -X- _ O
bi -X- _ O
- -X- _ O
blosan -X- _ O
3.6 -X- _ O
m -X- _ O
292 -X- _ O
leam -X- _ O
65 -X- _ O
k -X- _ O
65 -X- _ O
table -X- _ O
4 -X- _ O
: -X- _ O
comparison -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
and -X- _ O
speed -X- _ O
. -X- _ O

2014 -X- _ O
) -X- _ O
is -X- _ O
employed -X- _ O
on -X- _ O
the -X- _ O
Ô¨Ånal -X- _ O
mlp -X- _ O
layer -X- _ O
, -X- _ O
with -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0:5 -X- _ B-HyperparameterValue
. -X- _ O

we -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
‚Äôs -X- _ O
parameters -X- _ O
with -X- _ O
the -X- _ O
adam -X- _ O
optimizer -X- _ O
( -X- _ O
kingma -X- _ O
and -X- _ O
ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
ini- -X- _ B-HyperparameterName
tial -X- _ I-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0:001 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
a -X- _ O
minibatch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
100 -X- _ B-HyperparameterValue
. -X- _ O

for -X- _ O
the -X- _ O
datasets -X- _ O
without -X- _ O
representative -X- _ O
class -X- _ O
descriptions -X- _ O
, -X- _ O
one -X- _ O
may -X- _ O
initialize -X- _ O
the -X- _ O
label -X- _ O
embed- -X- _ O
dings -X- _ O
as -X- _ O
random -X- _ O
samples -X- _ O
drawn -X- _ O
from -X- _ O
a -X- _ O
standard -X- _ O
gaussian -X- _ O
distribution -X- _ O
. -X- _ O

speciÔ¨Åcally -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
text -X- _ O
em- -X- _ O
bedding -X- _ O
in -X- _ O
pte -X- _ O
is -X- _ O
similar -X- _ O
with -X- _ O
a -X- _ O
very -X- _ O
special -X- _ O
case -X- _ O
of -X- _ O
leam -X- _ O
, -X- _ O
when -X- _ O
our -X- _ O
window -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
r= -X- _ O
1 -X- _ B-HyperparameterValue
and -X- _ O
at- -X- _ O
tention -X- _ O
score -X- _ O
is -X- _ O
uniform -X- _ O
. -X- _ O

we -X- _ O
also -X- _ O
compute -X- _ O
a -X- _ O
pair -X- _ O
wise -X- _ O
cohen -X- _ B-MetricName
‚Äôs -X- _ I-MetricName
value -X- _ I-MetricName
of -X- _ O
0.97 -X- _ B-MetricValue
. -X- _ O

we -X- _ O
have -X- _ O
achieved -X- _ O
a -X- _ O
pearson -X- _ B-MetricName
‚Äôs -X- _ I-MetricName
and -X- _ O
spearman -X- _ B-MetricName
‚Äôs -X- _ I-MetricName
correlation -X- _ I-MetricName
of -X- _ O
0.94 -X- _ B-MetricValue
and -X- _ O
0.97 -X- _ B-MetricValue
respectively -X- _ O
as -X- _ O
com- -X- _ O
pared -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
0.91 -X- _ B-MetricValue
and -X- _ O
0.96 -X- _ B-MetricValue
in -X- _ O
( -X- _ O
alikaniotis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
found -X- _ O
that -X- _ O
that -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
all -X- _ O
these -X- _ O
parameters -X- _ O
our -X- _ O
system -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
existing -X- _ O
, -X- _ O
lstm -X- _ B-MethodName
, -X- _ O
bi -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
and -X- _ O
ease -X- _ O
mod- -X- _ O
els -X- _ O
. -X- _ O

on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
also -X- _ O
used -X- _ O
evalua- -X- _ O
tion -X- _ O
matrices -X- _ O
like -X- _ O
, -X- _ O
pearson -X- _ B-MetricName
‚Äôs -X- _ I-MetricName
correlation -X- _ I-MetricName
r -X- _ O
, -X- _ O
spear- -X- _ B-MetricName
man -X- _ I-MetricName
‚Äôs -X- _ I-MetricName
ranking -X- _ I-MetricName
correlation -X- _ I-MetricName
 -X- _ O
, -X- _ O
rmse -X- _ B-MetricName
scores -X- _ O
in -X- _ O
or- -X- _ O
der -X- _ O
to -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
systems -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
alikaniotis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

it -X- _ O
is -X- _ O
worth -X- _ O
mentioning -X- _ O
here -X- _ O
that -X- _ O
all -X- _ O
these -X- _ O
mod- -X- _ O
els -X- _ O
are -X- _ O
compared -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
qwk -X- _ B-MetricName
score -X- _ I-MetricName
. -X- _ O

for -X- _ O
ex- -X- _ O
ample -X- _ O
, -X- _ O
in -X- _ O
prompt -X- _ O
3 -X- _ O
, -X- _ O
6 -X- _ O
and -X- _ O
7 -X- _ O
we -X- _ O
have -X- _ O
achieved -X- _ O
an -X- _ O
qwk -X- _ B-MetricName
of -X- _ O
0.712 -X- _ B-MetricValue
, -X- _ O
0.831 -X- _ B-MetricValue
and -X- _ O
0.815 -X- _ B-MetricValue
respectively -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
reported -X- _ O
average -X- _ B-MetricName
qwk -X- _ I-MetricName
score -X- _ I-MetricName
of -X- _ O
0.694 -X- _ B-MetricValue
, -X- _ O
0.827 -X- _ B-MetricValue
and -X- _ O
.0.811 -X- _ B-MetricValue
respectively -X- _ O
for -X- _ O
the -X- _ O
10 -X- _ O
fold -X- _ O
run -X- _ O
of -X- _ O
cnn -X- _ O
- -X- _ O
lstm -X- _ O
and -X- _ O
lstm -X- _ O
only -X- _ O
. -X- _ O

for -X- _ O
the -X- _ O
convolution -X- _ O
layer -X- _ O
, -X- _ O
the -X- _ O
win- -X- _ B-HyperparameterName
dow -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
l -X- _ O
) -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
output -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
this -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
( -X- _ O
dc)is -X- _ O
set -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
. -X- _ O

we -X- _ O
set -X- _ O
the -X- _ O
word -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
( -X- _ O
dlt)to -X- _ O
50 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
output -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
recurrent -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
( -X- _ O
dr)to -X- _ O
300 -X- _ B-HyperparameterValue
. -X- _ O

the -X- _ O
mini -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
64 -X- _ B-HyperparameterValue
in -X- _ O
our -X- _ O
experiments -X- _ O
and -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
network -X- _ O
for -X- _ O
400 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O

we -X- _ O
use -X- _ O
the -X- _ O
rmsprop -X- _ O
optimizer -X- _ O
with -X- _ O
decay -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
)set -X- _ O
to -X- _ O
0.9 -X- _ B-HyperparameterValue
to -X- _ O
train -X- _ O
the -X- _ O
net- -X- _ O
work -X- _ O
and -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
base -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
0.001 -X- _ B-HyperparameterValue
. -X- _ O

we -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
a -X- _ O
Ô¨Åxed -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
( -X- _ O
around -X- _ O
8000 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
then -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
de- -X- _ O
velopment -X- _ O
set -X- _ O
. -X- _ O

in -X- _ O
each -X- _ O
fold -X- _ O
, -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
data -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
training -X- _ B-HyperparameterName
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
as -X- _ O
the -X- _ O
develop- -X- _ B-HyperparameterName
ment -X- _ I-HyperparameterName
set -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
as -X- _ O
the -X- _ O
test -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
. -X- _ O

of -X- _ O
Ô¨Ålters -X- _ O
100 -X- _ O
bi -X- _ O
- -X- _ O
lstm -X- _ O
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
100 -X- _ B-HyperparameterValue
dropout -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
1.0 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
200 -X- _ B-HyperparameterValue
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
10 -X- _ B-HyperparameterValue
initial -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
0.001 -X- _ B-HyperparameterValue
momentum -X- _ B-HyperparameterName
0.9 -X- _ B-HyperparameterValue
4 -X- _ O
experiments -X- _ O
4.1 -X- _ O
dataset -X- _ O
an -X- _ O
automated -X- _ O
student -X- _ O
assessment -X- _ O
prize -X- _ O
( -X- _ O
asap -X- _ O
) -X- _ O
contest -X- _ O
was -X- _ O
hosted -X- _ O
at -X- _ O
kaggle -X- _ O
in -X- _ O
2012 -X- _ O
. -X- _ O

where,2[0;1]is -X- _ O
the -X- _ O
smoothing -X- _ B-HyperparameterName
parameter -X- _ I-HyperparameterName
and -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
term -X- _ O
qin -X- _ O
the -X- _ O
corpus -X- _ O
c. -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
0:9 -X- _ B-HyperparameterValue
. -X- _ O

detection -X- _ O
t -X- _ O
ask -X- _ O
runs -X- _ O
precision -X- _ B-MetricName
recall -X- _ B-MetricName
f1 -X- _ B-MetricName
run1 -X- _ O
0.6736 -X- _ B-MetricValue
0.8621 -X- _ B-MetricValue
0.7563 -X- _ B-MetricValue
run2 -X- _ O
0.7266 -X- _ B-MetricValue
0.7408 -X- _ B-MetricValue
0.7336 -X- _ B-MetricValue
identification -X- _ O
t -X- _ O
ask -X- _ O
model -X- _ O
precision -X- _ B-MetricName
recall -X- _ B-MetricName
f1 -X- _ B-MetricName
run1 -X- _ O
0.4834 -X- _ B-MetricValue
0.5952 -X- _ B-MetricValue
0.5335 -X- _ B-MetricValue
run2 -X- _ O
0.5831 -X- _ B-MetricValue
0.4955 -X- _ B-MetricValue
0.5357 -X- _ B-MetricValue
position -X- _ O
t -X- _ O
ask -X- _ O
model -X- _ O
precision -X- _ B-MetricName
recall -X- _ B-MetricName
f1 -X- _ B-MetricName
run1 -X- _ O
0.2741 -X- _ B-MetricValue
0.3177 -X- _ B-MetricValue
0.2943 -X- _ B-MetricValue
run2 -X- _ O
0.3839 -X- _ B-MetricValue
0.2966 -X- _ B-MetricValue
0.3346 -X- _ B-MetricValue
t -X- _ O
able -X- _ O
6 -X- _ O
: -X- _ O
results -X- _ O
on -X- _ O
evaluation -X- _ O
dataset -X- _ O
of -X- _ O
dip -X- _ O
t -X- _ O
asks -X- _ O
. -X- _ O

in -X- _ O
top1 -X- _ O
correction -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
f1 -X- _ B-MetricName
of -X- _ O
run2 -X- _ O
ranked -X- _ O
2/9 -X- _ O
according -X- _ O
to -X- _ O
teams -X- _ O
and -X- _ O
2/23 -X- _ O
according -X- _ O
to -X- _ O
results -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
highest -X- _ O
result -X- _ O
by -X- _ O
only -X- _ O
0.0001 -X- _ B-MetricValue
. -X- _ O

and -X- _ O
in -X- _ O
the -X- _ O
position -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
f1 -X- _ B-MetricName
of -X- _ O
run2 -X- _ O
gained -X- _ O
third -X- _ O
place -X- _ O
among -X- _ O
32 -X- _ O
results -X- _ O
. -X- _ O

in -X- _ O
the -X- _ O
identification -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
f1 -X- _ B-MetricName
of -X- _ O
run1 -X- _ O
and -X- _ O
run2 -X- _ O
ranked -X- _ O
the -X- _ O
second -X- _ O
and -X- _ O
the -X- _ O
third -X- _ O
respectively -X- _ O
. -X- _ O

the -X- _ O
first -X- _ O
run -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
( -X- _ O
run1 -X- _ O
) -X- _ O
achieved -X- _ O
the -X- _ O
highest -X- _ O
f1 -X- _ B-MetricName
scores -X- _ I-MetricName
in -X- _ O
the -X- _ O
detec- -X- _ O
tion -X- _ O
task -X- _ O
. -X- _ O

specifically -X- _ O
, -X- _ O
we -X- _ O
tag -X- _ O
each -X- _ O
character -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
the -X- _ O
lstm -X- _ B-MethodName
- -X- _ I-MethodName
crf -X- _ I-MethodName
model -X- _ O
( -X- _ O
huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

the -X- _ O
pseudo -X- _ O
data -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
gives -X- _ O
rise -X- _ O
to -X- _ O
improvements -X- _ O
in -X- _ O
both -X- _ O
precision -X- _ B-MetricName
and -X- _ O
re- -X- _ B-MetricName
call -X- _ I-MetricName
. -X- _ O

7 -X- _ O
conclusion -X- _ O
and -X- _ O
f -X- _ O
uture -X- _ O
w -X- _ O
ork -X- _ O
in -X- _ O
cged -X- _ O
2018 -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
sequence -X- _ O
to -X- _ O
se- -X- _ O
quence -X- _ O
learning -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
grammar -X- _ B-TaskName
error -X- _ I-TaskName
correction -X- _ I-TaskName
. -X- _ O

t -X- _ O
able -X- _ O
2shows -X- _ O
the -X- _ O
ensembled -X- _ O
system -X- _ O
1 -X- _ O
+ -X- _ O
3 -X- _ O
( -X- _ O
> -X- _ O
1 -X- _ O
) -X- _ O
achieves -X- _ O
a -X- _ O
f -X- _ B-MetricName
alse -X- _ I-MetricName
positive -X- _ I-MetricName
rate -X- _ I-MetricName
( -X- _ O
fpr -X- _ B-MetricName
) -X- _ O
at -X- _ O
4.48 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
a -X- _ O
precision -X- _ B-MetricName
of -X- _ O
86.56 -X- _ B-MetricValue
% -X- _ I-MetricValue
the -X- _ O
detection -X- _ O
of -X- _ O
erroneous -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
best -X- _ O
fpr -X- _ B-MetricName
4.99 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
the -X- _ O
best -X- _ O
precision82.76 -X- _ B-MetricName
% -X- _ B-MetricValue
in -X- _ O
cged -X- _ O
2018 -X- _ O
submissions -X- _ O
, -X- _ O
respec- -X- _ O
tively -X- _ O
. -X- _ O

these -X- _ O
performances -X- _ O
are -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
best -X- _ O
in -X- _ O
cged -X- _ O
2018 -X- _ O
submissions -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
precision -X- _ B-MetricName
is -X- _ O
29.32 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
recall -X- _ B-MetricName
is -X- _ O
1.58 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O

the -X- _ O
ensembled -X- _ O
systems -X- _ O
steadily -X- _ O
achieve -X- _ O
a -X- _ O
precision -X- _ B-MetricName
greater -X- _ O
than -X- _ O
50 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
with -X- _ O
a -X- _ O
recall -X- _ B-MetricName
greater -X- _ O
than -X- _ O
8 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O

being -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
significance -X- _ O
of -X- _ O
pre- -X- _ B-MetricName
cision -X- _ I-MetricName
in -X- _ O
a -X- _ O
grammar -X- _ B-TaskName
error -X- _ I-TaskName
correction -X- _ I-TaskName
system -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
use -X- _ O
ensembles -X- _ O
to -X- _ O
boost -X- _ O
precisions -X- _ B-MetricName
. -X- _ O

a -X- _ O
teacher -X- _ O
would -X- _ O
always -X- _ O
prefers -X- _ O
a -X- _ O
grammar -X- _ B-TaskName
error -X- _ I-TaskName
correction -X- _ I-TaskName
system -X- _ O
with -X- _ O
high -X- _ O
precision -X- _ B-MetricName
, -X- _ O
even -X- _ O
if -X- _ O
it -X- _ O
has -X- _ O
a -X- _ O
low -X- _ O
recall -X- _ B-MetricName
, -X- _ O
than -X- _ O
a -X- _ O
system -X- _ O
returns -X- _ O
lots -X- _ O
of -X- _ O
noises -X- _ O
. -X- _ O

in -X- _ O
real -X- _ O
scenarios -X- _ O
of -X- _ O
grammar -X- _ O
error -X- _ O
diag- -X- _ O
noses -X- _ O
, -X- _ O
the -X- _ O
evaluation -X- _ O
metrics -X- _ O
of -X- _ O
precision -X- _ B-MetricName
, -X- _ O
re- -X- _ B-MetricName
call -X- _ I-MetricName
and -X- _ O
f1 -X- _ B-MetricName
are -X- _ O
not -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
importance -X- _ O
. -X- _ O

the -X- _ O
evaluation -X- _ O
in -X- _ O
t -X- _ O
able -X- _ O
1reveals -X- _ O
that -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
pseudo -X- _ O
data -X- _ O
has -X- _ O
improved -X- _ O
both -X- _ O
pre- -X- _ B-MetricName
cision -X- _ I-MetricName
and -X- _ O
recall -X- _ B-MetricName
in -X- _ O
the -X- _ O
correction -X- _ O
task -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
selection -X- _ O
errors -X- _ O
and -X- _ O
missing -X- _ O
errors -X- _ O
, -X- _ O
while -X- _ O
that -X- _ O
of -X- _ O
pos -X- _ O
tags -X- _ O
does -X- _ O
not -X- _ O
make -X- _ O
a -X- _ O
significant -X- _ O
contribution -X- _ O
. -X- _ O

w -X- _ O
e -X- _ O
use -X- _ O
the -X- _ O
default -X- _ O
settings -X- _ O
of -X- _ O
f -X- _ B-MethodName
airseq -X- _ I-MethodName
, -X- _ O
except -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
512 -X- _ B-HyperparameterValue
dimensions -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
character -X- _ I-HyperparameterName
embeddings -X- _ I-HyperparameterName
. -X- _ O

the -X- _ O
inputs -X- _ O
to -X- _ O
f -X- _ B-MethodName
airseq -X- _ I-MethodName
models -X- _ O
are -X- _ O
as -X- _ O
simple -X- _ O
as -X- _ O
chinese -X- _ O
characters -X- _ O
and -X- _ O
pos -X- _ O
tags -X- _ O
of -X- _ O
charac- -X- _ O
ters -X- _ O
. -X- _ O

in -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
f -X- _ B-MethodName
airseq -X- _ I-MethodName
model -X- _ O
. -X- _ O

the -X- _ O
f -X- _ B-MethodName
airseq -X- _ I-MethodName
models -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
pseudo -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
the -X- _ O
manually -X- _ O
labeled -X- _ O
data -X- _ O
delivered -X- _ O
in -X- _ O
cged -X- _ O
. -X- _ O

it -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
main- -X- _ O
stream -X- _ O
model -X- _ O
for -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
nowa- -X- _ O
days -X- _ O
( -X- _ O
klein -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

y -X- _ O
u -X- _ O
and -X- _ O
chen -X- _ O
( -X- _ O
2012 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
use -X- _ O
conditional -X- _ B-MethodName
random -X- _ I-MethodName
field -X- _ I-MethodName
( -X- _ O
crf -X- _ B-MethodName
) -X- _ O
( -X- _ O
lafferty -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

when -X- _ O
using -X- _ O
inputs -X- _ O
as -X- _ O
simple -X- _ O
as -X- _ O
chi- -X- _ O
nese -X- _ O
characters -X- _ O
, -X- _ O
the -X- _ O
ensembled -X- _ O
system -X- _ O
achieves -X- _ O
a -X- _ O
precision -X- _ B-MetricName
at -X- _ O
86.56 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
erroneous -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
precision -X- _ B-MetricName
at -X- _ O
51.53 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
the -X- _ O
correction -X- _ O
of -X- _ O
errors -X- _ O
of -X- _ O
selection -X- _ O
and -X- _ O
missing -X- _ O
types -X- _ O
. -X- _ O

a -X- _ O
robust -X- _ O
riskminimization -X- _ O
based -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
sys -X- _ O
- -X- _ O
tem -X- _ O
. -X- _ O

introduction -X- _ O
to -X- _ O
the -X- _ O
conll-2003 -X- _ O
shared -X- _ O
task -X- _ O
: -X- _ O
language -X- _ O
- -X- _ O
independent -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O

design -X- _ O
chal -X- _ O
- -X- _ O
lenges -X- _ O
and -X- _ O
misconceptions -X- _ O
in -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recogni -X- _ I-TaskName
- -X- _ I-TaskName
tion -X- _ I-TaskName
. -X- _ O

named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
with -X- _ O
document -X- _ O
- -X- _ O
speciÔ¨Åc -X- _ O
kb -X- _ O
tag -X- _ O
gazetteers -X- _ O
. -X- _ O

others -X- _ O
, -X- _ O
usedexternal -X- _ O
knowledge -X- _ O
by -X- _ O
exploiting -X- _ O
the -X- _ O
associationbetween -X- _ O
ner -X- _ B-TaskName
and -X- _ O
ned -X- _ B-TaskName
( -X- _ O
durrett -X- _ O
and -X- _ O
klein,2014;radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

previous -X- _ O
work -X- _ O
has -X- _ O
already -X- _ O
regarded -X- _ O
ner -X- _ B-TaskName
asa -X- _ O
knowledge -X- _ O
intensive -X- _ O
task -X- _ O
( -X- _ O
florian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

, -X- _ O
2016 -X- _ O
; -X- _ O
65 -X- _ O
70 -X- _ O
75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentitygerman -X- _ O
- -X- _ O
testgerman -X- _ O
- -X- _ O
devspanish -X- _ O
- -X- _ O
testspanish -X- _ O
- -X- _ O
dev -X- _ O
figure -X- _ O
3 -X- _ O
: -X- _ O
ner -X- _ B-TaskName
f1for -X- _ B-MetricName
german -X- _ O
on -X- _ O
conll2003gdataset -X- _ B-DatasetName
and -X- _ O
spanish -X- _ O
on -X- _ O
conll2002 -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

a -X- _ O
recent -X- _ O
trend -X- _ O
hasachieved -X- _ O
particularly -X- _ O
good -X- _ O
results -X- _ O
modeling -X- _ O
neras -X- _ B-TaskName
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
task -X- _ O
using -X- _ O
neural -X- _ O
networks -X- _ O
( -X- _ O
dossantos -X- _ O
and -X- _ O
guimarÀúaes,2015;chiu -X- _ O
and -X- _ O
nichols,2016;lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

, -X- _ O
2016 -X- _ O
) -X- _ O
in -X- _ O
german -X- _ O
and -X- _ O
1.98 -X- _ B-MetricValue
f1points -X- _ B-MetricName
on -X- _ O
( -X- _ O
yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

our -X- _ O
system -X- _ O
lags -X- _ O
only -X- _ O
1.56 -X- _ B-MetricValue
f1pointson -X- _ B-MetricName
( -X- _ O
lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

performance -X- _ O
is -X- _ O
evaluatedon -X- _ O
conll2003 -X- _ B-DatasetName
g -X- _ O
( -X- _ O
sang -X- _ O
and -X- _ O
meulder,2003 -X- _ O
) -X- _ O
forgerman -X- _ O
and -X- _ O
conll2002 -X- _ B-DatasetName
( -X- _ O
tjong -X- _ O
kim -X- _ O
sang,2002)for -X- _ O
spanish -X- _ O
. -X- _ O

interestingly -X- _ O
, -X- _ O
lo -X- _ O
- -X- _ O
cations -X- _ O
register -X- _ O
a -X- _ O
slight -X- _ O
decline -X- _ O
between -X- _ O
kb -X- _ O
andentity -X- _ O
( -X- _ O
0.56f1points).finally -X- _ B-MetricValue
, -X- _ O
fig.1bshows -X- _ O
the -X- _ O
performance -X- _ O
overspan -X- _ O
detection -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
span -X- _ O
where -X- _ O
the -X- _ O
namedentity -X- _ O
occurs -X- _ O
without -X- _ O
taking -X- _ O
type -X- _ O
information -X- _ O
intoaccount -X- _ O
. -X- _ O

the -X- _ O
positive -X- _ O
effect -X- _ O
is -X- _ O
par -X- _ O
- -X- _ O
ticularly -X- _ O
strong -X- _ O
for -X- _ O
persons -X- _ O
, -X- _ O
improving -X- _ O
more -X- _ O
than15f1points -X- _ B-MetricValue
( -X- _ O
78.70 -X- _ B-MetricValue
to -X- _ O
94.28 -X- _ B-MetricValue
) -X- _ O
. -X- _ O

75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentityconll2003 -X- _ B-DatasetName
- -X- _ O
testconll2003 -X- _ B-DatasetName
- -X- _ O
devmuc-7 -X- _ O
- -X- _ O
testmuc-7 -X- _ O
- -X- _ O
dev(b -X- _ O
) -X- _ O
span -X- _ O
- -X- _ O
basedf1score -X- _ B-MetricName
75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentityfperforgflocfmiscfall -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
type -X- _ O
- -X- _ O
based -X- _ O
nerf1score -X- _ B-TaskName
on -X- _ O
conll2003 -X- _ B-DatasetName
- -X- _ O
test -X- _ O
75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentityfperforgflocfall -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
type -X- _ O
- -X- _ O
based -X- _ O
nerf1score -X- _ B-TaskName
on -X- _ O
muc-7 -X- _ O
- -X- _ O
testfigure -X- _ O
1 -X- _ O
: -X- _ O
evaluation -X- _ O
results -X- _ O
by -X- _ O
type -X- _ O
conll2003 -X- _ B-DatasetName
- -X- _ O
test -X- _ O
and -X- _ O
muc-7-test.locations -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
successive -X- _ O
increment -X- _ O
is -X- _ O
sharper -X- _ O
. -X- _ O

244 -X- _ O
75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentityconll2003 -X- _ B-DatasetName
- -X- _ O
testconll2003 -X- _ B-DatasetName
- -X- _ O
devmuc-7 -X- _ O
- -X- _ O
testmuc-7 -X- _ O
- -X- _ O
dev -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
nerf1score -X- _ B-TaskName
. -X- _ O

to -X- _ O
perform -X- _ O
our -X- _ O
study -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
lin -X- _ B-MethodName
- -X- _ I-MethodName
ear -X- _ I-MethodName
chain -X- _ I-MethodName
crf(lafferty -X- _ I-MethodName
et -X- _ O
al -X- _ O
. -X- _ O

we -X- _ O
evaluate -X- _ O
on -X- _ O
two -X- _ O
standard -X- _ O
nerdatasetsconll2003.(sang -X- _ B-DatasetName
and -X- _ O
meulder,2003),a -X- _ O
collection -X- _ O
of -X- _ O
english -X- _ O
newswires -X- _ O
covering -X- _ O
enti -X- _ O
- -X- _ O
ties -X- _ O
with -X- _ O
four -X- _ O
types -X- _ O
( -X- _ O
per -X- _ O
, -X- _ O
org -X- _ O
, -X- _ O
loc -X- _ O
, -X- _ O
misc)andmuc-7 -X- _ O
, -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
new -X- _ O
york -X- _ O
times -X- _ O
articles(chinchor -X- _ O
and -X- _ O
robinson,1997 -X- _ O
) -X- _ O
with -X- _ O
annotationson -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
entities -X- _ O
( -X- _ O
per -X- _ O
, -X- _ O
org -X- _ O
, -X- _ O
loc).3.2 -X- _ O
incremental -X- _ O
knowledgehere -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
incrementallyadding -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O

as -X- _ O
a -X- _ O
referencepoint -X- _ O
, -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
systems -X- _ O
to -X- _ O
date -X- _ O
( -X- _ O
chiu -X- _ O
andnichols,2016 -X- _ O
) -X- _ O
( -X- _ O
neural -X- _ O
- -X- _ O
based -X- _ O
) -X- _ O
achievesf191.62on -X- _ O
conll2013 -X- _ B-DatasetName
- -X- _ O
test -X- _ O
, -X- _ O
while -X- _ O
our -X- _ O
full -X- _ O
- -X- _ O
knowledgecrf -X- _ O
reachesf191.12.fig.1cshows -X- _ O
the -X- _ O
performance -X- _ O
for -X- _ O
each -X- _ O
entitytype -X- _ O
on -X- _ O
conll2003 -X- _ B-DatasetName
. -X- _ O

they -X- _ O
encode -X- _ O
knowl -X- _ O
- -X- _ O
edge -X- _ O
about -X- _ O
named -X- _ O
entities -X- _ O
themselves -X- _ O
or -X- _ O
their -X- _ O
us -X- _ O
- -X- _ O
ages -X- _ O
. -X- _ O

our -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
theamount -X- _ O
of -X- _ O
knowledge -X- _ O
is -X- _ O
highly -X- _ O
correlated -X- _ O
withner -X- _ O
performance -X- _ O
. -X- _ O

on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
educational -X- _ O
environment -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
improved -X- _ O
to -X- _ O
impact -X- _ O
the -X- _ O
world -X- _ O
society -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
emergence -X- _ O
of -X- _ O
moocs -X- _ O
( -X- _ O
massive -X- _ O
open -X- _ O
online -X- _ O
courses -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
new -X- _ O
learning -X- _ O
tools -X- _ O
or -X- _ O
teach -X- _ O
- -X- _ O
ing -X- _ O
paradigms -X- _ O
have -X- _ O
also -X- _ O
change -X- _ O
the -X- _ O
way -X- _ O
of -X- _ O
class -X- _ O
interactions -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
classroom -X- _ O
re -X- _ O
- -X- _ O
sponse -X- _ O
systems -X- _ O
( -X- _ O
crs -X- _ O
) -X- _ O
( -X- _ O
siau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

top -X- _ O
3 -X- _ O
by -X- _ O
both -X- _ O
one -X- _ O
or -X- _ O
two -X- _ O
of -X- _ O
the -X- _ O
tradespeople -X- _ O
even -X- _ O
darted -X- _ O
out -X- _ O
of -X- _ O
their -X- _ O
shops -X- _ O
, -X- _ O
and -X- _ O
went -X- _ O
a -X- _ O
little -X- _ O
way -X- _ O
down -X- _ O
the -X- _ O
street -X- _ O
before -X- _ O
me -X- _ O
, -X- _ O
that -X- _ O
they -X- _ O
might -X- _ O
turn -X- _ O
, -X- _ O
as -X- _ O
if -X- _ O
they -X- _ O
had -X- _ O
forgotten -X- _ O
something -X- _ O
, -X- _ O
and -X- _ O
pass -X- _ O
me -X- _ O
face -X- _ O
to -X- _ O
face -X- _ O
‚Äì -X- _ O
on -X- _ O
which -X- _ O
occa -X- _ O
- -X- _ O
sions -X- _ O
i -X- _ O
do -X- _ O
n't -X- _ O
know -X- _ O
whether -X- _ O
they -X- _ O
or -X- _ O
i -X- _ O
made -X- _ O
the -X- _ O
worse -X- _ O
pretence -X- _ O
; -X- _ O
they -X- _ O
of -X- _ O
doing -X- _ O
it -X- _ O
, -X- _ O
or -X- _ O
i -X- _ O
of -X- _ O
not -X- _ O
seeing -X- _ O
it -X- _ O
. -X- _ O

many -X- _ O
of -X- _ O
the -X- _ O
decreases -X- _ O
are -X- _ O
statistically -X- _ O
insignificant -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
decrease -X- _ O
in -X- _ O
delay -X- _ O
from -X- _ O
g3 -X- _ O
to -X- _ O
g4 -X- _ O
with -X- _ O
p -X- _ B-MetricName
- -X- _ I-MetricName
value -X- _ I-MetricName
of -X- _ O
0.13 -X- _ B-MetricValue
. -X- _ O

conditional -X- _ B-MethodName
random -X- _ I-MethodName
fields -X- _ I-MethodName
with -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
features -X- _ O
for -X- _ O
sequence -X- _ O
labeling -X- _ O
. -X- _ O

for -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
val- -X- _ O
idation -X- _ O
of -X- _ O
the -X- _ O
precursor -X- _ B-MethodName
- -X- _ I-MethodName
induced -X- _ I-MethodName
crf -X- _ I-MethodName
in -X- _ O
deep -X- _ O
neu- -X- _ O
ral -X- _ O
architecture -X- _ O
for -X- _ O
ner -X- _ B-TaskName
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
lstm -X- _ B-MethodName
- -X- _ I-MethodName
crf -X- _ I-MethodName
neural -X- _ O
architecture -X- _ O
( -X- _ O
lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

evidence -X- _ O
from -X- _ O
this -X- _ O
study -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
utili- -X- _ O
zation -X- _ O
of -X- _ O
outside -X- _ O
labels -X- _ O
as -X- _ O
precedent -X- _ O
ne -X- _ O
infor- -X- _ O
mation -X- _ O
transmission -X- _ O
medium -X- _ O
presumably -X- _ O
can -X- _ O
en- -X- _ O
hance -X- _ O
the -X- _ O
expressiveness -X- _ O
of -X- _ O
the -X- _ O
crf -X- _ B-MethodName
while -X- _ O
keeping -X- _ O
the -X- _ O
first -X- _ O
- -X- _ O
order -X- _ O
template -X- _ O
. -X- _ O

although -X- _ O
the -X- _ O
performance -X- _ O
improvement -X- _ O
is -X- _ O
small -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
clinical -X- _ O
and -X- _ O
biomedical -X- _ O
ner -X- _ O
evaluations -X- _ O
, -X- _ O
this -X- _ O
study -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
design -X- _ O
enables -X- _ O
reduced -X- _ O
computational -X- _ O
cost -X- _ O
in -X- _ O
uti- -X- _ O
lizing -X- _ O
long -X- _ O
- -X- _ O
distance -X- _ O
label -X- _ O
dependency -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
second -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
. -X- _ O

the -X- _ O
design -X- _ O
of -X- _ O
the -X- _ O
precursor -X- _ B-MethodName
- -X- _ I-MethodName
induced -X- _ I-MethodName
crf -X- _ I-MethodName
apparently -X- _ O
allows -X- _ O
precedent -X- _ O
named -X- _ O
entity -X- _ O
in- -X- _ O
formation -X- _ O
to -X- _ O
pass -X- _ O
through -X- _ O
outside -X- _ O
labels -X- _ O
by -X- _ O
induc- -X- _ O
tion -X- _ O
, -X- _ O
even -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
maintains -X- _ O
a -X- _ O
first -X- _ O
- -X- _ O
order -X- _ O
template -X- _ O
. -X- _ O

these -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
precursor -X- _ B-MethodName
- -X- _ I-MethodName
induced -X- _ I-MethodName
crf -X- _ I-MethodName
, -X- _ O
where -X- _ O
long -X- _ O
- -X- _ O
distance -X- _ O
dependency -X- _ O
is -X- _ O
intro- -X- _ O
duced -X- _ O
in -X- _ O
crf -X- _ B-MethodName
by -X- _ O
label -X- _ O
induction -X- _ O
, -X- _ O
slightly -X- _ O
improves -X- _ O
the -X- _ O
effectiveness -X- _ O
in -X- _ O
clinical -X- _ O
and -X- _ O
biomedical -X- _ O
ner -X- _ B-TaskName
while -X- _ O
also -X- _ O
significantly -X- _ O
reducing -X- _ O
computational -X- _ O
cost -X- _ O
rather -X- _ O
than -X- _ O
building -X- _ O
second- -X- _ B-MethodName
or -X- _ I-MethodName
higher -X- _ I-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crfs -X- _ I-MethodName
. -X- _ O

the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
induced -X- _ I-MethodName
crf -X- _ I-MethodName
takes -X- _ O
significantly -X- _ O
less -X- _ O
time -X- _ O
than -X- _ O
the -X- _ O
second -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
while -X- _ O
the -X- _ O
pre- -X- _ B-MethodName
induced -X- _ I-MethodName
crf -X- _ I-MethodName
exploits -X- _ O
longer -X- _ O
label -X- _ O
transition -X- _ O
de- -X- _ O
pendency -X- _ O
than -X- _ O
the -X- _ O
second -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
. -X- _ O

the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
induced -X- _ I-MethodName
crf -X- _ I-MethodName
takes -X- _ O
1.7 -X- _ O
times -X- _ O
more -X- _ O
computation -X- _ O
time -X- _ O
than -X- _ O
the -X- _ O
first -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
in -X- _ O
average -X- _ O
. -X- _ O

the -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
second -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
takes -X- _ O
quite -X- _ O
more -X- _ O
time -X- _ O
than -X- _ O
the -X- _ O
first -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
to -X- _ O
compute -X- _ O
one -X- _ O
train- -X- _ O
ing -X- _ O
iteration -X- _ O
. -X- _ O

in -X- _ O
order -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
conventional -X- _ O
crf -X- _ B-MethodName
, -X- _ O
both -X- _ O
the -X- _ O
first -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
and -X- _ O
the -X- _ O
sec- -X- _ B-MethodName
ond -X- _ I-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
are -X- _ O
used -X- _ O
as -X- _ O
baseline -X- _ O
models -X- _ O
. -X- _ O

the -X- _ O
result -X- _ O
shows -X- _ O
a -X- _ O
tendency -X- _ O
that -X- _ O
pre- -X- _ B-MethodName
cursor -X- _ I-MethodName
- -X- _ I-MethodName
induced -X- _ I-MethodName
( -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
induced -X- _ I-MethodName
) -X- _ O
crf -X- _ B-MethodName
leads -X- _ O
to -X- _ O
a -X- _ O
slight -X- _ O
performance -X- _ O
improvement -X- _ O
compared -X- _ O
to -X- _ O
both -X- _ O
the -X- _ O
first -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
and -X- _ O
second -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crfs -X- _ I-MethodName
in -X- _ O
most -X- _ O
cases -X- _ O
. -X- _ O

to -X- _ O
perform -X- _ O
ner -X- _ B-TaskName
evaluation -X- _ O
, -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
feature -X- _ O
families -X- _ O
are -X- _ O
used -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
token -X- _ O
itself -X- _ O
and -X- _ O
neighbor -X- _ O
to- -X- _ O
kens -X- _ O
in -X- _ O
window -X- _ O
size -X- _ O
3 -X- _ O
. -X- _ O

the -X- _ O
named -X- _ O
entity -X- _ O
classes -X- _ O
in -X- _ O
the -X- _ O
biomedi- -X- _ O
cal -X- _ O
ner -X- _ B-TaskName
evaluation -X- _ O
are -X- _ O
dna -X- _ O
, -X- _ O
rna -X- _ O
, -X- _ O
protein -X- _ O
, -X- _ O
cell -X- _ O
line -X- _ O
, -X- _ O
and -X- _ O
cell -X- _ O
type -X- _ O
. -X- _ O

annotated -X- _ O
named -X- _ O
entities -X- _ O
involved -X- _ O
in -X- _ O
the -X- _ O
clini- -X- _ O
cal -X- _ O
ner -X- _ B-TaskName
evaluation -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
mentions -X- _ O
describ- -X- _ O
ing -X- _ O
the -X- _ O
patient -X- _ O
‚Äôs -X- _ O
history -X- _ O
. -X- _ O

in -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
induced -X- _ I-MethodName
crf -X- _ I-MethodName
, -X- _ O
the -X- _ O
outside -X- _ O
state -X- _ O
with -X- _ O
a -X- _ O
memory -X- _ O
element -X- _ O
behaves -X- _ O
as -X- _ O
if -X- _ O
an -X- _ O
information -X- _ O
transmission -X- _ O
medium -X- _ O
is -X- _ O
delivering -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
presence -X- _ O
or -X- _ O
absence -X- _ O
of -X- _ O
the -X- _ O
preceding -X- _ O
en- -X- _ O
tity -X- _ O
forward -X- _ O
. -X- _ O

the -X- _ O
main -X- _ O
purpose -X- _ O
of -X- _ O
the -X- _ O
precursor -X- _ O
- -X- _ O
induced -X- _ B-MethodName
crf -X- _ I-MethodName
model -X- _ O
, -X- _ O
introduced -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
is -X- _ O
to -X- _ O
capture -X- _ O
spe- -X- _ O
cific -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
named -X- _ O
entity -X- _ O
dependency -X- _ O
that -X- _ O
is -X- _ O
an -X- _ O
outside -X- _ O
word -X- _ O
sequence -X- _ O
between -X- _ O
two -X- _ O
nes -X- _ O
. -X- _ O

because -X- _ O
the -X- _ O
first -X- _ O
- -X- _ O
order -X- _ O
model -X- _ O
assumes -X- _ O
that -X- _ O
state -X- _ O
transition -X- _ O
dependencies -X- _ O
exist -X- _ O
only -X- _ O
between -X- _ O
proximate -X- _ O
two -X- _ O
la- -X- _ O
bels -X- _ O
to -X- _ O
prevent -X- _ O
an -X- _ O
increase -X- _ O
in -X- _ O
computational -X- _ O
com- -X- _ O
plexity -X- _ O
, -X- _ O
the -X- _ O
first -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
learns -X- _ O
bigram -X- _ O
label -X- _ O
transitions -X- _ O
from -X- _ O
the -X- _ O
subsequence -X- _ O
; -X- _ O
{ -X- _ O
( -X- _ O
ùê¥,ùëÇ),(ùëÇ,ùëÇ),(ùëÇ,ùêµ -X- _ O
) -X- _ O
} -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
label -X- _ O
transition -X- _ O
data -X- _ O
learnt -X- _ O
from -X- _ O
the -X- _ O
example -X- _ O
sequence -X- _ O
. -X- _ O

as -X- _ O
a -X- _ O
sequence -X- _ O
labeling -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
conventional -X- _ O
crf -X- _ B-MethodName
models -X- _ O
the -X- _ O
conditional -X- _ O
distribu- -X- _ O
tion -X- _ O
ùëÉ(ùíö|ùíô -X- _ O
) -X- _ O
in -X- _ O
which -X- _ O
x -X- _ O
is -X- _ O
the -X- _ O
input -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
token -X- _ O
, -X- _ O
word -X- _ O
) -X- _ O
sequence -X- _ O
and -X- _ O
y -X- _ O
is -X- _ O
the -X- _ O
label -X- _ O
sequence -X- _ O
of -X- _ O
x. -X- _ O
a -X- _ O
hidden -X- _ O
state -X- _ O
value -X- _ O
set -X- _ O
consists -X- _ O
of -X- _ O
target -X- _ O
entity -X- _ O
labels -X- _ O
and -X- _ O
a -X- _ O
single -X- _ O
outside -X- _ O
label -X- _ O
. -X- _ O

2 -X- _ O
precursor -X- _ O
- -X- _ O
induced -X- _ O
crf -X- _ B-MethodName
prior -X- _ O
to -X- _ O
introducing -X- _ O
the -X- _ O
new -X- _ O
model -X- _ O
formulation -X- _ O
, -X- _ O
the -X- _ O
following -X- _ O
information -X- _ O
presents -X- _ O
the -X- _ O
general -X- _ O
con- -X- _ O
cept -X- _ O
of -X- _ O
crf -X- _ B-MethodName
. -X- _ O

10 -X- _ O
kens -X- _ O
, -X- _ O
this -X- _ O
study -X- _ O
explores -X- _ O
the -X- _ O
method -X- _ O
which -X- _ O
modi- -X- _ O
fies -X- _ O
the -X- _ O
first -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
linear -X- _ I-MethodName
- -X- _ I-MethodName
chain -X- _ I-MethodName
crf -X- _ I-MethodName
by -X- _ O
using -X- _ O
the -X- _ O
induction -X- _ O
method -X- _ O
. -X- _ O

previous -X- _ O
studies -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
implementation -X- _ O
of -X- _ O
the -X- _ O
higher- -X- _ O
order -X- _ O
crf -X- _ B-MethodName
exploiting -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
label -X- _ O
patterns -X- _ O
leads -X- _ O
to -X- _ O
slight -X- _ O
performance -X- _ O
improvement -X- _ O
in -X- _ O
the -X- _ O
conventional -X- _ O
crf -X- _ B-MethodName
in -X- _ O
ner -X- _ B-TaskName
( -X- _ O
cuong -X- _ O
, -X- _ O
ye -X- _ O
, -X- _ O
lee -X- _ O
, -X- _ O
& -X- _ O
chieu -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
fersini -X- _ O
, -X- _ O
messina -X- _ O
, -X- _ O
felici -X- _ O
, -X- _ O
& -X- _ O
roth -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
sarawagi -X- _ O
& -X- _ O
cohen -X- _ O
, -X- _ O
2005 -X- _ O
; -X- _ O
ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

only -X- _ O
dependencies -X- _ O
between -X- _ O
neighbor -X- _ O
labels -X- _ O
are -X- _ O
generally -X- _ O
used -X- _ O
in -X- _ O
practice -X- _ O
because -X- _ O
conventional -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
crfs -X- _ B-MethodName
are -X- _ O
known -X- _ O
to -X- _ O
be -X- _ O
intractable -X- _ O
in -X- _ O
ner -X- _ B-TaskName
( -X- _ O
ye -X- _ O
, -X- _ O
lee -X- _ O
, -X- _ O
chieu -X- _ O
, -X- _ O
& -X- _ O
wu -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O

one -X- _ O
major -X- _ O
issue -X- _ O
in -X- _ O
previous -X- _ O
studies -X- _ O
was -X- _ O
con- -X- _ O
cerned -X- _ O
with -X- _ O
the -X- _ O
way -X- _ O
in -X- _ O
which -X- _ O
to -X- _ O
explore -X- _ O
long -X- _ O
- -X- _ O
dis- -X- _ O
tance -X- _ O
dependencies -X- _ O
in -X- _ O
ner -X- _ B-TaskName
. -X- _ O

in -X- _ O
contrast -X- _ O
, -X- _ O
a -X- _ O
crf -X- _ B-MethodName
in -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
ner -X- _ B-TaskName
) -X- _ O
can -X- _ O
not -X- _ O
fully -X- _ O
capture -X- _ O
dependencies -X- _ O
between -X- _ O
named -X- _ O
entity -X- _ O
( -X- _ O
ne -X- _ O
) -X- _ O
labels -X- _ O
. -X- _ O

one -X- _ O
of -X- _ O
the -X- _ O
primary -X- _ O
advantages -X- _ O
of -X- _ O
applying -X- _ O
the -X- _ O
crf -X- _ B-MethodName
to -X- _ O
language -X- _ O
processing -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
learns -X- _ O
transi- -X- _ O
tion -X- _ O
factors -X- _ O
between -X- _ O
hidden -X- _ O
variables -X- _ O
correspond- -X- _ O
ing -X- _ O
to -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
single -X- _ O
word -X- _ O
. -X- _ O

even -X- _ O
in -X- _ O
deep -X- _ O
- -X- _ O
learn- -X- _ O
ing -X- _ O
architecture -X- _ O
, -X- _ O
crf -X- _ B-MethodName
has -X- _ O
been -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
funda- -X- _ O
mental -X- _ O
element -X- _ O
in -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
lample -X- _ O
, -X- _ O
ballesteros -X- _ O
, -X- _ O
subramanian -X- _ O
, -X- _ O
kawakami -X- _ O
, -X- _ O
& -X- _ O
dyer -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
liu -X- _ O
, -X- _ O
tang -X- _ O
, -X- _ O
wang -X- _ O
, -X- _ O
& -X- _ O
chen -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

1 -X- _ O
introduction -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
conditional -X- _ B-MethodName
random -X- _ I-MethodName
fields -X- _ I-MethodName
( -X- _ O
crfs -X- _ B-MethodName
) -X- _ O
( -X- _ O
john -X- _ O
lafferty -X- _ O
, -X- _ O
andrew -X- _ O
mccallum -X- _ O
, -X- _ O
& -X- _ O
fernando -X- _ O
pereira -X- _ O
, -X- _ O
2001 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
successfully -X- _ O
adapted -X- _ O
in -X- _ O
many -X- _ O
sequence -X- _ O
labeling -X- _ O
problems -X- _ O
( -X- _ O
andrew -X- _ O
mccallum -X- _ O
& -X- _ O
wei -X- _ O
li -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
fei -X- _ O
sha -X- _ O
& -X- _ O
fernando -X- _ O
pereira -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
john -X- _ O
lafferty -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

then -X- _ O
, -X- _ O
empirical -X- _ O
results -X- _ O
apparently -X- _ O
demonstrate -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
exploit -X- _ O
long -X- _ O
- -X- _ O
distance -X- _ O
label -X- _ O
dependency -X- _ O
in -X- _ O
the -X- _ O
orig- -X- _ O
inal -X- _ O
first -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
linear -X- _ I-MethodName
chain -X- _ I-MethodName
crf -X- _ I-MethodName
structure -X- _ O
upon -X- _ O
ner -X- _ B-TaskName
while -X- _ O
reducing -X- _ O
computational -X- _ O
loss -X- _ O
rather -X- _ O
than -X- _ O
in -X- _ O
the -X- _ O
second -X- _ B-MethodName
- -X- _ I-MethodName
order -X- _ I-MethodName
crf -X- _ I-MethodName
. -X- _ O

the -X- _ O
proposed -X- _ O
design -X- _ O
uses -X- _ O
outside -X- _ O
label -X- _ O
in -X- _ O
ner -X- _ B-TaskName
as -X- _ O
a -X- _ O
transmission -X- _ O
me- -X- _ O
dium -X- _ O
of -X- _ O
precedent -X- _ O
entity -X- _ O
information -X- _ O
on -X- _ O
the -X- _ O
crf -X- _ B-MethodName
. -X- _ O

com- -X- _ O
pared -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ O
methods -X- _ O
, -X- _ O
our -X- _ O
leam -X- _ B-MethodName
al- -X- _ O
gorithm -X- _ O
requires -X- _ O
much -X- _ O
lower -X- _ O
computational -X- _ O
cost -X- _ O
, -X- _ O
and -X- _ O
achieves -X- _ O
better -X- _ O
if -X- _ O
not -X- _ O
comparable -X- _ O
performance -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
yahoo -X- _ B-DatasetName
dataset -X- _ I-DatasetName
( -X- _ O
b -X- _ O
) -X- _ O
clinical -X- _ O
text -X- _ O
figure -X- _ O
4 -X- _ O
: -X- _ O
visualization -X- _ O
of -X- _ O
learned -X- _ O
attention -X- _ O
. -X- _ O

cnn -X- _ B-MethodName
con- -X- _ O
sistently -X- _ O
outperforms -X- _ O
the -X- _ O
basic -X- _ O
bi -X- _ B-MethodName
- -X- _ I-MethodName
gru -X- _ I-MethodName
architec- -X- _ O
ture -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
logistic -X- _ B-MethodName
regression -X- _ I-MethodName
baseline -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
all -X- _ O
deep -X- _ O
learning -X- _ O
architectures -X- _ O
. -X- _ O

leam -X- _ B-MethodName
pro- -X- _ O
vides -X- _ O
the -X- _ O
best -X- _ O
auc -X- _ B-MetricName
score -X- _ O
, -X- _ O
and -X- _ O
better -X- _ O
f1 -X- _ B-MetricName
and -X- _ O
p@5 -X- _ B-MetricName
values -X- _ O
than -X- _ O
all -X- _ O
methods -X- _ O
except -X- _ O
cnn -X- _ O
. -X- _ O

2018 -X- _ O
) -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
micro -X- _ O
- -X- _ O
averaged -X- _ O
and -X- _ O
macro -X- _ O
- -X- _ O
averaged -X- _ O
f1 -X- _ B-MetricName
and -X- _ O
area -X- _ B-MetricName
under -X- _ I-MetricName
the -X- _ I-MetricName
roc -X- _ I-MetricName
curve -X- _ I-MetricName
( -X- _ O
auc -X- _ B-MetricName
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
preci- -X- _ B-MetricName
sion -X- _ I-MetricName
atn(p@n -X- _ B-MetricName
) -X- _ O
. -X- _ O

we -X- _ O
also -X- _ O
compare -X- _ O
with -X- _ O
three -X- _ O
recent -X- _ O
methods -X- _ O
for -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
label -X- _ I-TaskName
classiÔ¨Åcation -X- _ I-TaskName
of -X- _ O
clinical -X- _ O
text -X- _ O
, -X- _ O
including -X- _ O
condensed -X- _ B-MethodName
memory -X- _ I-MethodName
net- -X- _ I-MethodName
works -X- _ I-MethodName
( -X- _ O
c -X- _ B-MethodName
- -X- _ I-MethodName
memnn -X- _ I-MethodName
) -X- _ O
( -X- _ O
prakash -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

5.3 -X- _ O
applications -X- _ O
to -X- _ O
clinical -X- _ O
text -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
practical -X- _ O
value -X- _ O
of -X- _ O
label -X- _ O
embed- -X- _ O
dings -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
leam -X- _ B-MethodName
for -X- _ O
a -X- _ O
real -X- _ O
health -X- _ O
care -X- _ O
sce- -X- _ O
nario -X- _ O
: -X- _ O
medical -X- _ O
code -X- _ O
prediction -X- _ O
on -X- _ O
the -X- _ O
electronic -X- _ O
health -X- _ O
records -X- _ O
dataset -X- _ O
. -X- _ O

we -X- _ O
visualize -X- _ O
two -X- _ O
examples -X- _ O
in -X- _ O
figure -X- _ O
4(a -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
yahoo -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

the -X- _ O
high -X- _ O
on -X- _ O
- -X- _ O
diagonal -X- _ O
elements -X- _ O
and -X- _ O
low -X- _ O
off -X- _ O
- -X- _ O
diagonal -X- _ O
elements -X- _ O
in -X- _ O
figure -X- _ O
3(a -X- _ O
) -X- _ O
indicate -X- _ O
the -X- _ O
superb -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
label -X- _ O
representations -X- _ O
learned -X- _ O
from -X- _ O
leam -X- _ B-MethodName
. -X- _ O

5.2 -X- _ O
representational -X- _ O
ability -X- _ O
label -X- _ O
embeddings -X- _ O
are -X- _ O
highly -X- _ O
meaningful -X- _ O
to -X- _ O
provide -X- _ O
insight -X- _ O
into -X- _ O
the -X- _ O
meaningfulness -X- _ O
of -X- _ O
the -X- _ O
learned -X- _ O
representations -X- _ O
, -X- _ O
in -X- _ O
figure -X- _ O
3 -X- _ O
we -X- _ O
visual- -X- _ O
ize -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
label -X- _ O
embeddings -X- _ O
and -X- _ O
document -X- _ O
embeddings -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
yahoo -X- _ B-DatasetName
date- -X- _ I-DatasetName
set -X- _ I-DatasetName
. -X- _ O

the -X- _ O
topic -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
tasks -X- _ O
generally -X- _ O
requires -X- _ O
a -X- _ O
larger -X- _ O
r -X- _ B-HyperparameterName
, -X- _ O
while -X- _ O
senti- -X- _ B-TaskName
ment -X- _ I-TaskName
classiÔ¨Åcation -X- _ I-TaskName
tasks -X- _ O
allows -X- _ O
relatively -X- _ O
smaller -X- _ O
r. -X- _ B-HyperparameterName
one -X- _ O
may -X- _ O
safely -X- _ O
choose -X- _ O
raround -X- _ O
50if -X- _ B-HyperparameterValue
not -X- _ O
Ô¨Åne- -X- _ O
tuning -X- _ O
. -X- _ O

leam -X- _ B-MethodName
uses -X- _ O
much -X- _ O
less -X- _ O
model -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
converges -X- _ O
signiÔ¨Åcantlymodel -X- _ O
# -X- _ O
parameters -X- _ O
time -X- _ O
cost -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
cnn -X- _ O
541k -X- _ O
171 -X- _ O
lstm -X- _ O
1.8 -X- _ O
m -X- _ O
598 -X- _ O
swem -X- _ O
61 -X- _ O
k -X- _ O
63 -X- _ O
bi -X- _ O
- -X- _ O
blosan -X- _ O
3.6 -X- _ O
m -X- _ O
292 -X- _ O
leam -X- _ O
65 -X- _ O
k -X- _ O
65 -X- _ O
table -X- _ O
4 -X- _ O
: -X- _ O
comparison -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
and -X- _ O
speed -X- _ O
. -X- _ O

2014 -X- _ O
) -X- _ O
is -X- _ O
employed -X- _ O
on -X- _ O
the -X- _ O
Ô¨Ånal -X- _ O
mlp -X- _ O
layer -X- _ O
, -X- _ O
with -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0:5 -X- _ B-HyperparameterValue
. -X- _ O

we -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
‚Äôs -X- _ O
parameters -X- _ O
with -X- _ O
the -X- _ O
adam -X- _ O
optimizer -X- _ O
( -X- _ O
kingma -X- _ O
and -X- _ O
ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
ini- -X- _ B-HyperparameterName
tial -X- _ I-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0:001 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
a -X- _ O
minibatch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
100 -X- _ B-HyperparameterValue
. -X- _ O

for -X- _ O
the -X- _ O
datasets -X- _ O
without -X- _ O
representative -X- _ O
class -X- _ O
descriptions -X- _ O
, -X- _ O
one -X- _ O
may -X- _ O
initialize -X- _ O
the -X- _ O
label -X- _ O
embed- -X- _ O
dings -X- _ O
as -X- _ O
random -X- _ O
samples -X- _ O
drawn -X- _ O
from -X- _ O
a -X- _ O
standard -X- _ O
gaussian -X- _ O
distribution -X- _ O
. -X- _ O

speciÔ¨Åcally -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
text -X- _ O
em- -X- _ O
bedding -X- _ O
in -X- _ O
pte -X- _ O
is -X- _ O
similar -X- _ O
with -X- _ O
a -X- _ O
very -X- _ O
special -X- _ O
case -X- _ O
of -X- _ O
leam -X- _ O
, -X- _ O
when -X- _ O
our -X- _ O
window -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
r= -X- _ O
1 -X- _ B-HyperparameterValue
and -X- _ O
at- -X- _ O
tention -X- _ O
score -X- _ O
is -X- _ O
uniform -X- _ O
. -X- _ O

we -X- _ O
also -X- _ O
compute -X- _ O
a -X- _ O
pair -X- _ O
wise -X- _ O
cohen -X- _ B-MetricName
‚Äôs -X- _ I-MetricName
value -X- _ I-MetricName
of -X- _ O
0.97 -X- _ B-MetricValue
. -X- _ O

we -X- _ O
have -X- _ O
achieved -X- _ O
a -X- _ O
pearson -X- _ B-MetricName
‚Äôs -X- _ I-MetricName
and -X- _ O
spearman -X- _ B-MetricName
‚Äôs -X- _ I-MetricName
correlation -X- _ I-MetricName
of -X- _ O
0.94 -X- _ B-MetricValue
and -X- _ O
0.97 -X- _ B-MetricValue
respectively -X- _ O
as -X- _ O
com- -X- _ O
pared -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
0.91 -X- _ B-MetricValue
and -X- _ O
0.96 -X- _ B-MetricValue
in -X- _ O
( -X- _ O
alikaniotis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
found -X- _ O
that -X- _ O
that -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
all -X- _ O
these -X- _ O
parameters -X- _ O
our -X- _ O
system -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
existing -X- _ O
, -X- _ O
lstm -X- _ B-MethodName
, -X- _ O
bi -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
and -X- _ O
ease -X- _ O
mod- -X- _ O
els -X- _ O
. -X- _ O

on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
also -X- _ O
used -X- _ O
evalua- -X- _ O
tion -X- _ O
matrices -X- _ O
like -X- _ O
, -X- _ O
pearson -X- _ B-MetricName
‚Äôs -X- _ I-MetricName
correlation -X- _ I-MetricName
r -X- _ O
, -X- _ O
spear- -X- _ B-MetricName
man -X- _ I-MetricName
‚Äôs -X- _ I-MetricName
ranking -X- _ I-MetricName
correlation -X- _ I-MetricName
 -X- _ O
, -X- _ O
rmse -X- _ B-MetricName
scores -X- _ O
in -X- _ O
or- -X- _ O
der -X- _ O
to -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
systems -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
alikaniotis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

it -X- _ O
is -X- _ O
worth -X- _ O
mentioning -X- _ O
here -X- _ O
that -X- _ O
all -X- _ O
these -X- _ O
mod- -X- _ O
els -X- _ O
are -X- _ O
compared -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
qwk -X- _ B-MetricName
score -X- _ I-MetricName
. -X- _ O

for -X- _ O
ex- -X- _ O
ample -X- _ O
, -X- _ O
in -X- _ O
prompt -X- _ O
3 -X- _ O
, -X- _ O
6 -X- _ O
and -X- _ O
7 -X- _ O
we -X- _ O
have -X- _ O
achieved -X- _ O
an -X- _ O
qwk -X- _ B-MetricName
of -X- _ O
0.712 -X- _ B-MetricValue
, -X- _ O
0.831 -X- _ B-MetricValue
and -X- _ O
0.815 -X- _ B-MetricValue
respectively -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
reported -X- _ O
average -X- _ B-MetricName
qwk -X- _ I-MetricName
score -X- _ I-MetricName
of -X- _ O
0.694 -X- _ B-MetricValue
, -X- _ O
0.827 -X- _ B-MetricValue
and -X- _ O
.0.811 -X- _ B-MetricValue
respectively -X- _ O
for -X- _ O
the -X- _ O
10 -X- _ O
fold -X- _ O
run -X- _ O
of -X- _ O
cnn -X- _ O
- -X- _ O
lstm -X- _ O
and -X- _ O
lstm -X- _ O
only -X- _ O
. -X- _ O

for -X- _ O
the -X- _ O
convolution -X- _ O
layer -X- _ O
, -X- _ O
the -X- _ O
win- -X- _ B-HyperparameterName
dow -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
l -X- _ O
) -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
output -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
this -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
( -X- _ O
dc)is -X- _ O
set -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
. -X- _ O

we -X- _ O
set -X- _ O
the -X- _ O
word -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
( -X- _ O
dlt)to -X- _ O
50 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
output -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
recurrent -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
( -X- _ O
dr)to -X- _ O
300 -X- _ B-HyperparameterValue
. -X- _ O

the -X- _ O
mini -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
64 -X- _ B-HyperparameterValue
in -X- _ O
our -X- _ O
experiments -X- _ O
and -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
network -X- _ O
for -X- _ O
400 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O

we -X- _ O
use -X- _ O
the -X- _ O
rmsprop -X- _ O
optimizer -X- _ O
with -X- _ O
decay -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
)set -X- _ O
to -X- _ O
0.9 -X- _ B-HyperparameterValue
to -X- _ O
train -X- _ O
the -X- _ O
net- -X- _ O
work -X- _ O
and -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
base -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
0.001 -X- _ B-HyperparameterValue
. -X- _ O

we -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
a -X- _ O
Ô¨Åxed -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
( -X- _ O
around -X- _ O
8000 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
then -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
de- -X- _ O
velopment -X- _ O
set -X- _ O
. -X- _ O

in -X- _ O
each -X- _ O
fold -X- _ O
, -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
data -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
training -X- _ B-HyperparameterName
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
as -X- _ O
the -X- _ O
develop- -X- _ B-HyperparameterName
ment -X- _ I-HyperparameterName
set -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
as -X- _ O
the -X- _ O
test -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
. -X- _ O

of -X- _ O
Ô¨Ålters -X- _ O
100 -X- _ O
bi -X- _ O
- -X- _ O
lstm -X- _ O
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
100 -X- _ B-HyperparameterValue
dropout -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
1.0 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
200 -X- _ B-HyperparameterValue
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
10 -X- _ B-HyperparameterValue
initial -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
0.001 -X- _ B-HyperparameterValue
momentum -X- _ B-HyperparameterName
0.9 -X- _ B-HyperparameterValue
4 -X- _ O
experiments -X- _ O
4.1 -X- _ O
dataset -X- _ O
an -X- _ O
automated -X- _ O
student -X- _ O
assessment -X- _ O
prize -X- _ O
( -X- _ O
asap -X- _ O
) -X- _ O
contest -X- _ O
was -X- _ O
hosted -X- _ O
at -X- _ O
kaggle -X- _ O
in -X- _ O
2012 -X- _ O
. -X- _ O

where,2[0;1]is -X- _ O
the -X- _ O
smoothing -X- _ B-HyperparameterName
parameter -X- _ I-HyperparameterName
and -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
term -X- _ O
qin -X- _ O
the -X- _ O
corpus -X- _ O
c. -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
0:9 -X- _ B-HyperparameterValue
. -X- _ O

detection -X- _ O
t -X- _ O
ask -X- _ O
runs -X- _ O
precision -X- _ B-MetricName
recall -X- _ B-MetricName
f1 -X- _ B-MetricName
run1 -X- _ O
0.6736 -X- _ B-MetricValue
0.8621 -X- _ B-MetricValue
0.7563 -X- _ B-MetricValue
run2 -X- _ O
0.7266 -X- _ B-MetricValue
0.7408 -X- _ B-MetricValue
0.7336 -X- _ B-MetricValue
identification -X- _ O
t -X- _ O
ask -X- _ O
model -X- _ O
precision -X- _ B-MetricName
recall -X- _ B-MetricName
f1 -X- _ B-MetricName
run1 -X- _ O
0.4834 -X- _ B-MetricValue
0.5952 -X- _ B-MetricValue
0.5335 -X- _ B-MetricValue
run2 -X- _ O
0.5831 -X- _ B-MetricValue
0.4955 -X- _ B-MetricValue
0.5357 -X- _ B-MetricValue
position -X- _ O
t -X- _ O
ask -X- _ O
model -X- _ O
precision -X- _ B-MetricName
recall -X- _ B-MetricName
f1 -X- _ B-MetricName
run1 -X- _ O
0.2741 -X- _ B-MetricValue
0.3177 -X- _ B-MetricValue
0.2943 -X- _ B-MetricValue
run2 -X- _ O
0.3839 -X- _ B-MetricValue
0.2966 -X- _ B-MetricValue
0.3346 -X- _ B-MetricValue
t -X- _ O
able -X- _ O
6 -X- _ O
: -X- _ O
results -X- _ O
on -X- _ O
evaluation -X- _ O
dataset -X- _ O
of -X- _ O
dip -X- _ O
t -X- _ O
asks -X- _ O
. -X- _ O

in -X- _ O
top1 -X- _ O
correction -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
f1 -X- _ B-MetricName
of -X- _ O
run2 -X- _ O
ranked -X- _ O
2/9 -X- _ O
according -X- _ O
to -X- _ O
teams -X- _ O
and -X- _ O
2/23 -X- _ O
according -X- _ O
to -X- _ O
results -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
highest -X- _ O
result -X- _ O
by -X- _ O
only -X- _ O
0.0001 -X- _ B-MetricValue
. -X- _ O

and -X- _ O
in -X- _ O
the -X- _ O
position -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
f1 -X- _ B-MetricName
of -X- _ O
run2 -X- _ O
gained -X- _ O
third -X- _ O
place -X- _ O
among -X- _ O
32 -X- _ O
results -X- _ O
. -X- _ O

in -X- _ O
the -X- _ O
identification -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
f1 -X- _ B-MetricName
of -X- _ O
run1 -X- _ O
and -X- _ O
run2 -X- _ O
ranked -X- _ O
the -X- _ O
second -X- _ O
and -X- _ O
the -X- _ O
third -X- _ O
respectively -X- _ O
. -X- _ O

the -X- _ O
first -X- _ O
run -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
( -X- _ O
run1 -X- _ O
) -X- _ O
achieved -X- _ O
the -X- _ O
highest -X- _ O
f1 -X- _ B-MetricName
scores -X- _ I-MetricName
in -X- _ O
the -X- _ O
detec- -X- _ O
tion -X- _ O
task -X- _ O
. -X- _ O

specifically -X- _ O
, -X- _ O
we -X- _ O
tag -X- _ O
each -X- _ O
character -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
the -X- _ O
lstm -X- _ B-MethodName
- -X- _ I-MethodName
crf -X- _ I-MethodName
model -X- _ O
( -X- _ O
huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

the -X- _ O
pseudo -X- _ O
data -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
gives -X- _ O
rise -X- _ O
to -X- _ O
improvements -X- _ O
in -X- _ O
both -X- _ O
precision -X- _ B-MetricName
and -X- _ O
re- -X- _ B-MetricName
call -X- _ I-MetricName
. -X- _ O

7 -X- _ O
conclusion -X- _ O
and -X- _ O
f -X- _ O
uture -X- _ O
w -X- _ O
ork -X- _ O
in -X- _ O
cged -X- _ O
2018 -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
sequence -X- _ O
to -X- _ O
se- -X- _ O
quence -X- _ O
learning -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
grammar -X- _ B-TaskName
error -X- _ I-TaskName
correction -X- _ I-TaskName
. -X- _ O

t -X- _ O
able -X- _ O
2shows -X- _ O
the -X- _ O
ensembled -X- _ O
system -X- _ O
1 -X- _ O
+ -X- _ O
3 -X- _ O
( -X- _ O
> -X- _ O
1 -X- _ O
) -X- _ O
achieves -X- _ O
a -X- _ O
f -X- _ B-MetricName
alse -X- _ I-MetricName
positive -X- _ I-MetricName
rate -X- _ I-MetricName
( -X- _ O
fpr -X- _ B-MetricName
) -X- _ O
at -X- _ O
4.48 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
a -X- _ O
precision -X- _ B-MetricName
of -X- _ O
86.56 -X- _ B-MetricValue
% -X- _ I-MetricValue
the -X- _ O
detection -X- _ O
of -X- _ O
erroneous -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
best -X- _ O
fpr -X- _ B-MetricName
4.99 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
the -X- _ O
best -X- _ O
precision82.76 -X- _ B-MetricName
% -X- _ B-MetricValue
in -X- _ O
cged -X- _ O
2018 -X- _ O
submissions -X- _ O
, -X- _ O
respec- -X- _ O
tively -X- _ O
. -X- _ O

these -X- _ O
performances -X- _ O
are -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
best -X- _ O
in -X- _ O
cged -X- _ O
2018 -X- _ O
submissions -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
precision -X- _ B-MetricName
is -X- _ O
29.32 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
recall -X- _ B-MetricName
is -X- _ O
1.58 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O

the -X- _ O
ensembled -X- _ O
systems -X- _ O
steadily -X- _ O
achieve -X- _ O
a -X- _ O
precision -X- _ B-MetricName
greater -X- _ O
than -X- _ O
50 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
with -X- _ O
a -X- _ O
recall -X- _ B-MetricName
greater -X- _ O
than -X- _ O
8 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O

being -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
significance -X- _ O
of -X- _ O
pre- -X- _ B-MetricName
cision -X- _ I-MetricName
in -X- _ O
a -X- _ O
grammar -X- _ B-TaskName
error -X- _ I-TaskName
correction -X- _ I-TaskName
system -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
use -X- _ O
ensembles -X- _ O
to -X- _ O
boost -X- _ O
precisions -X- _ B-MetricName
. -X- _ O

a -X- _ O
teacher -X- _ O
would -X- _ O
always -X- _ O
prefers -X- _ O
a -X- _ O
grammar -X- _ B-TaskName
error -X- _ I-TaskName
correction -X- _ I-TaskName
system -X- _ O
with -X- _ O
high -X- _ O
precision -X- _ B-MetricName
, -X- _ O
even -X- _ O
if -X- _ O
it -X- _ O
has -X- _ O
a -X- _ O
low -X- _ O
recall -X- _ B-MetricName
, -X- _ O
than -X- _ O
a -X- _ O
system -X- _ O
returns -X- _ O
lots -X- _ O
of -X- _ O
noises -X- _ O
. -X- _ O

in -X- _ O
real -X- _ O
scenarios -X- _ O
of -X- _ O
grammar -X- _ O
error -X- _ O
diag- -X- _ O
noses -X- _ O
, -X- _ O
the -X- _ O
evaluation -X- _ O
metrics -X- _ O
of -X- _ O
precision -X- _ B-MetricName
, -X- _ O
re- -X- _ B-MetricName
call -X- _ I-MetricName
and -X- _ O
f1 -X- _ B-MetricName
are -X- _ O
not -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
importance -X- _ O
. -X- _ O

the -X- _ O
evaluation -X- _ O
in -X- _ O
t -X- _ O
able -X- _ O
1reveals -X- _ O
that -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
pseudo -X- _ O
data -X- _ O
has -X- _ O
improved -X- _ O
both -X- _ O
pre- -X- _ B-MetricName
cision -X- _ I-MetricName
and -X- _ O
recall -X- _ B-MetricName
in -X- _ O
the -X- _ O
correction -X- _ O
task -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
selection -X- _ O
errors -X- _ O
and -X- _ O
missing -X- _ O
errors -X- _ O
, -X- _ O
while -X- _ O
that -X- _ O
of -X- _ O
pos -X- _ O
tags -X- _ O
does -X- _ O
not -X- _ O
make -X- _ O
a -X- _ O
significant -X- _ O
contribution -X- _ O
. -X- _ O

w -X- _ O
e -X- _ O
use -X- _ O
the -X- _ O
default -X- _ O
settings -X- _ O
of -X- _ O
f -X- _ B-MethodName
airseq -X- _ I-MethodName
, -X- _ O
except -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
512 -X- _ B-HyperparameterValue
dimensions -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
character -X- _ I-HyperparameterName
embeddings -X- _ I-HyperparameterName
. -X- _ O

the -X- _ O
inputs -X- _ O
to -X- _ O
f -X- _ B-MethodName
airseq -X- _ I-MethodName
models -X- _ O
are -X- _ O
as -X- _ O
simple -X- _ O
as -X- _ O
chinese -X- _ O
characters -X- _ O
and -X- _ O
pos -X- _ O
tags -X- _ O
of -X- _ O
charac- -X- _ O
ters -X- _ O
. -X- _ O

in -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
f -X- _ B-MethodName
airseq -X- _ I-MethodName
model -X- _ O
. -X- _ O

the -X- _ O
f -X- _ B-MethodName
airseq -X- _ I-MethodName
models -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
pseudo -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
the -X- _ O
manually -X- _ O
labeled -X- _ O
data -X- _ O
delivered -X- _ O
in -X- _ O
cged -X- _ O
. -X- _ O

it -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
main- -X- _ O
stream -X- _ O
model -X- _ O
for -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
nowa- -X- _ O
days -X- _ O
( -X- _ O
klein -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

y -X- _ O
u -X- _ O
and -X- _ O
chen -X- _ O
( -X- _ O
2012 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
use -X- _ O
conditional -X- _ B-MethodName
random -X- _ I-MethodName
field -X- _ I-MethodName
( -X- _ O
crf -X- _ B-MethodName
) -X- _ O
( -X- _ O
lafferty -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

when -X- _ O
using -X- _ O
inputs -X- _ O
as -X- _ O
simple -X- _ O
as -X- _ O
chi- -X- _ O
nese -X- _ O
characters -X- _ O
, -X- _ O
the -X- _ O
ensembled -X- _ O
system -X- _ O
achieves -X- _ O
a -X- _ O
precision -X- _ B-MetricName
at -X- _ O
86.56 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
erroneous -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
precision -X- _ B-MetricName
at -X- _ O
51.53 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
the -X- _ O
correction -X- _ O
of -X- _ O
errors -X- _ O
of -X- _ O
selection -X- _ O
and -X- _ O
missing -X- _ O
types -X- _ O
. -X- _ O

a -X- _ O
robust -X- _ O
riskminimization -X- _ O
based -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
sys -X- _ O
- -X- _ O
tem -X- _ O
. -X- _ O

introduction -X- _ O
to -X- _ O
the -X- _ O
conll-2003 -X- _ O
shared -X- _ O
task -X- _ O
: -X- _ O
language -X- _ O
- -X- _ O
independent -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O

design -X- _ O
chal -X- _ O
- -X- _ O
lenges -X- _ O
and -X- _ O
misconceptions -X- _ O
in -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recogni -X- _ I-TaskName
- -X- _ I-TaskName
tion -X- _ I-TaskName
. -X- _ O

named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
with -X- _ O
document -X- _ O
- -X- _ O
speciÔ¨Åc -X- _ O
kb -X- _ O
tag -X- _ O
gazetteers -X- _ O
. -X- _ O

others -X- _ O
, -X- _ O
usedexternal -X- _ O
knowledge -X- _ O
by -X- _ O
exploiting -X- _ O
the -X- _ O
associationbetween -X- _ O
ner -X- _ B-TaskName
and -X- _ O
ned -X- _ B-TaskName
( -X- _ O
durrett -X- _ O
and -X- _ O
klein,2014;radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

previous -X- _ O
work -X- _ O
has -X- _ O
already -X- _ O
regarded -X- _ O
ner -X- _ B-TaskName
asa -X- _ O
knowledge -X- _ O
intensive -X- _ O
task -X- _ O
( -X- _ O
florian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

, -X- _ O
2016 -X- _ O
; -X- _ O
65 -X- _ O
70 -X- _ O
75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentitygerman -X- _ O
- -X- _ O
testgerman -X- _ O
- -X- _ O
devspanish -X- _ O
- -X- _ O
testspanish -X- _ O
- -X- _ O
dev -X- _ O
figure -X- _ O
3 -X- _ O
: -X- _ O
ner -X- _ B-TaskName
f1for -X- _ B-MetricName
german -X- _ O
on -X- _ O
conll2003gdataset -X- _ B-DatasetName
and -X- _ O
spanish -X- _ O
on -X- _ O
conll2002 -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

a -X- _ O
recent -X- _ O
trend -X- _ O
hasachieved -X- _ O
particularly -X- _ O
good -X- _ O
results -X- _ O
modeling -X- _ O
neras -X- _ B-TaskName
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
task -X- _ O
using -X- _ O
neural -X- _ O
networks -X- _ O
( -X- _ O
dossantos -X- _ O
and -X- _ O
guimarÀúaes,2015;chiu -X- _ O
and -X- _ O
nichols,2016;lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

, -X- _ O
2016 -X- _ O
) -X- _ O
in -X- _ O
german -X- _ O
and -X- _ O
1.98 -X- _ B-MetricValue
f1points -X- _ B-MetricName
on -X- _ O
( -X- _ O
yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

our -X- _ O
system -X- _ O
lags -X- _ O
only -X- _ O
1.56 -X- _ B-MetricValue
f1pointson -X- _ B-MetricName
( -X- _ O
lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

performance -X- _ O
is -X- _ O
evaluatedon -X- _ O
conll2003 -X- _ B-DatasetName
g -X- _ O
( -X- _ O
sang -X- _ O
and -X- _ O
meulder,2003 -X- _ O
) -X- _ O
forgerman -X- _ O
and -X- _ O
conll2002 -X- _ B-DatasetName
( -X- _ O
tjong -X- _ O
kim -X- _ O
sang,2002)for -X- _ O
spanish -X- _ O
. -X- _ O

interestingly -X- _ O
, -X- _ O
lo -X- _ O
- -X- _ O
cations -X- _ O
register -X- _ O
a -X- _ O
slight -X- _ O
decline -X- _ O
between -X- _ O
kb -X- _ O
andentity -X- _ O
( -X- _ O
0.56f1points).finally -X- _ B-MetricValue
, -X- _ O
fig.1bshows -X- _ O
the -X- _ O
performance -X- _ O
overspan -X- _ O
detection -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
span -X- _ O
where -X- _ O
the -X- _ O
namedentity -X- _ O
occurs -X- _ O
without -X- _ O
taking -X- _ O
type -X- _ O
information -X- _ O
intoaccount -X- _ O
. -X- _ O

the -X- _ O
positive -X- _ O
effect -X- _ O
is -X- _ O
par -X- _ O
- -X- _ O
ticularly -X- _ O
strong -X- _ O
for -X- _ O
persons -X- _ O
, -X- _ O
improving -X- _ O
more -X- _ O
than15f1points -X- _ B-MetricValue
( -X- _ O
78.70 -X- _ B-MetricValue
to -X- _ O
94.28 -X- _ B-MetricValue
) -X- _ O
. -X- _ O

75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentityconll2003 -X- _ B-DatasetName
- -X- _ O
testconll2003 -X- _ B-DatasetName
- -X- _ O
devmuc-7 -X- _ O
- -X- _ O
testmuc-7 -X- _ O
- -X- _ O
dev(b -X- _ O
) -X- _ O
span -X- _ O
- -X- _ O
basedf1score -X- _ B-MetricName
75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentityfperforgflocfmiscfall -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
type -X- _ O
- -X- _ O
based -X- _ O
nerf1score -X- _ B-TaskName
on -X- _ O
conll2003 -X- _ B-DatasetName
- -X- _ O
test -X- _ O
75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentityfperforgflocfall -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
type -X- _ O
- -X- _ O
based -X- _ O
nerf1score -X- _ B-TaskName
on -X- _ O
muc-7 -X- _ O
- -X- _ O
testfigure -X- _ O
1 -X- _ O
: -X- _ O
evaluation -X- _ O
results -X- _ O
by -X- _ O
type -X- _ O
conll2003 -X- _ B-DatasetName
- -X- _ O
test -X- _ O
and -X- _ O
muc-7-test.locations -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
successive -X- _ O
increment -X- _ O
is -X- _ O
sharper -X- _ O
. -X- _ O

244 -X- _ O
75 -X- _ O
80 -X- _ O
85 -X- _ O
90 -X- _ O
95 -X- _ O
100 -X- _ O
anamekbentityconll2003 -X- _ B-DatasetName
- -X- _ O
testconll2003 -X- _ B-DatasetName
- -X- _ O
devmuc-7 -X- _ O
- -X- _ O
testmuc-7 -X- _ O
- -X- _ O
dev -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
nerf1score -X- _ B-TaskName
. -X- _ O

to -X- _ O
perform -X- _ O
our -X- _ O
study -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
lin -X- _ B-MethodName
- -X- _ I-MethodName
ear -X- _ I-MethodName
chain -X- _ I-MethodName
crf(lafferty -X- _ I-MethodName
et -X- _ O
al -X- _ O
. -X- _ O

we -X- _ O
evaluate -X- _ O
on -X- _ O
two -X- _ O
standard -X- _ O
nerdatasetsconll2003.(sang -X- _ B-DatasetName
and -X- _ O
meulder,2003),a -X- _ O
collection -X- _ O
of -X- _ O
english -X- _ O
newswires -X- _ O
covering -X- _ O
enti -X- _ O
- -X- _ O
ties -X- _ O
with -X- _ O
four -X- _ O
types -X- _ O
( -X- _ O
per -X- _ O
, -X- _ O
org -X- _ O
, -X- _ O
loc -X- _ O
, -X- _ O
misc)andmuc-7 -X- _ O
, -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
new -X- _ O
york -X- _ O
times -X- _ O
articles(chinchor -X- _ O
and -X- _ O
robinson,1997 -X- _ O
) -X- _ O
with -X- _ O
annotationson -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
entities -X- _ O
( -X- _ O
per -X- _ O
, -X- _ O
org -X- _ O
, -X- _ O
loc).3.2 -X- _ O
incremental -X- _ O
knowledgehere -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
incrementallyadding -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O

as -X- _ O
a -X- _ O
referencepoint -X- _ O
, -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
systems -X- _ O
to -X- _ O
date -X- _ O
( -X- _ O
chiu -X- _ O
andnichols,2016 -X- _ O
) -X- _ O
( -X- _ O
neural -X- _ O
- -X- _ O
based -X- _ O
) -X- _ O
achievesf191.62on -X- _ O
conll2013 -X- _ B-DatasetName
- -X- _ O
test -X- _ O
, -X- _ O
while -X- _ O
our -X- _ O
full -X- _ O
- -X- _ O
knowledgecrf -X- _ O
reachesf191.12.fig.1cshows -X- _ O
the -X- _ O
performance -X- _ O
for -X- _ O
each -X- _ O
entitytype -X- _ O
on -X- _ O
conll2003 -X- _ B-DatasetName
. -X- _ O

they -X- _ O
encode -X- _ O
knowl -X- _ O
- -X- _ O
edge -X- _ O
about -X- _ O
named -X- _ O
entities -X- _ O
themselves -X- _ O
or -X- _ O
their -X- _ O
us -X- _ O
- -X- _ O
ages -X- _ O
. -X- _ O

our -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
theamount -X- _ O
of -X- _ O
knowledge -X- _ O
is -X- _ O
highly -X- _ O
correlated -X- _ O
withner -X- _ O
performance -X- _ O
. -X- _ O

on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
educational -X- _ O
environment -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
improved -X- _ O
to -X- _ O
impact -X- _ O
the -X- _ O
world -X- _ O
society -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
emergence -X- _ O
of -X- _ O
moocs -X- _ O
( -X- _ O
massive -X- _ O
open -X- _ O
online -X- _ O
courses -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
new -X- _ O
learning -X- _ O
tools -X- _ O
or -X- _ O
teach -X- _ O
- -X- _ O
ing -X- _ O
paradigms -X- _ O
have -X- _ O
also -X- _ O
change -X- _ O
the -X- _ O
way -X- _ O
of -X- _ O
class -X- _ O
interactions -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
classroom -X- _ O
re -X- _ O
- -X- _ O
sponse -X- _ O
systems -X- _ O
( -X- _ O
crs -X- _ O
) -X- _ O
( -X- _ O
siau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

On B-MethodName
Training I-MethodName
Instance I-MethodName
Selection I-MethodName
for O
Few B-TaskName
- I-TaskName
Shot I-TaskName
Neural I-TaskName
Text I-TaskName
Generation I-TaskName
Large B-MethodName
- I-MethodName
scale I-MethodName
pretrained I-MethodName
language I-MethodName
models I-MethodName
have O
led O
to O
dramatic O
improvements O
in O
text B-TaskName
generation I-TaskName
. O
Impressive O
performance O
can O
be O
achieved O
by O
finetuning O
only O
on O
a O
small O
number O
of O
instances O
( O
few O
- O
shot O
setting O
) O
. O
Nonetheless O
, O
almost O
all O
previous O
work O
simply O
applies O
random B-MethodName
sampling I-MethodName
to O
select O
the O
few O
- O
shot O
training O
instances O
. O
Little O
to O
no O
attention O
has O
been O
paid O
to O
the O
selection B-MethodName
strategies I-MethodName
and O
how O
they O
would O
affect O
model O
performance O
. O
In O
this O
work O
, O
we O
present O
a O
study O
on O
training B-MethodName
instance I-MethodName
selection I-MethodName
in O
few B-TaskName
- I-TaskName
shot I-TaskName
neural I-TaskName
text I-TaskName
generation I-TaskName
. O
The O
selection O
decision O
is O
made O
based O
only O
on O
the O
unlabeled O
data O
so O
as O
to O
identify O
the O
most O
worthwhile O
data O
points O
that O
should O
be O
annotated O
under O
some O
budget O
of O
labeling O
cost O
. O
Based O
on O
the O
intuition O
that O
the O
few O
- O
shot O
training O
instances O
should O
be O
diverse O
and O
representative O
of O
the O
entire O
data O
distribution O
, O
we O
propose O
a O
simple O
selection B-MethodName
strategy I-MethodName
with I-MethodName
K I-MethodName
- I-MethodName
means I-MethodName
clustering I-MethodName
. O
We O
show O
that O
even O
with O
the O
naive O
clustering O
- O
based O
approach O
, O
the O
generation O
models O
consistently O
outperform O
random B-MethodName
sampling I-MethodName
on O
three O
text O
generation O
tasks O
: O
data B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
generation I-TaskName
, O
document B-TaskName
summarization I-TaskName
and O
question B-TaskName
generation I-TaskName
. O
The O
code O
and O
training O
data O
are O
made O
available O
at O
https://gitlab.com/erniecyc/ O
few O
- O
selector O
. O
We O
hope O
that O
this O
work O
will O
call O
for O
more O
attention O
on O
this O
largely O
unexplored O
area O
. O
* O
Equal O
contribution O
. O
X.shen O
is O
now O
at O
Amazon O
Alexa O
AI O
. O

Coach B-MethodName
: O
A O
Coarse O
- O
to O
- O
Fine O
Approach O
for O
Cross O
- O
domain O
Slot B-TaskName
Filling E-TaskName
As O
an O
essential O
task B-TaskName
in O
task B-TaskName
- O
oriented O
dialog O
systems O
, O
slot B-TaskName
filling E-TaskName
requires O
extensive O
training B-DatasetName
data E-DatasetName
in O
a O
certain O
domain O
. O

However O
, O
such O
data O
are O
not O
always O
available O
. O

Hence O
, O
cross O
- O
domain O
slot B-TaskName
filling E-TaskName
has O
naturally O
arisen O
to O
cope O
with O
this O
data O
scarcity O
problem O
. O

In O
this O
paper O
, O
we O
propose O
a O
Coarse O
- O
to O
- O
fine O
approach O
( O
Coach B-MethodName
) O
for O
cross O
- O
domain O
slot B-TaskName
filling E-TaskName
. O

Our O
model O
first O
learns O
the O
general O
pattern O
of O
slot O
entities O
by O
detecting O
whether O
the O
tokens O
are O
slot O
entities O
or O
not O
. O

It O
then O
predicts O
the O
specific O
types O
for O
the O
slot O
entities O
. O

In O
addition O
, O
we O
propose O
a O
template B-MethodName
regularization E-MethodName
approach O
to O
improve O
the O
adaptation B-MetricName
robustness E-MetricName
by O
regularizing B-MethodName
the M-MethodName
representation E-MethodName
of O
utterances O
based O
on O
utterance O
templates O
. O

Experimental O
results O
show O
that O
our O
model O
significantly O
outperforms O
state O
- O
of O
- O
the O
- O
art O
approaches O
in O
slot B-TaskName
filling E-TaskName
. O

Furthermore O
, O
our O
model O
can O
also O
be O
applied O
to O
the O
cross O
- O
domain O
named B-MethodName
entity M-MethodName
recognition M-MethodName
task E-MethodName
, O
and O
it O
achieves O
better O
adaptation B-MetricName
performance E-MetricName
than O
other O
existing O
baselines O
. O

Introduction O

Slot B-MethodName
filling M-MethodName
models E-MethodName
identify O
task O
- O
related O
slot O
types O
in O
certain O
domains O
for O
user O
utterances O
, O
and O
are O
an O
indispensable O
part O
of O
task O
- O
oriented O
dialog O
systems O
. O

Supervised O
approaches O
have O
made O
great O
achievements O
in O
the O
slot B-TaskName
filling E-TaskName
task O
( O
Goo O
et O
al O
. O
, O
2018 O
; O
, O
where O
substantial O
labeled O
training B-DatasetName
samples E-DatasetName
are O
needed O
. O

However O
, O
collecting O
large O
numbers O
of O
training B-DatasetName
samples E-DatasetName
is O
not O
only O
expensive O
but O
also O
time O
- O
consuming O
. O

To O
cope O
with O
the O
data O
scarcity O
issue O
, O
we O
are O
motivated O
to O
investigate O
cross O
- O
domain O
slot B-MethodName
filling M-MethodName
methods E-MethodName
, O
which O
leverage O
knowledge O
learned O
in O
the O
source O
domains O
and O
adapt O
the O
models O
to O
the O
target O
domain O
with O
a O
minimum O
number O
of O
target O
domain O
labeled O
training B-DatasetName
samples E-DatasetName
. O

A O
challenge O
in O
cross O
- O
domain O
slot B-TaskName
filling E-TaskName
is O
to O
handle O
unseen O
slot O
types O
, O
which O
prevents O
general O
Playlist O
Music O
Item O
Step O
1 O
Step O
2 O
Step O
2 O
( O
b O
) O
Our O
proposed O
framework O
, O
Coach B-MethodName
. O

classification B-MethodName
models E-MethodName
from O
adapting O
to O
the O
target O
domain O
without O
any O
target O
domain O
supervision O
signals O
. O

Recently O
, O
Bapna O
et O
al O
. O
( O
2017 O
) O
proposed O
a O
cross O
- O
domain O
slot B-MethodName
filling M-MethodName
framework E-MethodName
, O
which O
enables O
zero B-MethodName
- M-MethodName
shot M-MethodName
adaptation E-MethodName
. O

As O
illustrated O
in O
Figure O
1a O
, O
their O
model O
conducts O
slot B-TaskName
filling E-TaskName
individually O
for O
each O
slot O
type O
. O

It O
first O
generates O
word O
- O
level O
representations O
, O
which O
are O
then O
concatenated O
with O
the O
representation O
of O
each O
slot O
type O
description O
, O
and O
the O
predictions O
are O
based O
on O
the O
concatenated O
features O
for O
each O
slot O
type O
. O

Due O
to O
the O
inherent O
variance O
of O
slot O
entities O
across O
different O
domains O
, O
it O
is O
difficult O
for O
this O
framework O
to O
capture O
the O
whole O
slot O
entity O
( O
e.g. O
, O
" O
latin O
dance O
cardio O
" O
in O
Figure O
1a O
) O
in O
the O
target O
domain O
. O

There O
also O
exists O
a O
multiple O
prediction O
problem O
. O

For O
example O
, O
" O
tune O
" O
in O
Figure O
1a O
could O
be O
predicted O
as O
" O
B O
" O
for O
both O
" O
music O
item O
" O
and O
" O
playlist O
" O
, O
which O
would O
cause O
additional O
trouble O
for O
the O
final O
prediction O
. O

We O
emphasize O
that O
in O
order O
to O
capture O
the O
whole O
slot O
entity O
, O
it O
is O
pivotal O
for O
the O
model O
to O
share O
its O
parameters O
for O
all O
slot O
types O
in O
the O
source O
domains O
and O
learn O
the O
general O
pattern O
of O
slot O
entities O
. O

Therefore O
, O
as O
depicted O
in O
Figure O
1b O
Regularization O
Loss O
Step O
One O
Step O
Two O
Can O
you O
put O
this O
music O
item O
onto O
playlist O
Incorrect O
... O
Can O
you O
put O
this O
object O
name O
onto O
city O
Figure O
2 O
: O
Illustration O
of O
our O
framework O
, O
Coach B-MethodName
, O
and O
the O
template B-MethodName
regularization E-MethodName
approach O
. O

a O
coarse O
- O
to O
- O
fine O
approach O
. O

It O
first O
coarsely O
learns O
the O
slot O
entity O
pattern O
by O
predicting O
whether O
the O
tokens O
are O
slot O
entities O
or O
not O
. O

Then O
, O
it O
combines O
the O
features O
for O
each O
slot O
entity O
and O
predicts O
the O
specific O
( O
fine O
) O
slot O
type O
based O
on O
the O
similarity O
with O
the O
representation O
of O
each O
slot O
type O
description O
. O

In O
this O
way O
, O
our O
framework O
is O
able O
to O
avoid O
the O
multiple O
predictions O
problem O
. O

Additionally O
, O
we O
introduce O
a O
template B-MethodName
regularization M-MethodName
method E-MethodName
that O
delexicalizes O
slot O
entity O
tokens O
in O
utterances O
into O
different B-DatasetName
slot M-DatasetName
labels E-DatasetName
and O
produces O
both O
correct O
and O
incorrect O
utterance B-DatasetName
templates E-DatasetName
to O
regularize O
the O
utterance O
representations O
. O

By O
doing O
so O
, O
the O
model O
learns O
to O
cluster O
the O
representations O
of O
semantically O
similar O
utterances O
( O
i.e. O
, O
in O
the O
same O
or O
similar O
templates O
) O
into O
a O
similar O
vector O
space O
, O
which O
further O
improves O
the O
adaptation B-MetricName
robustness E-MetricName
. O

Experimental O
results O
show O
that O
our O
model O
surpasses O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
by O
a O
large O
margin O
in O
both O
zero O
- O
shot O
and O
few O
- O
shot O
scenarios O
. O

In O
addition O
, O
further O
experiments O
show O
that O
our O
framework O
can O
be O
applied O
to O
cross O
- O
domain O
named B-TaskName
entity M-TaskName
recognition E-TaskName
, O
and O
achieves O
better O
adaptation B-MetricName
performance E-MetricName
than O
other O
existing O
frameworks O
. O

Related O
Work O

Coarse O
- O
to O
- O
fine O
methods O
in O
NLP O
are O
best O
known O
for O
syntactic B-MethodName
parsing E-MethodName
( O
Charniak O
et O
al O
. O
, O
2006;Petrov O
, O
2011 O
) O
. O
Zhang O
et O
al O
. O
( O
2017 O
) O
reduced O
the O
search O
space O
of O
semantic O
parsers O
by O
using O
coarse O
macro O
grammars O
. O

Different O
from O
the O
previous O
work O
, O
we O
apply O
the O
idea O
of O
coarse O
- O
to O
- O
fine O
into O
cross O
- O
domain O
slot B-TaskName
filling E-TaskName
to O
handle O
unseen O
slot O
types O
by O
separating O
the O
slot B-TaskName
filling M-TaskName
task E-TaskName
into O
two O
steps O
( O
Zhai O
et O
al O
. O
, O
2017 O
Guerini O
et O
al O
. O
, O
2018 O
) O
. O

Coping O
with O
low B-TaskName
- M-TaskName
resource M-TaskName
problems E-TaskName
where O
there O
are O
zero O
or O
few O
existing O
training O
samples O
has O
always O
been O
an O
interesting O
and O
challenging O
task O
( O
Kingma O
et O
al O
. O
, O
2014;Lample O
et O
al O
. O
, O
2018;Liu O
et O
al O
. O
, O
2019a O
, O
b O
; O
. O

Cross O
- O
domain O
adaptation O
addresses O
the O
data O
scarcity O
problem O
in O
low O
- O
resource O
target O
domains O
( O
Pan O
et O
al O
. O
, O
2010;Jaech O
et O
al O
. O
, O
2016;Guo O
et O
al O
. O
, O
2018;Jia O
et O
al O
. O
, O
2019 O
; O
. O

However O
, O
most O
research O
studying O
the O
cross O
- O
domain O
aspect O
has O
not O
focused O
on O
predicting O
unseen O
label O
types O
in O
the O
target O
domain O
since O
both O
source O
and O
target O
domains O
have O
the O
same O
label O
types O
in O
the O
considered O
tasks O
( O
Guo O
et O
al O
. O
, O
2018 O
) O
. O

In O
another O
line O
of O
work O
, O
to O
bypass O
unseen O
label O
types O
, O
Ruder O
and O
Plank O
( O
2018 O
) O
and O
Jia O
et O
al O
. O
( O
2019 O
) O
utilized O
target O
domain O
training B-DatasetName
samples E-DatasetName
, O
so O
that O
there O
was O
no O
unseen O
label O
type O
in O
the O
target O
domain O
. O

Recently O
, O
based O
on O
the O
framework O
proposed O
by O
Bapna O
et O
al O
. O
( O
2017 O
) O
( O
discussed O
in O
Section O
1 O
) O
, O
Lee O
and O
Jha O
( O
2019 O
) O
added O
an O
attention O
layer O
to O
produce O
slot O
- O
aware O
representations O
, O
and O
Shah O
et O
al O
. O
( O
2019 O
) O
leveraged O
slot B-DatasetName
examples E-DatasetName
to O
increase O
the O
robustness B-MetricName
of M-MetricName
cross M-MetricName
- M-MetricName
domain M-MetricName
slot M-MetricName
filling M-MetricName
adaptation E-MetricName
. O

Methodology O

Coach B-MethodName
Framework E-MethodName

As O
depicted O
in O
Figure O
2 O
, O
the O
slot B-TaskName
filling E-TaskName
process O
in O
our O
Coach B-MethodName
framework O
consists O
of O
two O
steps O
. O

In O
the O
first O
step O
, O
we O
utilize O
a O
BiLSTM B-MethodName
- M-MethodName
CRF E-MethodName
structure O
( O
Lample O
et O
al O
. O
, O
2016 O
) O
to O
learn O
the O
general O
pattern O
of O
slot O
entities O
by O
having O
our O
model O
predict O
whether O
tokens O
are O
slot O
entities O
or O
not O
( O
i.e. O
, O
3 O
- O
way O
classification O
for O
each O
token O
) O
. O

In O
the O
second O
step O
, O
our O
model O
further O
predicts O
a O
specific O
type O
for O
each O
slot O
entity O
based O
on O
the O
similarities O
with O
the O
description O
representations O
of O
all O
possible O
slot O
types O
. O

To O
generate O
representations O
of O
slot O
entities O
, O
we O
leverage O
another O
encoder O
, O
BiLSTM B-MethodName
( O
Hochreiter O
and O
Schmidhuber O
, O
1997 O
) O
, O
to O
encode O
the O
hidden O
states O
of O
slot O
entity O
tokens O
and O
produce O
representations O
for O
each O
slot O
entity O
. O

We O
represent O
the O
user O
utterance O
with O
n O
tokens O
as O
w O
= O
[ O
w O
1 O
, O
w O
2 O
, O
... O
, O
w O
n O
] O
, O
and O
E O
denotes O
the O
embedding O
layer O
for O
utterances O
. O

The O
whole O
process O
can O
be O
formulated O
as O
follows O
: O
[ O
h O
1 O
, O
h O
2 O
, O
... O
, O
h O
n O
] O
= O
BiLSTM(E(w)),(1 B-MethodName
) O
[ O
p O
1 O
, O
p O
2 O
, O
... O
, O
p O
n O
] O
= O
CRF([h B-MethodName
1 O
, O
h O
2 O
, O
... O
, O
h O
n O
] O
) O
, O
( O
2 O
) O
where O
[ O
p O
1 O
, O
p O
2 O
, O
... O
, O
p O
n O
] O
are O
the O
logits O
for O
the O
3 O
- O
way O
classification O
. O

Then O
, O
for O
each O
slot O
entity O
, O
we O
take O
its O
hidden O
states O
to O
calculate O
its O
representation O
: O
r O
k O
= O
BiLSTM([h B-MethodName
i O
, O
h O
i+1 O
, O
... O
h O
j O
] O
) O
, O
( O
3 O
) O
s O
k O
= O
M O
desc O
Èà• O
r O
k O
, O
( O
4 O
) O
where O
r O
k O
denotes O
the O
representation O
of O
the O
k O
th O
slot O
entity O
, O
[ O
h O
i O
, O
h O
i+1 O
, O
... O
, O
h O
j O
] O
denotes O
the O
BiLSTM B-MethodName
hidden O
states O
for O
the O
k O
th O
slot O
entity O
, O
M O
desc O
Èà≠ O
R O
nsËÑ≥ds O
is O
the O
representation O
matrix O
of O
the O
slot O
description O
( O
n O
s O
is O
the O
number O
of O
possible O
slot O
types O
and O
d O
s O
is O
the O
dimension O
of O
slot O
descriptions O
) O
, O
and O
s O
k O
is O
the O
specific O
slot O
type O
prediction O
for O
this O
k O
th O
slot O
entity O
. O

We O
obtain O
the O
slot O
description O
representation O
r O
desc O
Èà≠ O
R O
ds O
by O
summing O
the O
embeddings O
of O
the O
N O
slot O
description O
tokens O
( O
similar O
to O
Shah O
et O
al O
. O
( O
2019 O
) O
): O
r O
desc O
= O
N O
i=1 O
E(t O
i O
) O
, O
( O
5 O
) O
where O
t O
i O
is O
the O
i O
th O
token O
and O
E O
is O
the O
same O
embedding O
layer O
as O
that O
for O
utterances O
. O

Template O
Regularization O

In O
many O
cases O
, O
similar O
or O
the O
same O
slot O
types O
in O
the O
target O
domain O
can O
also O
be O
found O
in O
the O
source O
domains O
. O

Nevertheless O
, O
it O
is O
still O
challenging O
for O
the O
model O
to O
recognize O
the O
slot O
types O
in O
the O
target O
domain O
owing O
to O
the O
variance O
between O
the O
source O
domains O
and O
the O
target O
domain O
. O

To O
improve O
the O
adaptation O
ability O
, O
we O
introduce O
a O
template B-MethodName
regularization E-MethodName
method O
. O

As O
shown O
in O
Figure O
2 O
, O
we O
first O
replace O
the O
slot O
entity O
tokens O
in O
the O
utterance O
with O
different B-DatasetName
slot M-DatasetName
labels E-DatasetName
to O
generate O
correct O
and O
incorrect O
utterance O
templates O
. O

Then O
, O
we O
use O
BiLSTM B-MethodName
and O
an O
attention O
layer O
( O
Felbo O
et O
al O
. O
, O
2017 O
) O
to O
generate O
the O
utterance O
and O
template O
representations O
: O
e O
t O
= O
h O
t O
w O
a O
, O
‰º™ O
t O
= O
exp(e O
t O
) O
n O
j=1 O
exp(e O
j O
) O
, O
R O
= O
n O
t=1 O
‰º™ O
t O
h O
t O
, O
( O
6 O
) O
where O
h O
t O
is O
the O
BiLSTM B-MethodName
hidden O
state O
in O
the O
t O
th O
step O
, O
w O
a O
is O
the O
weight O
vector O
in O
the O
attention O
layer O
and O
R O
is O
the O
representation O
for O
the O
input O
utterance O
or O
template O
. O

We O
minimize O
the O
regularization O
loss O
functions O
for O
the O
right O
and O
wrong O
templates O
, O
which O
can O
be O
formulated O
as O
follows O
: O
L O
r O
= O
MSE(R B-MetricName
u O
, O
R O
r O
) O
, O
( O
7 O
) O
L O
w O
= O
Èà≠Êç® O
ËÑ≥ O
MSE(R B-MetricName
u O
, O
R O
w O
) O
, O
( O
8) O
where O
R O
u O
is O
the O
representation O
for O
the O
user O
utterance O
, O
R O
r O
and O
R O
w O
are O
the O
representations O
of O
right O
and O
wrong O
templates O
, O
we O
set O
Â∞æ O
as O
one O
, O
and O
MSE B-MetricName
denotes O
mean B-MetricName
square M-MetricName
error E-MetricName
. O

Hence O
, O
in O
the O
training O
phase O
, O
we O
minimize O
the O
distance O
between O
R O
u O
and O
R O
r O
and O
maximize O
the O
distance O
between O
R O
u O
and O
R O
w O
. O

To O
generate O
a O
wrong O
template O
, O
we O
replace O
the O
correct O
slot O
entity O
with O
another O
random O
slot O
entity O
, O
and O
we O
generate O
two O
wrong O
templates O
for O
each O
utterance O
. O

To O
ensure O
the O
representations O
of O
the O
templates O
are O
meaningful O
( O
i.e. O
, O
similar O
templates O
have O
similar O
representations O
) O
for O
training O
R O
u O
, O
in O
the O
first O
several O
epochs O
, O
the O
regularization B-MetricName
loss E-MetricName
is O
only O
to O
optimize O
the O
template O
representations O
, O
and O
in O
the O
following O
epochs O
, O
we O
optimize O
both O
template O
representations O
and O
utterance O
representations O
. O

By O
doing O
so O
, O
the O
model O
learns O
to O
cluster O
the O
representations O
in O
the O
same O
or O
similar O
templates O
into O
a O
similar O
vector O
space O
. O

Hence O
, O
the O
hidden O
states O
of O
tokens O
that O
belong O
to O
the O
same O
slot O
type O
tend O
to O
be O
similar O
, O
which O
boosts O
the O
robustness B-MetricName
of O
these O
slot O
types O
in O
the O
target O
domain O
. O

Experiments O

Dataset O

We O
evaluate O
our O
framework O
on O
SNIPS B-DatasetName
( O
Coucke O
et O
al O
. O
, O
2018 O
) O
, O
a O
public O
spoken B-DatasetName
language M-DatasetName
understanding M-DatasetName
dataset E-DatasetName
which O
contains O
39 O
slot O
types O
across O
seven O
domains O
( O
intents O
) O
and O
Èà≠2000 O
training B-DatasetName
samples O
per O
domain O
. O

To O
test O
our O
framework O
, O
each O
time O
, O
we O
choose O
one O
domain O
as O
the O
target O
domain O
and O
the O
other O
six O
domains O
as O
the O
source O
domains O
. O
  O
Moreover O
, O
we O
also O
study O
another O
adaptation O
case O
where O
there O
is O
no O
unseen O
label O
in O
the O
target O
domain O
. O

We O
utilize O
the O
CoNLL-2003 O
English O
named B-DatasetName
entity M-DatasetName
recognition E-DatasetName
( O
NER B-DatasetName
) O
dataset O
as O
the O
source O
domain O
( O
Tjong O
Kim O
Sang O
and O
De O
Meulder O
, O
2003 O
) O
, O
and O
the O
CBS B-DatasetName
SciTech M-DatasetName
News M-DatasetName
NER M-DatasetName
dataset E-DatasetName
from O
Jia O
et O
al O
. O
( O
2019 O
) O
as O
the O
target O
domain O
. O

These O
two O
datasets O
have O
the O
same O
four O
types O
of O
entities O
, O
namely O
, O
PER O
( O
person O
) O
, O
LOC O
( O
location O
) O
, O
ORG O
( O
organization O
) O
, O
and O
MISC O
( O
miscellaneous O
) O
. O

Baselines O

We O
use O
word O
- O
level O
( O
Bojanowski O
et O
al O
. O
, O
2017 O
) O
and O
character O
- O
level O
( O
Hashimoto O
et O
al O
. O
, O
2017 O
) O
embeddings O
for O
our O
model O
as O
well O
as O
all O
the O
following O
baselines O
. O

Concept B-MethodName
Tagger E-MethodName
( O
CT B-MethodName
) O

Bapna O
et O
al O
. O
( O
2017 O
) O
proposed O
a O
slot B-MethodName
filling E-MethodName
framework O
that O
utilizes O
slot O
descriptions O
to O
cope O
with O
the O
unseen O
slot O
types O
in O
the O
target O
domain O
. O

Robust B-MethodName
Zero M-MethodName
- M-MethodName
shot M-MethodName
Tagger E-MethodName
( O
RZT B-MethodName
) O

Based O
on O
CT B-MethodName
, O
Shah O
et O
al O
. O
( O
2019 O
) O
leveraged O
example O
values O
of O
slots O
to O
improve O
robustness B-MetricName
of M-MetricName
cross M-MetricName
- M-MetricName
domain M-MetricName
adaptation E-MetricName
. O

BiLSTM B-MethodName
- O
CRF B-MethodName

This O
baseline O
is O
only O
for O
the O
cross O
- O
domain O
NER B-TaskName
. O

Since O
there O
is O
no O
unseen O
label O
in O
the O
NER B-TaskName
target O
domain O
, O
the O
BiLSTM B-MethodName
- O
CRF B-MethodName
( O
Lample O
et O
al O
. O
, O
2016 O
) O
uses O
the O
same O
label O
set O
for O
the O
source O
and O
target O
domains O
and O
casts O
it O
as O
an O
entity B-TaskName
classification E-TaskName
task O
for O
each O
token O
, O
which O
is O
applicable O
in O
both O
zero O
- O
shot O
and O
few O
- O
shot O
scenarios O
. O

Training O
Details O

We O
use O
a O
2 B-HyperparameterValue
- O
layer B-HyperparameterName
BiLSTM B-MethodName
with O
a O
hidden B-HyperparameterName
size E-HyperparameterName
of O
200 B-HyperparameterValue
and O
a O
dropout B-HyperparameterName
rate E-HyperparameterName
of O
0.3 B-HyperparameterValue
for O
both O
the O
template O
encoder O
and O
utterance O
encoder O
. O

Note O
that O
the O
parameters O
in O
these O
two O
encoders O
are O
not O
shared O
. O

The O
BiLSTM B-MethodName
for O
encoding O
the O
hidden B-HyperparameterName
states E-HyperparameterName
of O
entity O
tokens O
has O
one B-HyperparameterValue
layer B-HyperparameterName
with O
a O
hidden B-HyperparameterName
size E-HyperparameterName
of O
200 B-HyperparameterValue
, O
which O
would O
output O
the O
same O
dimension O
as O
the O
concatenated O
word O
- O
level O
and O
char O
- O
level O
embeddings O
. O

We O
use O
Adam B-MethodName
optimizer E-MethodName
with O
a O
learning B-HyperparameterName
rate E-HyperparameterName
of O
0.0005 B-HyperparameterValue
. O
Cross B-MetricName
- M-MetricName
entropy M-MetricName
loss E-MetricName
is O
leveraged O
to O
train O
the O
3 O
- O
way O
classification O
in O
the O
first O
step O
, O
and O
the O
specific O
slot O
type O
predictions O
are O
used O
in O
the O
second O
step O
. O

We O
split O
500 B-HyperparameterValue
data B-DatasetName
samples E-DatasetName
in O
the O
target O
domain O
as O
the O
validation B-DatasetName
set E-DatasetName
for O
choosing O
the O
best O
model O
and O
the O
remainder O
are O
used O
for O
the O
test B-DatasetName
set E-DatasetName
. O

We O
implement O
the O
model O
in O
CT B-MethodName
and O
RZT B-MethodName
and O
follow O
the O
same O
setting O
as O
for O
our O
model O
for O
a O
fair O
comparison O
. O

Results O
& O
Discussion O

Cross O
- O
domain O
Slot B-TaskName
Filling E-TaskName

Quantitative O
Analysis O

As O
illustrated O
in O
Table O
1 O
, O
we O
can O
clearly O
see O
that O
our O
models O
are O
able O
to O
achieve O
significantly O
better O
performance O
than O
the O
current O
state O
- O
of O
- O
the O
- O
art O
approach O
( O
RZT B-MethodName
) O
. O

The O
CT B-MethodName
framework O
suffers O
from O
the O
difficulty O
of O
capturing O
the O
whole O
slot O
entity O
, O
while O
our O
framework O
is O
able O
to O
recognize O
the O
slot O
entity O
tokens O
by O
sharing O
its O
parameters O
across O
all O
slot O
types O
. O

Based O
on O
the O
CT B-MethodName
framework O
, O
the O
performance O
of O
RZT B-MethodName
is O
still O
limited O
, O
and O
Coach B-MethodName
outperforms O
RZT B-MethodName
by O
a O
3 B-MetricValue
% E-MetricValue
F1 B-MetricName
- O
score O
in O
the O
zero O
- O
shot O
setting O
. O

Additionally O
, O
template O
regularization O
further O
improves O
the O
adaptation B-MetricName
robustness E-MetricName
by O
helping O
the O
model O
cluster O
the O
utterance O
representations O
into O
a O
similar O
vector O
space O
based O
on O
their O
corresponding O
template O
representations O
. O

Interestingly O
, O
our O
models O
achieve O
impressive O
performance O
in O
the O
few O
- O
shot O
scenario O
. O

In O
terms O
of O
the O
averaged O
performance O
, O
our O
best O
model O
( O
Coach+TR B-MethodName
) O
outperforms O
RZT B-MethodName
by O
8 B-MetricValue
% E-MetricValue
and O
9 B-MetricValue
% E-MetricValue
F1 B-MetricName
- O
scores O
on O
the O
20 O
- O
shot O
and O
50 O
- O
shot O
settings O
, O
respectively O
. O

We O
conjecture O
that O
our O
model O
is O
able O
to O
better O
recognize O
the O
whole O
slot O
entity O
in O
the O
target O
domain O
and O
map O
the O
representation O
of O
the O
slot O
entity O
belonging O
to O
the O
same O
slot O
type O
into O
a O
similar O
vector O
space O
  O
to O
the O
representation O
of O
this O
slot O
type O
based O
on O
Eq O
( O
4 O
) O
. O

This O
enables O
the O
model O
to O
quickly O
adapt O
to O
the O
target O
domain O
slots O
. O

Analysis O
on O
Seen O
and O
Unseen O
Slots O

We O
take O
a O
further O
step O
to O
test O
the O
models O
on O
seen O
and O
unseen O
slots O
in O
target O
domains O
to O
analyze O
the O
effectiveness O
of O
our O
approaches O
. O

To O
test O
the O
performance O
, O
we O
split O
the O
test B-DatasetName
set E-DatasetName
into O
" O
unseen O
" O
and O
" O
seen O
" O
parts O
. O

An O
utterance O
is O
categorized O
into O
the O
" O
unseen O
" O
part O
as O
long O
as O
there O
is O
an O
unseen O
slot O
( O
i.e. O
, O
the O
slot O
does O
not O
exist O
in O
the O
remaining O
six O
source O
domains O
) O
in O
it O
. O

Otherwise O
we O
categorize O
it O
into O
the O
" O
seen O
" O
part O
. O

The O
results O
for O
the O
" O
seen O
" O
and O
" O
unseen O
" O
categories O
are O
shown O
in O
Table O
2 O
. O

We O
observe O
that O
our O
approaches O
generally O
improve O
on O
both O
unseen O
and O
seen O
slot O
types O
compared O
to O
the O
baseline B-MethodName
models E-MethodName
. O

For O
the O
improvements O
in O
the O
unseen O
slots O
, O
our O
models O
are O
better O
able O
to O
capture O
the O
unseen O
slots O
since O
they O
explicitly O
learn O
the O
general O
pattern O
of O
slot O
entities O
. O

Interestingly O
, O
our O
models O
also O
bring O
large O
improvements O
in O
the O
seen O
slot O
types O
. O

We O
conjecture O
that O
it O
is O
also O
challenging O
to O
adapt O
models O
to O
seen O
slots O
due O
to O
the O
large O
variance O
between O
the O
source O
and O
target O
domains O
. O

For O
example O
, O
slot O
entities O
belonging O
to O
the O
" O
object O
type O
" O
in O
the O
" O
RateBook O
" O
domain O
are O
different O
from O
those O
in O
the O
" O
SearchCreativeWork O
" O
domain O
. O

Hence O
, O
the O
baseline B-MethodName
models E-MethodName
might O
fail O
to O
recognize O
these O
seen O
slots O
in O
the O
target O
domain O
, O
while O
our O
approaches O
can O
adapt O
to O
the O
seen O
slot O
types O
more O
quickly O
in O
comparison O
. O

In O
addition O
, O
we O
observe O
that O
template O
regularization O
improves O
performance O
in O
both O
seen O
and O
unseen O
slots O
, O
which O
illustrates O
that O
clustering O
representations O
based O
on O
templates O
can O
boost O
the O
adaptation O
ability O
. O

Cross O
- O
domain O
NER B-TaskName

From O
Table O
3 O
, O
we O
see O
that O
the O
Coach B-MethodName
framework O
is O
also O
suitable O
for O
the O
case O
where O
there O
are O
no O
unseen O
labels O
in O
the O
target O
domain O
in O
both O
the O
zero O
- O
shot O
and O
few O
- O
shot O
scenarios O
, O
while O
CT B-MethodName
and O
RZT B-MethodName
are O
not O
as O
effective O
as O
BiLSTM B-MethodName
- O
CRF B-MethodName
. O

However O
, O
we O
observe O
that O
template O
regularization O
loses O
its O
effectiveness O
in O
this O
task O
, O
since O
the O
text O
in O
NER B-TaskName
is O
relatively O
more O
open O
, O
which O
makes O
it O
hard O
to O
capture O
the O
templates O
for O
each O
label O
type O
. O

Ablation O
Study O

We O
conduct O
an O
ablation O
study O
in O
terms O
of O
the O
methods O
to O
encode O
the O
entity O
tokens O
( O
described O
in O
Eq O
. O
( O
3 O
) O
) O
to O
investigate O
how O
they O
affect O
the O
performance O
. O

Instead O
of O
using O
BiLSTM B-MethodName
, O
we O
try O
two O
alternatives O
. O

One O
is O
to O
use O
the O
encoder B-MethodName
of O
Transformer B-MethodName
( O
trs B-MethodName
) O
( O
Vaswani O
et O
al O
. O
, O
2017 O
) O
, O
and O
the O
other O
is O
to O
simply O
sum O
the O
hidden O
states O
of O
slot O
entity O
tokens O
. O

From O
Table O
4 O
, O
we O
can O
see O
that O
there O
is O
no O
significant O
performance O
difference O
among O
different O
methods O
, O
and O
we O
observe O
that O
using O
BiLSTM B-MethodName
to O
encode O
the O
entity O
tokens O
generally O
achieves O
better O
results O
. O

Conclusion O

We O
introduce O
a O
new O
cross O
slot B-MethodName
filling E-MethodName
framework O
to O
handle O
the O
unseen O
slot O
type O
issue O
. O

Our O
model O
shares O
its O
parameters O
across O
all O
slot O
types O
and O
learns O
to O
predict O
whether O
input O
tokens O
are O
slot O
entities O
or O
not O
. O

Then O
, O
it O
detects O
concrete O
slot O
types O
for O
these O
slot O
entity O
tokens O
based O
on O
the O
slot O
type O
descriptions O
. O

Moreover O
, O
template B-MethodName
regularization E-MethodName
is O
proposed O
to O
improve O
the O
adaptation B-MetricName
robustness E-MetricName
further O
. O

Experiments O
show O
that O
our O
model O
significantly O
outperforms O
existing O
cross O
- O
domain O
slot B-MethodName
filling E-MethodName
approaches O
, O
and O
it O
also O
achieves O
better O
performance O
for O
the O
cross O
- O
domain O
NER B-TaskName
task O
, O
where O
there O
is O
no O
unseen O
label O
type O
in O
the O
target O
domain O
. O

Acknowledgments O

This O
work O
is O
partially O
funded O
by O
ITF/319/16FP O
and O
MRP/055/18 O
of O
the O
Innovation O
Technology O
Commission O
, O
the O
Hong O
Kong O
SAR O
Government O
. O

Have O
my O
arguments O
been O
replied O
to O
? O
Argument B-TaskName
Pair M-TaskName
Extraction E-TaskName
as O
Machine B-TaskName
Reading M-TaskName
Comprehension E-TaskName

Argument B-TaskName
pair M-TaskName
extraction E-TaskName
( O
APE B-TaskName
) O
aims O
to O
automatically O
mine O
argument O
pairs O
from O
two B-DatasetName
interrelated M-DatasetName
argumentative M-DatasetName
documents E-DatasetName
. O

Existing O
studies O
typically O
identify O
argument O
pairs O
indirectly O
by O
predicting O
sentence O
- O
level O
relations O
between O
two B-DatasetName
documents E-DatasetName
, O
neglecting O
the O
modeling O
of O
the O
holistic O
argument O
- O
level O
interactions O
. O

Towards O
this O
issue O
, O
we O
propose O
to O
address O
APE B-TaskName
via O
a O
machine B-TaskName
reading M-TaskName
comprehension E-TaskName
( O
MRC B-TaskName
) O
framework O
with O
two O
phases O
. O

The O
first O
phase O
employs O
an O
argument B-TaskName
mining E-TaskName
( O
AM B-TaskName
) O
query O
to O
identify O
all O
arguments O
in O
two B-DatasetName
documents E-DatasetName
. O

The O
second O
phase O
considers O
each O
identified O
argument O
as O
an O
APE B-TaskName
query O
to O
extract O
its O
paired O
arguments O
from O
another B-DatasetName
document E-DatasetName
, O
allowing O
to O
better O
capture O
the O
argument O
- O
level O
interactions O
. O

Also O
, O
this O
framework O
enables O
these O
two O
phases O
to O
be O
jointly O
trained O
in O
a O
single O
MRC B-TaskName
model O
, O
thereby O
maximizing O
the O
mutual O
benefits O
of O
them O
. O

Experimental O
results O
demonstrate O
that O
our O
approach O
achieves O
the O
best O
performance O
, O
outperforming O
the O
state O
- O
of O
- O
the O
- O
art O
method O
by O
7.11 B-MetricValue
% E-MetricValue
in O
F B-MetricName
1 E-MetricName
score O
. O

Introduction O

As O
a O
salient O
part O
of O
argument B-TaskName
mining E-TaskName
( O
AM B-TaskName
) O
, O
the O
analysis O
of O
dialogical O
argumentation O
has O
received O
increasing O
research O
attention O
( O
Morio O
and O
Fujita O
, O
2018 O
Chakrabarty O
et O
al O
. O
, O
2019;Cheng O
et O
al O
. O
, O
2021;Yuan O
et O
al O
. O
, O
2021 O
) O
. O

Argument B-TaskName
pair M-TaskName
extraction E-TaskName
( O
APE B-TaskName
) O
, O
proposed O
by O
Cheng O
et O
al O
. O
( O
2020 O
) O
, O
is O
a O
new O
task O
within O
this O
field O
that O
focuses O
on O
extracting O
interactive O
argument O
pairs O
from O
two B-TaskName
interrelated M-TaskName
documents E-TaskName
( O
e.g. O
, O
peer O
reviewer O
and O
rebuttal O
) O
. O
Figure O
1 O
presents O
an O
example O
of O
APE B-TaskName
where O
two B-DatasetName
interrelated M-DatasetName
documents E-DatasetName
are O
segmented O
into O
arguments O
and O
non O
- O
arguments O
at O
sentence O
level O
. O

Two O
arguments O
from O
different O
documents O
that O
discuss O
the O
same O
issues O
are O
regarded O
as O
an O
argument O
pair O
. O

* O
Equal O
Contribution O

Corresponding O
Author O

s O
i O
j O
is O
the O
j O
- O
th O
sentence O
in O
document O
i O
, O
and O
arg O
i O
j O
is O
an O
argument O
in O
the O
j O
- O
th O
argument O
pair O
from O
document B-DatasetName
i. O
Sentences O
without O
colors O
indicate O
non O
- O
arguments O
, O
while O
sentences O
covered O
by O
colors O
can O
form O
arguments O
. O

Two O
arguments O
with O
the O
same O
color O
are O
regarded O
as O
an O
argument O
pair O
. O

Previous O
works O
( O
Cheng O
et O
al O
. O
, O
2020(Cheng O
et O
al O
. O
, O
, O
2021 O
commonly O
address O
APE B-TaskName
by O
decomposing O
it O
into O
two O
sentence O
- O
level O
subtasks O
, O
i.e. O
, O
a O
sequence B-TaskName
labeling M-TaskName
task E-TaskName
and O
a O
sentence O
relation O
classification O
task O
. O

These O
methods O
identify O
arguments O
by O
sentencelevel O
sequence O
labeling O
and O
determine O
whether O
two O
sentences O
belong O
to O
the O
same O
argument O
pair O
by O
sentence O
relation O
classification O
. O

Afterwards O
, O
the O
argument O
pairs O
are O
inferred O
indirectly O
by O
certain O
rules O
combining O
the O
results O
of O
the O
two O
subtasks O
. O

However O
, O
such O
a O
paradigm O
only O
considers O
sentencelevel O
relations O
, O
while O
the O
holistic O
argument O
- O
level O
relations O
can O
not O
be O
well O
modeled O
. O

In O
this O
paper O
, O
we O
argue O
that O
APE B-TaskName
can O
be O
considered O
as O
a O
multi O
- O
turn O
machine B-TaskName
reading M-TaskName
comprehension E-TaskName
( O
MRC B-TaskName
) O
task O
with O
two O
phases O
, O
i.e. O
, O
an O
AM B-TaskName
phase O
and O
an O
APE B-TaskName
phase O
. O

Specifically O
, O
in O
the O
first O
turn O
, O
a O
special O
AM B-TaskName
query O
is O
employed O
to O
identify O
all O
the O
arguments O
in O
the O
first O
document O
( O
AM B-TaskName
phase O
) O
. O

Afterwards O
, O
in O
each O
subsequent O
turn O
, O
every O
identified O
argument O
is O
treated O
as O
an O
APE O
query O
to O
extract O
its O
paired O
arguments O
from O
the O
second B-DatasetName
document E-DatasetName
( O
APE B-TaskName
phase O
) O
. O

Similarly O
, O
this O
process O
can O
also O
be O
performed O
in O
another O
direction O
, O
that O
is O
, O
using O
the O
arguments O
identified O
in O
the O
second B-DatasetName
document E-DatasetName
as O
queries O
to O
extract O
the O
paired O
arguments O
from O
the O
first B-DatasetName
document E-DatasetName
. O

We O
train O
these O
two O
phases O
jointly O
in O
a O
single O
MRC B-MethodName
model E-MethodName
, O
allowing O
them O
to O
benefit O
each O
other O
. O

By O
considering O
arguments O
as O
queries O
, O
our O
proposed O
MRC B-MethodName
framework E-MethodName
can O
better O
capture O
the O
interactions O
between O
each O
query O
argument O
and O
the O
queried O
document O
, O
thus O
extracting O
the O
argument O
pairs O
at O
the O
argument O
level O
. O

In O
addition O
, O
considering O
the O
long O
length O
of O
the O
documents B-DatasetName
, O
we O
utilize O
Longformer B-MethodName
( O
Beltagy O
et O
al O
. O
, O
2020 O
) O
to O
model O
longer O
contexts O
. O

We O
evaluate O
our O
method O
on O
the O
large O
benchmark B-DatasetName
dataset E-DatasetName
( O
Cheng O
et O
al O
. O
, O
2020 O
) O
. O

Results O
show O
that O
our O
proposed O
method O
significantly O
outperforms O
the O
current O
state O
- O
of O
- O
the O
- O
art O
method O
by O
7.11 B-MetricValue
% E-MetricValue
in O
F B-MetricName
1 E-MetricName
score O
. O

Related O
Work O

Argument B-TaskName
Mining E-TaskName

Argument B-TaskName
mining E-TaskName
aims O
to O
analyze O
the O
structure O
of O
argumentation O
, O
and O
it O
contains O
various O
subtasks O
, O
such O
as O
argument B-TaskName
component M-TaskName
identification E-TaskName
( O
Moens O
et O
al O
. O
, O
2007;Goudas O
et O
al O
. O
, O
2015;Ajjour O
et O
al O
. O
, O
2017;Jo O
et O
al O
. O
, O
2019 O
) O
, O
argument B-TaskName
relation M-TaskName
prediction E-TaskName
( O
Nguyen O
and O
Litman O
, O
2016;Cocarascu O
et O
al O
. O
, O
2020;Jo O
et O
al O
. O
, O
2021 O
) O
, O
argumentation B-TaskName
structure M-TaskName
parsing E-TaskName
( O
Stab O
and O
Gurevych O
, O
2017;Kuribayashi O
et O
al O
. O
, O
2019;Morio O
et O
al O
. O
, O
2020;Bao O
et O
al O
. O
, O
2021 O
) O
, O
argumentation B-TaskName
strategy M-TaskName
analysis E-TaskName
( O
Khatib O
et O
al O
. O
, O
2018;Morio O
et O
al O
. O
, O
2019 O
) O
, O
etc O
. O

Most O
previous O
works O
mainly O
focus O
on O
monological O
argumentation O
, O
while O
dialogical O
argumentation O
( O
Morio O
and O
Fujita O
, O
2018;Chakrabarty O
et O
al O
. O
, O
2019 O
) O
is O
relatively O
less O
emphasized O
. O

Recently O
, O
the O
analysis O
of O
dialogical O
argumentation O
has O
attracted O
increasing O
attention O
in O
the O
field O
of O
argument B-TaskName
mining E-TaskName
. O

Cheng O
et O
al O
. O
( O
2020 O
) O
propose O
the O
APE B-TaskName
task E-TaskName
which O
involves O
identifying O
arguments O
and O
extracting O
argument O
pairs O
in O
peer O
review O
and O
rebuttal O
. O

Ji O
et O
al O
. O
( O
2021 O
) O
identify O
interactive O
argument O
pairs O
in O
online O
debate O
forums O
based O
on O
the O
discrete O
variational O
autoencoders O
. O

Cheng O
et O
al O
. O
( O
2021 O
) O
address O
the O
APE B-TaskName
task E-TaskName
based O
on O
a O
table B-MethodName
- M-MethodName
filling M-MethodName
approach E-MethodName
. O

Yuan O
et O
al O
. O
( O
2021 O
) O
construct O
a O
dialogical O
argumentation O
knowledge O
graph O
for O
identifying O
argument O
pairs O
. O

Machine B-TaskName
Reading M-TaskName
Comprehension E-TaskName

Machine B-TaskName
reading M-TaskName
comprehension E-TaskName
( O
MRC B-TaskName
) O
aims O
to O
extract O
answer O
spans O
from O
a O
passage O
according O
to O
a O
given O
query O
Devlin O
et O
al O
. O
, O
2019 O
; O
Wen O
et O
al O
. O
, O
2021 O
) O
. O

Formulating O
NLP B-TaskName
tasks E-TaskName
as O
MRC B-TaskName
tasks E-TaskName
has O
been O
a O
rising O
trend O
in O
recent O
years O
, O
such O
as O
dependency O
parsing O
( O
Gan O
et O
al O
. O
, O
2021 O
) O
, O
relation O
extraction O
( O
Levy O
et O
al O
. O
, O
2017 O
) O
, O
named O
entity O
recognition O
( O
Li O
et O
al O
. O
, O
2020 O
) O
, O
sentiment O
analysis O
( O
Chen O
et O
al O
. O
, O
2021 O
; O
Mao O
et O
al O
. O
, O
2021 O
) O
. O

Unlike O
previous O
studies O
above O
, O
we O
employ O
a O
MRC B-MethodName
framework E-MethodName
to O
analyze O
the O
complex O
argumentative O
relations O
between O
two O
documents O
with O
excessively O
long O
length O
. O

Methodology O

Task O
Formulation O

We O
assume O
that O
two B-DatasetName
interrelated M-DatasetName
documents E-DatasetName
D O
a O
= O
( O
s O
a O
1 O
, O
s O
a O
2 O
, O
... O
, O
s O
a O
n O
a O
) O
and O
D O
b O
= O
( O
s O
b O
1 O
, O
s O
b O
2 O
, O
... O
, O
s O
b O
n O
b O
) O
are O
given O
, O
where O
s O
i O
j O
denotes O
the O
j O
- O
th O
sentence O
in O
document O
i O
. O

We O
need O
to O
extract O
the O
collection O
of O
argument O
pairs O
P O
= O
{ O
( O
arg O
a O
i O
, O
arg O
b O
i O
) O
} O
|P O
| O
i=1 O
, O
where O
arg O
a O
i O
and O
arg O
b O
i O
respectively O
represent O
the O
arguments O
in O
document B-DatasetName
D O
a O
and O
D O
b O
, O
and O
they O
compose O
the O
i O
- O
th O
argument O
pair O
. O

Note O
that O
each O
argument O
consists O
of O
one O
or O
more O
consecutive O
sentences O
. O

For O
example O
, O
arg O
a O
i O
= O
( O
s O
a O
, O
i O
start O
, O
s O
a O
, O
i O
start+1 O
, O
... O
, O
s O
a O
, O
i O
end O
) O
where O
start O
and O
end O
denote O
the O
start O
and O
end O
sentence O
index O
. O

To O
frame O
APE B-TaskName
as O
a O
multi O
- O
turn O
MRC B-TaskName
task E-TaskName
, O
two O
types O
of O
queries O
are O
constructed O
, O
i.e. O
, O
the O
argument B-TaskName
mining E-TaskName
( O
AM B-TaskName
) O
query O
and O
the O
argument B-TaskName
pair M-TaskName
extraction E-TaskName
( O
APE B-TaskName
) O
query O
. O

Intuitively O
, O
we O
could O
consider O
the O
process O
of O
extracting O
argument O
pairs O
from O
the O
perspective O
of O
two O
directions O
, O
i.e. O
, O
D O
a O
Èà´ O
D O
b O
and O
D O
b O
D O
a O
. O

For O
the O
D O
a O
Èà´ O
D O
b O
direction O
, O
we O
first O
construct O
an O
AM B-TaskName
query O
using O
a O
special O
token O
whose O
corresponding O
answers O
are O
all O
the O
arguments O
in O
document B-DatasetName
D O
a O
. O

After O
recognizing O
all O
arguments O
through O
the O
AM B-TaskName
query O
, O
each O
recognized O
argument O
is O
considered O
as O
an O
APE B-TaskName
query O
whose O
corresponding O
answers O
are O
its O
paired O
arguments O
in O
document O
D O
b O
. O

Similarly O
, O
for O
the O
D O
b O
Èà´ O
D O
a O
direction O
, O
we O
first O
query O
document B-DatasetName
D O
b O
with O
the O
AM B-TaskName
query O
, O
and O
then O
generate O
the O
APE B-TaskName
queries O
for O
document B-DatasetName
D O
a O
. O

Finally O
, O
the O
argument O
pairs O
can O
be O
derived O
by O
fusing O
the O
answer O
results O
of O
all O
APE B-TaskName
queries O
. O

MRC B-MethodName
Framework E-MethodName

Encoder B-TaskName

Since O
APE B-TaskName
is O
a O
document O
- O
level O
task O
with O
excessively O
long O
text O
, O
we O
adopt O
Longformer B-MethodName
to O
capture O
contextual O
information O
over O
longer O
distances O
. O

For O
brevity O
, O
we O
only O
describe O
the O
MRC B-TaskName
process O
in O
the O
D O
a O
Èà´ O
D O
b O
direction O
below O
, O
and O
the O
D O
b O
Èà´ O
D O
a O
direction O
can O
be O
performed O
similarly O
. O

With O
these O
queries O
, O
we O
first O
concatenate O
the O
AM B-TaskName
query O
q O
am B-TaskName
and O
the O
document B-DatasetName
D O
a O
as O
an O
input O
sequence O
for O
AM B-TaskName
: O
I O
am B-TaskName
= O
( O
[ O
s O
] O
, O
q O
am O
, O
[ O
/s O
] O
, O
[ O
s O
] O
, O
s O
a O
1 O
, O
s O
a O
2 O
, O
... O
, O
s O
a O
n O
a O
, O
[ O
/s])(1 O
) O
Also O
, O
we O
concatenate O
each O
APE B-TaskName
query O
q O
a O
, O
ape B-TaskName
k O
and O
the O
document B-DatasetName
D O
b O
to O
obtain O
multiple O
input O
sequences O
for O
APE B-TaskName
: O
Subsequently O
, O
for O
each O
sequence O
above O
, O
we O
feed O
it O
into O
Longformer B-MethodName
to O
get O
the O
hidden O
representation O
of O
each O
token O
in O
the O
input B-DatasetName
document E-DatasetName
. O

Specifically O
, O
to O
enable O
Longformer B-MethodName
to O
better O
learn O
argument O
specific O
representations O
, O
we O
add O
global O
attention O
to O
the O
tokens O
of O
the O
query O
. O

Afterwards O
, O
we O
derive O
the O
hidden O
representation O
of O
each O
sentence O
through O
mean O
pooling O
on O
token O
representations O
in O
this O
sentence O
. O

Further O
, O
to O
better O
model O
the O
longterm O
dependency O
among O
sentences O
, O
the O
hidden O
representations O
of O
sentences O
are O
fed O
into O
LSTM B-MethodName
to O
derive O
the O
contextual O
sentence O
representation O
matrix O
H O
= O
( O
h O
1 O
, O
h O
2 O
, O
. O
. O
. O
, O
h O
n O
) O
. O
I O
ape O
k O
= O
( O
[ O
s O
] O
, O
q O
a O
, O
ape O
k O
, O
[ O
/s O
] O
, O
[ O
s O
] O
, O
s O
b O
1 O
, O
s O
b O
2 O
, O
... O
, O
s O
b O
n O
b O
, O
[ O
/s])(2 O

Answer O
Span O
Prediction O

For O
each O
turn O
, O
one O
or O
more O
answer O
spans O
will O
be O
extracted O
as O
arguments O
. O

Note O
that O
, O
in O
each O
direction O
, O
the O
first O
turn O
aims O
to O
extract O
all O
arguments O
, O
while O
the O
following O
turns O
aim O
to O
extract O
arguments O
that O
can O
form O
pairs O
with O
the O
query O
argument O
. O

Specifically O
, O
inspired O
by O
Li O
et O
al O
. O
( O
2020 O
) O
, O
we O
fed O
H O
into O
two O
binary O
classifiers O
to O
predict O
the O
start O
and O
end O
sentence O
positions O
of O
arguments O
. O

After O
obtaining O
all O
start O
and O
end O
positions O
, O
we O
further O
employ O
another O
binary O
classifier O
to O
determine O
whether O
each O
start O
and O
end O
position O
pair O
( O
matched O
by O
Cartesian O
product O
) O
forms O
an O
answer O
span O
. O

Note O
that O
the O
input O
of O
this O
span O
classifier O
is O
the O
concatenation O
of O
the O
start O
and O
end O
sentence O
representations O
from O
H. O

Training O

During O
training O
, O
the O
three O
classifiers O
described O
in O
Section O
3.2.2 O
yield O
three O
cross B-MetricName
- M-MetricName
entropy M-MetricName
losses E-MetricName
, O
i.e. O
, O
a O
start O
loss O
, O
an O
end O
loss O
, O
and O
a O
span O
loss O
. O

We O
simply O
sum O
these O
losses O
up O
as O
the O
training O
objective O
of O
our O
model O
. O

In O
addition O
, O
the O
AM B-TaskName
phrase O
and O
the O
APE B-TaskName
phrase O
are O
trained O
jointly O
in O
a O
single O
MRC B-MethodName
model E-MethodName
. O

Inference O

During O
inference O
, O
the O
D O
a O
Èà´ O
D O
b O
direction O
uses O
the O
trained O
MRC B-MethodName
model E-MethodName
to O
first O
identify O
all O
the O
arguments O
in O
D O
a O
by O
the O
AM B-TaskName
query O
and O
then O
extract O
all O
the O
argument O
pairs O
in O
D O
b O
by O
the O
APE B-TaskName
queries O
. O

Similarly O
, O
the O
D O
b O
Èà´ O
D O
a O
direction O
can O
be O
performed O
in O
the O
same O
manner O
by O
simply O
exchanging O
the O
order O
of O
D O
a O
and O
D O
b O
. O

Each O
APE B-TaskName
query O
in O
both O
directions O
yields O
one O
or O
more O
argument O
pairs O
, O
where O
each O
argument O
pair O
contains O
the O
query O
argument O
and O
one O
extracted O
argument O
. O

We O
simply O
merge O
all O
argument O
pairs O
extracted O
by O
all O
APE B-TaskName
queries O
into O
a O
union O
set O
to O
obtain O
the O
final O
inference O
results O
. O

Experiments O

Experimental O
setup O

Dataset O

Our O
experiments O
are O
conducted O
on O
the O
large O
APE B-TaskName
benchmark M-TaskName
dataset E-TaskName
, O
namely O
the O
Review B-TaskName
- M-TaskName
Rebuttal E-TaskName
( O
RR B-TaskName
) O
dataset O
( O
Cheng O
et O
al O
. O
, O
2020 O
) O
, O
which O
contains O
4,764 O
pairs O
of O
review O
- O
rebuttal O
passages O
of O
ICLR O
. O

Following O
the O
setup O
of O
( O
Cheng O
et O
al O
. O
, O
2021 O
) O
, O
we O
also O
evaluate O
our O
method O
on O
two O
versions O
of O
the O
train B-DatasetName
/ M-DatasetName
dev M-DatasetName
/ M-DatasetName
test E-DatasetName
( O
8:01:01 O
) O
split O
, O
i.e. O
, O
RR B-DatasetName
- M-DatasetName
Passage M-DatasetName
- M-DatasetName
v1 E-DatasetName
and O
RR B-DatasetName
- M-DatasetName
Submission M-DatasetName
- M-DatasetName
v2 E-DatasetName
. O

Note O
that O
in O
our O
method O
, O
we O
view O
review O
passage O
and O
rebuttal O
passage O
as O
document B-DatasetName
D O
a O
and O
document B-DatasetName
D O
b O
, O
respectively O
. O

Implementation O
Details O

We O
adopt O
Longformer B-MethodName
- O
base-4096 B-HyperparameterValue
1 O
as O
base O
encoder O
, O
and O
we O
use O
sliding O
window O
attention O
with O
the O
window B-HyperparameterName
size E-HyperparameterName
of O
512 B-HyperparameterValue
. O

We O
train O
our O
model O
6 B-MetricValue
epochs E-MetricValue
with O
a O
batch B-HyperparameterName
size E-HyperparameterName
of O
4 B-HyperparameterValue
. O

AdamW B-MethodName
( O
Kingma O
and O
Ba O
, O
2015 O
) O
is O
used O
as O
the O
optimizer O
, O
and O
the O
learning B-HyperparameterName
rates E-HyperparameterName
for O
Longformer B-MethodName
and O
other O
layers O
are O
1.00E-05 B-HyperparameterValue
and O
1.00E-03 B-HyperparameterValue
. O
2 O

The O
evaluation O
metrics O
contain O
two O
aspects O
, O
namely O
AM B-TaskName
and O
APE B-TaskName
. O

Different O
from O
( O
Cheng O
et O
al O
. O
, O
2021(Cheng O
et O
al O
. O
, O
, O
2020 O
, O
sentence B-TaskName
pairing E-TaskName
is O
not O
included O
as O
a O
metric O
because O
we O
extract O
argument O
pairs O
directly O
. O

We O
select O
the O
best O
parameters O
based O
on O
the O
performance O
( O
i.e. O
, O
average O
F B-MetricName
1 E-MetricName
scores O
of O
AM B-TaskName
and O
APE B-TaskName
) O
on O
the O
dev B-DatasetName
set E-DatasetName
. O

All O
scores O
are O
averaged O
across O
5 O
distinct O
trials O
using O
different O
random O
seeds O
. O

Baselines O

We O
compare O
our O
model O
with O
several O
baselines O
. O

PL B-MethodName
- M-MethodName
H M-MethodName
- M-MethodName
LSTM M-MethodName
- M-MethodName
CRF E-MethodName
( O
Cheng O
et O
al O
. O
, O
2020 O
) O
independently O
trains O
an O
argument B-TaskName
mining M-TaskName
task E-TaskName
and O
a O
sentence B-TaskName
pairing M-TaskName
task E-TaskName
, O
while O
MT B-MethodName
- M-MethodName
H M-MethodName
- M-MethodName
LSTM M-MethodName
- M-MethodName
CRF E-MethodName
( O
Cheng O
et O
al O
. O
, O
2020 O
) O
trains O
two O
subtasks O
in O
a O
multi O
- O
task O
framework O
. O

MLMC B-MethodName
( O
Cheng O
et O
al O
. O
, O
2021 O
) O
is O
an O
attentionguided O
model O
based O
on O
a O
table B-MethodName
- M-MethodName
filling M-MethodName
approach E-MethodName
, O
which O
is O
the O
current O
state O
- O
of O
- O
the O
- O
art O
method O
. O

Furthermore O
, O
we O
implement O
two O
additional O
baselines O
. O

Results O
and O
Analysis O

Main O
Results O

As O
shown O
in O
Table O
1 O
, O
our O
model O
achieves O
the O
best O
performance O
on O
both O
versions O
of O
the O
RR B-DatasetName
dataset E-DatasetName
. O

Concretely O
, O
on O
RR B-DatasetName
- M-DatasetName
Submission M-DatasetName
- M-DatasetName
v2 E-DatasetName
, O
our O
model O
significantly O
outperforms O
the O
current O
state O
- O
of O
- O
the O
- O
art O
model O
MLMC B-MethodName
by O
at O
least O
7.11 B-MetricValue
% E-MetricValue
in O
APE B-TaskName
F B-MetricName
1 E-MetricName
score O
. O

On O
RR B-DatasetName
- M-DatasetName
Passage M-DatasetName
- M-DatasetName
v1 M-DatasetName
, E-DatasetName
our O
model O
obtains O
at O
least O
a O
6.54 B-MetricValue
% E-MetricValue
higher O
APE B-TaskName
F B-MetricName
1 E-MetricName
score O
than O
the O
MLMC B-MethodName
. O

Also O
, O
our O
model O
achieves O
the O
best O
performance O
on O
AM B-TaskName
. O

Furthermore O
, O
without O
applying O
Longformer B-MethodName
as O
the O
base O
encoder O
, O
MRC B-MethodName
- M-MethodName
APE M-MethodName
- M-MethodName
Bert E-MethodName
still O
outperforms O
MLMC O
in O
APE B-TaskName
F B-MetricName
1 E-MetricName
score O
, O
demonstrating O
that O
our O
improvement O
is O
not O
only O
brought O
by O
Longformer B-MethodName
. O

However O
, O
for O
the O
AM B-TaskName
task O
, O
MAC B-MethodName
- M-MethodName
APE M-MethodName
- M-MethodName
Bert E-MethodName
  O
achieves O
slightly O
lower O
F B-MetricName
1 E-MetricName
score O
than O
MLMC B-MethodName
. O

The O
reason O
may O
be O
that O
, O
in O
MLMC B-MethodName
, O
the O
predictions O
of O
the O
AM B-TaskName
task O
are O
influenced O
by O
the O
APE B-TaskName
task O
through O
a O
complex O
attention O
interaction O
mechanism O
. O

However O
, O
our O
model O
does O
not O
require O
such O
a O
complex O
design O
and O
can O
achieve O
much O
better O
results O
on O
the O
APE B-TaskName
task O
. O

Besides O
, O
our O
MRC B-MethodName
- M-MethodName
APE E-MethodName
achieves O
better O
results O
than O
MRC B-MethodName
- M-MethodName
APE M-MethodName
- M-MethodName
Sep. E-MethodName
on O
both O
AM B-TaskName
and O
APE B-TaskName
tasks O
, O
indicating O
that O
jointly O
training O
two O
phases O
in O
a O
single O
MRC B-MethodName
model E-MethodName
could O
maximize O
the O
mutual O
benefits O
of O
the O
two O
phases O
. O

In O
addition O
, O
to O
analyze O
the O
error O
propagation O
from O
the O
first O
phase O
to O
the O
second O
phase O
, O
we O
use O
the O
TRUE O
label O
of O
AM B-TaskName
task O
to O
predict O
APE B-TaskName
task O
. O

Under O
this O
setting O
, O
our O
model O
can O
achieve O
around O
59.44 B-MetricValue
% E-MetricValue
F B-MetricName
1 E-MetricName
score O
for O
APE B-TaskName
task O
, O
showing O
effectiveness O
in O
identifying O
argument O
pairs O
. O

Ablation O
Study O

The O
ablation O
study O
results O
are O
shown O
in O
Table O
2 O
. O

It O
can O
be O
observed O
that O
using O
two O
directions O
contributes O
greatly O
to O
our O
method O
. O

Also O
, O
using O
the O
arguments O
recognized O
in O
D O
a O
to O
extract O
the O
paired O
arguments O
in O
D O
b O
is O
more O
critical O
in O
the O
RR B-DatasetName
dataset E-DatasetName
, O
removing O
it O
causes O
a O
6.51 B-MetricValue
% E-MetricValue
decrease O
in O
APE B-TaskName
F B-MetricName
1 E-MetricName
score O
. O

Without O
the O
LSTM B-MethodName
to O
capture O
the O
long O
- O
term O
dependency O
among O
sentences O
, O
the O
APE B-TaskName
F B-MetricName
1 E-MetricName
score O
decreases O
by O
0.86 B-MetricValue
% E-MetricValue
. O

Furthermore O
, O
the O
performance O
drops O
heavily O
without O
the O
global O
attention O
, O
because O
it O
enables O
more O
interactions O
between O
the O
query O
argument O
and O
the O
queried O
document O
, O
thus O
better O
argument O
- O
specific O
representations O
could O
be O
learned O
. O

Conclusion O

In O
this O
paper O
, O
we O
propose O
to O
frame O
the O
argument B-TaskName
pair M-TaskName
extraction E-TaskName
( O
APE B-TaskName
task O
as O
a O
machine B-TaskName
reading M-TaskName
comprehension E-TaskName
( O
MRC B-TaskName
) O
task O
. O

Our B-MethodName
MRC M-MethodName
framework E-MethodName
addresses O
APE B-TaskName
through O
two O
phases O
with O
two O
types O
of O
queries O
, O
that O
is O
, O
argument B-TaskName
mining E-TaskName
( O
AM B-TaskName
) O
query O
and O
argument B-TaskName
pair M-TaskName
extraction E-TaskName
( O
APE B-TaskName
) O
query O
. O

Our O
proposed O
method O
can O
better O
model O
the O
argumentlevel O
interactions O
, O
thus O
facilitating O
the O
extraction O
of O
argument O
pairs O
. O

Experimental O
results O
on O
a O
large O
benchmark B-DatasetName
dataset E-DatasetName
demonstrate O
that O
our O
proposed O
method O
achieves O
state O
- O
of O
- O
the O
- O
art O
performance O
. O

Acknowledgments O

This O
work O
was O
partially O
supported O
by O
the O
National O
Natural O
Science O
Foundation O
of O
China O
( O
61876053 O
, O
62006062 O
, O
62176076 O
) O
, O
the O
Shenzhen O
Foundational O
Research O
Funding O
( O
JCYJ20200109113441941 O
, O
JCYJ20210324115614039 O
) O
, O
Joint O
Lab O
of O
HITSZ O
and O
China O
Merchants O
Securities O
. O

The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
iterations -X- _ I-HyperparameterName
for -X- _ O
DAU-AM -X- _ B-MethodName
and -X- _ O
DAU-PTM -X- _ B-MethodName
was -X- _ O
1,000. -X- _ B-HyperparameterValue

Compared -X- _ O
to -X- _ O
textual -X- _ O
media, -X- _ O
which -X- _ O
allows -X- _ O
readers -X- _ O
to -X- _ O
read -X- _ O
at -X- _ O
their -X- _ O
own -X- _ O
pace, -X- _ O
dialogue-based -X- _ O
media -X- _ O
does -X- _ O
not -X- _ O
allow -X- _ O
users -X- _ O
to -X- _ O
skip -X- _ O
unnecessary -X- _ O
information -X- _ O
or -X- _ O
skim -X- _ O
necessary -X- _ O
information -X- _ O
while -X- _ O
listening. -X- _ O

When -X- _ O
Œ≤ -X- _ B-HyperparameterName
= -X- _ O
2, -X- _ B-HyperparameterValue
the -X- _ O
exclusion -X- _ O
rate -X- _ O
is -X- _ O
twice -X- _ O
as -X- _ O
important -X- _ O
as -X- _ O
the -X- _ O
coverage. -X- _ O

Figure -X- _ O
3: -X- _ O
Processing -X- _ O
time -X- _ O
for -X- _ O
each -X- _ O
number -X- _ O
of -X- _ O
sentences -X- _ O
(N -X- _ B-HyperparameterName
= -X- _ O
3, -X- _ B-HyperparameterValue
T0 -X- _ B-HyperparameterName
= -X- _ O
270) -X- _ B-HyperparameterValue

However, -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
EoIT, -X- _ B-MetricName
DAU-PTM -X- _ B-MethodName
was -X- _ O
higher -X- _ O
than -X- _ O
DAU-AM. -X- _ B-MethodName

We -X- _ O
used -X- _ O
EoITŒ≤ -X- _ B-MetricName
(efficiency -X- _ B-MetricName
of -X- _ I-MetricName
information -X- _ I-MetricName
transmission) -X- _ I-MetricName
(Takatsu -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
as -X- _ O
the -X- _ O
evaluation -X- _ O
metric. -X- _ O

The -X- _ O
number -X- _ O
of -X- _ O
replicas -X- _ O
in -X- _ O
DAU-PTM -X- _ B-MethodName
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
runs -X- _ O
of -X- _ O
annealing -X- _ O
in -X- _ O
DAU-AM -X- _ B-MethodName
were -X- _ O
128. -X- _ B-HyperparameterValue

It -X- _ O
can -X- _ O
handle -X- _ O
up -X- _ O
to -X- _ O
4,096 -X- _ O
binary -X- _ O
variables -X- _ O
with -X- _ O
64-bit -X- _ O
precision -X- _ O
or -X- _ O
as -X- _ O
many -X- _ O
as -X- _ O
8,192 -X- _ O
binary -X- _ O
variables -X- _ O
with -X- _ O
16-bit -X- _ O
precision. -X- _ O

A -X- _ O
soft -X- _ O
chunk -X- _ O
occurs -X- _ O
when -X- _ O
the -X- _ O
child -X- _ O
sentence -X- _ O
is -X- _ O
useful -X- _ O
to -X- _ O
prevent -X- _ O
a -X- _ O
biased -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
parent -X- _ O
sentence, -X- _ O
although -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
necessarily -X- _ O
contain -X- _ O
essential -X- _ O
information -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
parent -X- _ O
sentence -X- _ O
itself. -X- _ O

We -X- _ O
defined -X- _ O
the -X- _ O
following -X- _ O
as -X- _ O
discourse -X- _ O
relations: -X- _ O
Start, -X- _ O
Result, -X- _ O
Cause, -X- _ O
Background, -X- _ O
Correspondence, -X- _ O
Contrast, -X- _ O
Topic -X- _ O
Change, -X- _ O
Example, -X- _ O
Conclusion, -X- _ O
and -X- _ O
Supplement. -X- _ O

A -X- _ O
discourse -X- _ O
relation -X- _ O
classifies -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
semantic -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
child -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
parent -X- _ O
sentence. -X- _ O

In -X- _ O
each -X- _ O
genre, -X- _ O
we -X- _ O
manually -X- _ O
selected -X- _ O
200 -X- _ O
articles -X- _ O
to -X- _ O
minimize -X- _ O
topic -X- _ O
overlap. -X- _ O

To -X- _ O
achieve -X- _ O
both -X- _ O
personalization -X- _ O
and -X- _ O
coherence -X- _ O
simultaneously, -X- _ O
we -X- _ O
propose -X- _ O
ILP -X- _ B-MethodName
and -X- _ O
QUBO -X- _ B-MethodName
models -X- _ O
to -X- _ O
extract -X- _ O
sentences -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
user‚Äôs -X- _ O
interest -X- _ O
and -X- _ O
generate -X- _ O
a -X- _ O
personalized -X- _ O
summary -X- _ O
for -X- _ O
each -X- _ O
user -X- _ O
while -X- _ O
maintaining -X- _ O
coherence -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
discourse -X- _ O
structure. -X- _ O

Yang -X- _ O
and -X- _ O
Li -X- _ O
(2018) -X- _ O
proposed -X- _ O
a -X- _ O
method -X- _ O
to -X- _ O
manually -X- _ O
annotate -X- _ O
the -X- _ O
dependency -X- _ O
structure -X- _ O
and -X- _ O
discourse -X- _ O
relations -X- _ O
between -X- _ O
elementary -X- _ O
discourse -X- _ O
units -X- _ O
for -X- _ O
abstracts -X- _ O
of -X- _ O
scientific -X- _ O
papers, -X- _ O
and -X- _ O
then -X- _ O
constructed -X- _ O
SciDTB. -X- _ B-DatasetName

RST -X- _ B-DatasetName
Discourse -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
constructed -X- _ O
based -X- _ O
on -X- _ O
rhetorical -X- _ O
structure -X- _ O
theory -X- _ O
(Mann -X- _ O
and -X- _ O
Thompson, -X- _ O
1988). -X- _ O

In -X- _ O
recent -X- _ O
years, -X- _ O
non-von -X- _ O
Neumann -X- _ O
computers -X- _ O
called -X- _ O
Ising -X- _ B-MethodName
machines -X- _ I-MethodName
have -X- _ O
been -X- _ O
attracting -X- _ O
attention -X- _ O
as -X- _ O
they -X- _ O
can -X- _ O
solve -X- _ O
combinatorial -X- _ O
optimization -X- _ O
problems -X- _ O
and -X- _ O
obtain -X- _ O
quasi-optimal -X- _ O
solutions -X- _ O
instantly -X- _ O
(Sao -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

In -X- _ O
addition, -X- _ O
the -X- _ O
dialogue -X- _ O
scenarios -X- _ O
generated -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
extracted -X- _ O
information -X- _ O
should -X- _ O
be -X- _ O
coherent -X- _ O
to -X- _ O
aid -X- _ O
in -X- _ O
the -X- _ O
proper -X- _ O
understanding. -X- _ O

The -X- _ O
summarization -X- _ O
problem -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
a -X- _ O
quadratic -X- _ B-MethodName
unconstraint -X- _ I-MethodName
binary -X- _ I-MethodName
optimization -X- _ I-MethodName
(QUBO) -X- _ B-MethodName
problem, -X- _ O
which -X- _ O
extracts -X- _ O
sentences -X- _ O
that -X- _ O
maximize -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
user‚Äôs -X- _ O
interest -X- _ O
in -X- _ O
the -X- _ O
sentences -X- _ O
of -X- _ O
documents -X- _ O
with -X- _ O
the -X- _ O
discourse -X- _ O
structure -X- _ O
of -X- _ O
each -X- _ O
document -X- _ O
and -X- _ O
the -X- _ O
total -X- _ O
utterance -X- _ O
time -X- _ O
as -X- _ O
constraints. -X- _ O

A -X- _ O
larger -X- _ O
total -X- _ O
effect -X- _ O
could -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
handling -X- _ O
negation, -X- _ O
however, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
why -X- _ O
that -X- _ O
would -X- _ O
be -X- _ O
the -X- _ O
case -X- _ O
if -X- _ O
the -X- _ O
original -X- _ O
sample -X- _ O
was -X- _ O
incorrectly -X- _ O
predicted. -X- _ O

Figure -X- _ O
4: -X- _ O
Natural -X- _ O
indirect -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
5% -X- _ O
of -X- _ O
neurons -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
per -X- _ O
negation -X- _ O
category. -X- _ O
Shaded -X- _ O
area -X- _ O
represents -X- _ O
the -X- _ O
standard -X- _ O
deviation. -X- _ O

When -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
original -X- _ O
example -X- _ O
correctly, -X- _ O
a -X- _ O
larger -X- _ O
total -X- _ O
effect -X- _ O
under -X- _ O
the -X- _ O
intervention -X- _ O
could -X- _ O
indicate -X- _ O
a -X- _ O
better -X- _ O
handling -X- _ O
of -X- _ O
negation, -X- _ O
as -X- _ O
it -X- _ O
suggests -X- _ O
a -X- _ O
higher -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
label -X- _ O
under -X- _ O
negation. -X- _ O

We -X- _ O
measure -X- _ O
the -X- _ O
natural -X- _ B-MetricName
indirect -X- _ I-MetricName
effect -X- _ I-MetricName
(NIE) -X- _ B-MetricName
of -X- _ O
a -X- _ O
change -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
X -X- _ O
on -X- _ O
the -X- _ O
response -X- _ O
variable -X- _ O
y, -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
a -X- _ O
mediator -X- _ O
z. -X- _ O

Table -X- _ O
3: -X- _ O
Accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
negation -X- _ O
test -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
non-negated -X- _ O
(positive) -X- _ O
examples. -X- _ O

Table -X- _ O
4: -X- _ O
Accuracy -X- _ B-MetricName
for -X- _ O
the -X- _ O
negated -X- _ O
examples -X- _ O
for -X- _ O
whose -X- _ O
original -X- _ O
(unnegated) -X- _ O
version -X- _ O
the -X- _ O
model -X- _ O
makes -X- _ O
a -X- _ O
correct/incorrect -X- _ O
prediction -X- _ O
(‚Äúo. -X- _ O
correct‚Äù/‚Äúo. -X- _ O
incorrect‚Äù). -X- _ O

Looking -X- _ O
at -X- _ O
specific -X- _ O
categories, -X- _ O
LXMERT -X- _ B-MethodName
seems -X- _ O
to -X- _ O
struggle -X- _ O
the -X- _ O
most -X- _ O
with -X- _ O
verbal -X- _ O
negation, -X- _ O
while -X- _ O
both -X- _ O
versions -X- _ O
of -X- _ O
UNITER -X- _ B-MethodName
perform -X- _ O
better, -X- _ O
achieving -X- _ O
scores -X- _ O
between -X- _ O
14 -X- _ B-MetricValue
and -X- _ O
20 -X- _ B-MetricValue
points -X- _ O
higher -X- _ O
than -X- _ O
LXMERT. -X- _ B-MethodName

It -X- _ O
should -X- _ O
also -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
while -X- _ O
negation -X- _ O
is -X- _ O
a -X- _ O
complex -X- _ O
phenomenon, -X- _ O
here -X- _ O
we -X- _ O
only -X- _ O
consider -X- _ O
absolute -X- _ O
negators -X- _ O
(e.g., -X- _ O
no, -X- _ O
not, -X- _ O
nobody, -X- _ O
nothing), -X- _ O
and -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
approximate -X- _ O
negators -X- _ O
(e.g., -X- _ O
few, -X- _ O
little, -X- _ O
barely) -X- _ O
or -X- _ O
affixal -X- _ O
negators -X- _ O
(e.g., -X- _ O
the -X- _ O
prefixes -X- _ O
un-, -X- _ O
in-, -X- _ O
non-, -X- _ O
see -X- _ O
Pullum -X- _ O
and -X- _ O
Huddleston -X- _ O
(2002). -X- _ O

While -X- _ O
causal -X- _ O
mediation -X- _ O
analysis -X- _ O
is -X- _ O
a -X- _ O
useful -X- _ O
analysis -X- _ O
tool, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
straightforward -X- _ O
to -X- _ O
apply -X- _ O
it -X- _ O
to -X- _ O
all -X- _ O
models -X- _ O
and -X- _ O
to -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
attention -X- _ O
when -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
of -X- _ O
different -X- _ O
length -X- _ O
in -X- _ O
the -X- _ O
base -X- _ O
case -X- _ O
and -X- _ O
under -X- _ O
the -X- _ O
intervention. -X- _ O

We -X- _ O
also -X- _ O
compared -X- _ O
the -X- _ O
NIEs -X- _ B-MetricName
of -X- _ O
examples -X- _ O
split -X- _ O
by -X- _ O
whether -X- _ O
the -X- _ O
original/negated -X- _ O
one -X- _ O
is -X- _ O
correctly -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
model, -X- _ O
however, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
observe -X- _ O
notable -X- _ O
differences -X- _ O
(Appendix -X- _ O
F). -X- _ O

As -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
2.3, -X- _ O
this -X- _ O
is -X- _ O
done -X- _ O
by -X- _ O
fixing -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
its -X- _ O
value -X- _ O
without -X- _ O
the -X- _ O
intervention, -X- _ O
but -X- _ O
changing -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
mediator -X- _ O
z -X- _ O
to -X- _ O
its -X- _ O
value -X- _ O
under -X- _ O
the -X- _ O
intervention. -X- _ O

Table -X- _ O
4 -X- _ O
shows -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
the -X- _ O
negated -X- _ O
samples, -X- _ O
split -X- _ O
by -X- _ O
whether -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
corresponding -X- _ O
original -X- _ O
sample -X- _ O
correctly -X- _ O
or -X- _ O
not. -X- _ O

UNITERtriplet -X- _ B-MethodName
was -X- _ O
finetuned -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
achieved -X- _ O
accuracies -X- _ B-MetricName
of -X- _ O
71.53% -X- _ B-MetricValue
on -X- _ O
the -X- _ O
development -X- _ O
and -X- _ O
73.10% -X- _ B-MetricValue
on -X- _ O
the -X- _ O
test -X- _ O
set. -X- _ O

The -X- _ O
existing -X- _ O
dataset -X- _ O
also -X- _ O
cannot -X- _ O
be -X- _ O
used -X- _ O
reliably -X- _ O
to -X- _ O
make -X- _ O
performance -X- _ O
comparisons -X- _ O
between -X- _ O
negated -X- _ O
and -X- _ O
nonnegated -X- _ O
examples. -X- _ O

Vig -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
apply -X- _ O
causal -X- _ O
mediation -X- _ O
analysis -X- _ O
to -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
gender -X- _ O
bias -X- _ O
in -X- _ O
large -X- _ O
pre-trained -X- _ O
language -X- _ O
models. -X- _ O

For -X- _ O
the -X- _ O
purposes -X- _ O
of -X- _ O
this -X- _ O
analysis, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
a -X- _ O
particular -X- _ O
vision-and-language -X- _ O
task, -X- _ O
Natural -X- _ B-MethodName
Language -X- _ I-MethodName
Visual -X- _ I-MethodName
Reasoning -X- _ I-MethodName
for -X- _ I-MethodName
Real -X- _ I-MethodName
(NLVR2) -X- _ B-MethodName
(Suhr -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Figure -X- _ O
1: -X- _ O
Examples -X- _ O
from -X- _ O
the -X- _ O
NLVR2 -X- _ B-DatasetName
corpus. -X- _ O

ÔªøFollowing -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
on -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
language -X- _ O
tasks, -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
vision-and-language -X- _ O
have -X- _ O
involved -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
pre-trained -X- _ O
models -X- _ O
(e.g., -X- _ O
UNITER, -X- _ B-MethodName
Chen -X- _ O
et -X- _ O
al. -X- _ O
2020, -X- _ O
VisualBERT, -X- _ B-MethodName
Li -X- _ O
et -X- _ O
al. -X- _ O
2019, -X- _ O
ViLBERT, -X- _ B-MethodName
Lu -X- _ O
et -X- _ O
al. -X- _ O
2019, -X- _ O
LXMERT, -X- _ B-MethodName
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
2019). -X- _ O

Given -X- _ O
that -X- _ O
unmasking -X- _ O
is -X- _ O
supposed -X- _ O
to -X- _ O
optimize -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
tasks, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
surprising -X- _ O
that -X- _ O
unmasking -X- _ O
handicapped -X- _ O
BabyBERTa -X- _ B-MethodName
during -X- _ O
pre-training. -X- _ O

For -X- _ O
all -X- _ O
models -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
standard -X- _ O
masking -X- _ O
strategy, -X- _ O
in -X- _ O
which -X- _ O
masked -X- _ O
words -X- _ O
are -X- _ O
left -X- _ O
unmasked -X- _ O
10% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
time -X- _ O
(unmasking -X- _ B-HyperparameterName
= -X- _ O
yes), -X- _ B-HyperparameterValue
overall -X- _ O
accuracy -X- _ B-MetricName
was -X- _ O
between -X- _ O
8 -X- _ B-MetricValue
and -X- _ O
16 -X- _ B-MetricValue
points -X- _ O
higher -X- _ O
when -X- _ O
MLM -X- _ B-MethodName
scoring -X- _ O
was -X- _ O
used. -X- _ O

Further, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
probing -X- _ O
across -X- _ O
time -X- _ O
framework -X- _ O
used -X- _ O
by -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

We -X- _ O
also -X- _ O
evaluated -X- _ O
RoBERTabase -X- _ B-MethodName
pre-trained -X- _ O
from -X- _ O
scratch -X- _ O
by -X- _ O
Warstadt -X- _ O
et -X- _ O
al. -X- _ O
(2020b) -X- _ O
on -X- _ O
a -X- _ O
similarly -X- _ O
sized -X- _ O
dataset -X- _ O
consisting -X- _ O
of -X- _ O
10M -X- _ O
words -X- _ O
of -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
and -X- _ O
Smashwords, -X- _ B-DatasetName
which -X- _ O
achieved -X- _ O
an -X- _ O
average -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
64.5, -X- _ B-MetricValue
well -X- _ O
below -X- _ O
81.1. -X- _ B-MetricValue

The -X- _ O
drop -X- _ O
in -X- _ O
average -X- _ O
accuracy -X- _ B-MetricName
is -X- _ O
striking -X- _ O
- -X- _ O
from -X- _ O
81.1 -X- _ B-MetricValue
to -X- _ O
59.2. -X- _ B-MetricValue

The -X- _ O
preference -X- _ O
score -X- _ O
was -X- _ O
calculated -X- _ O
by -X- _ O
summing -X- _ O
the -X- _ O
cross-entropy -X- _ O
errors -X- _ O
at -X- _ O
each -X- _ O
position -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
(Zaczynska -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Additionally, -X- _ O
and -X- _ O
more -X- _ O
importantly, -X- _ O
during -X- _ O
training, -X- _ O
we -X- _ O
modified -X- _ O
the -X- _ O
probability -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
unmasking -X- _ I-HyperparameterName
from -X- _ O
0.1 -X- _ B-HyperparameterValue
to -X- _ B-HyperparameterValue
0.0 -X- _ I-HyperparameterValue
- -X- _ O
effectively -X- _ O
removing -X- _ O
unmasking. -X- _ O

We -X- _ O
introduce -X- _ O
a -X- _ O
scaled-down -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
RoBERTa -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
with -X- _ O
8M -X- _ O
parameters, -X- _ O
8912 -X- _ O
vocabulary -X- _ O
items, -X- _ O
and -X- _ O
trained -X- _ O
on -X- _ O
no -X- _ O
more -X- _ O
than -X- _ O
30M -X- _ O
words. -X- _ O

The -X- _ O
pre-training -X- _ O
stage -X- _ O
for -X- _ O
both -X- _ O
BART -X- _ B-MethodName
and -X- _ O
mBART -X- _ B-MethodName
is -X- _ O
akin -X- _ O
to -X- _ O
a -X- _ O
denoising -X- _ O
autoencoder, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
receives -X- _ O
a -X- _ O
noisy -X- _ O
(in -X- _ O
this -X- _ O
case -X- _ O
masked) -X- _ O
sentence, -X- _ O
and -X- _ O
it -X- _ O
learns -X- _ O
to -X- _ O
reconstruct -X- _ O
it. -X- _ O

For -X- _ O
evaluating -X- _ O
on -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
(SMILE) -X- _ B-DatasetName
and -X- _ O
offensive -X- _ B-TaskName
language -X- _ I-TaskName
identification -X- _ I-TaskName
(OLID), -X- _ B-DatasetName
we -X- _ O
trained -X- _ O
a -X- _ O
simple -X- _ O
word-level -X- _ O
TF-IDF -X- _ B-MethodName
model -X- _ O
together -X- _ O
with -X- _ O
a -X- _ O
linear -X- _ O
SVM -X- _ B-MethodName
with -X- _ O
balanced -X- _ O
weights. -X- _ O

As -X- _ O
opposed -X- _ O
to -X- _ O
current -X- _ O
two-stage -X- _ O
methods -X- _ O
for -X- _ O
word -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
ranking, -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
more -X- _ O
straightforward. -X- _ O

For -X- _ O
example, -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
Croatian, -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
dataset -X- _ O
is -X- _ O
the -X- _ O
second -X- _ O
largest, -X- _ O
the -X- _ O
performance -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
for -X- _ O
other -X- _ O
languages. -X- _ O

Our -X- _ O
lexical -X- _ O
normalization -X- _ O
improves -X- _ O
results -X- _ O
on -X- _ O
both -X- _ O
these -X- _ O
tasks, -X- _ O
compared -X- _ O
to -X- _ O
modelling -X- _ O
the -X- _ O
raw, -X- _ O
unprocessed -X- _ O
social -X- _ O
media -X- _ O
posts. -X- _ O

We -X- _ O
trained -X- _ O
a -X- _ O
word-level -X- _ O
TF-IDF -X- _ B-MethodName
and -X- _ O
a -X- _ O
linear -X- _ O
SVM -X- _ B-MethodName
with -X- _ O
balanced -X- _ O
weights -X- _ O
for -X- _ O
both -X- _ O
datasets -X- _ O
and -X- _ O
reported -X- _ O
a -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score. -X- _ O

Moreover, -X- _ O
we -X- _ O
also -X- _ O
evaluated -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
lexical -X- _ O
normalization -X- _ O
on -X- _ O
two -X- _ O
other -X- _ O
tasks -X- _ O
- -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
on -X- _ O
the -X- _ O
SMILE -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
offensive -X- _ B-TaskName
language -X- _ I-TaskName
identification -X- _ I-TaskName
on -X- _ O
OLID -X- _ B-DatasetName
(Table -X- _ O
5). -X- _ O

Since -X- _ O
the -X- _ O
memory -X- _ O
requirements -X- _ O
of -X- _ O
an -X- _ O
mBART -X- _ B-MethodName
model -X- _ O
are -X- _ O
quite -X- _ O
high, -X- _ O
we -X- _ O
employed -X- _ O
gradient -X- _ O
accumulation -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
batch -X- _ O
size. -X- _ O

Moreover, -X- _ O
we -X- _ O
also -X- _ O
evaluate -X- _ O
the -X- _ O
extrinsic -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
two -X- _ O
additional -X- _ O
tasks: -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
on -X- _ O
the -X- _ O
SMILE -X- _ B-DatasetName
dataset -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
and -X- _ O
hate -X- _ B-TaskName
speech -X- _ I-TaskName
detection -X- _ I-TaskName
on -X- _ O
OLID -X- _ B-DatasetName
dataset -X- _ O
(Zampieri -X- _ O
et -X- _ O
al., -X- _ O
2019a). -X- _ O

However, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
translation -X- _ O
between -X- _ O
languages, -X- _ O
but -X- _ O
instead, -X- _ O
we -X- _ O
use -X- _ O
mBART -X- _ B-MethodName
as -X- _ O
a -X- _ O
denoising -X- _ O
autoencoder, -X- _ O
i.e. -X- _ O
translating -X- _ O
from -X- _ O
bad -X- _ O
English -X- _ O
to -X- _ O
good -X- _ O
English. -X- _ O

MoNoise -X- _ B-MethodName
is -X- _ O
a -X- _ O
normalization -X- _ O
model -X- _ O
using -X- _ O
spelling -X- _ O
correction -X- _ O
and -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
a -X- _ O
feature-based -X- _ O
random -X- _ B-MethodName
forest -X- _ I-MethodName
classifier -X- _ O
for -X- _ O
candidate -X- _ O
ranking. -X- _ O

One -X- _ O
way -X- _ O
to -X- _ O
resolve -X- _ O
this -X- _ O
issue -X- _ O
is -X- _ O
through -X- _ O
lexical -X- _ O
normalization, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
transforming -X- _ O
non-standard -X- _ O
text, -X- _ O
usually -X- _ O
from -X- _ O
social -X- _ O
media, -X- _ O
into -X- _ O
a -X- _ O
more -X- _ O
standardized -X- _ O
form. -X- _ O

As -X- _ O
we -X- _ O
can -X- _ O
see, -X- _ O
AAN -X- _ B-MethodName
and -X- _ O
all -X- _ O
the -X- _ O
variants -X- _ O
with -X- _ O
AAN -X- _ B-MethodName
have -X- _ O
an -X- _ O
absolutely -X- _ O
lower -X- _ O
Self-BLEU -X- _ B-MetricName
score -X- _ O
with -X- _ O
the -X- _ O
Transformer. -X- _ B-MethodName

The -X- _ O
Self-BLEU -X- _ B-MetricName
scores -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
demonstrate -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
two -X- _ O
models, -X- _ O
more -X- _ O
different -X- _ O
models -X- _ O
generally -X- _ O
have -X- _ O
lower -X- _ O
scores. -X- _ O

Knowledge -X- _ O
Distillation -X- _ O
and -X- _ O
more -X- _ O
BT -X- _ O
data -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
from -X- _ O
20.82 -X- _ B-MetricValue
to -X- _ O
22.11. -X- _ B-MetricValue

Our -X- _ O
WMT2021 -X- _ B-TaskName
English‚ÜíChinese -X- _ O
submission -X- _ O
achieves -X- _ O
a -X- _ O
SacreBLEU -X- _ B-MetricName
score -X- _ O
of -X- _ O
36.9, -X- _ B-MetricValue
which -X- _ O
is -X- _ O
the -X- _ O
highest -X- _ O
among -X- _ O
all -X- _ O
submissions -X- _ O
and -X- _ O
chrF -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.337. -X- _ B-MetricValue

With -X- _ O
BSBE -X- _ B-MethodName
strategies -X- _ O
in -X- _ O
Sec. -X- _ O
3.6, -X- _ O
a -X- _ O
better -X- _ O
model -X- _ O
combination -X- _ O
with -X- _ O
less -X- _ O
number -X- _ O
of -X- _ O
models -X- _ O
are -X- _ O
quickly -X- _ O
searched, -X- _ O
and -X- _ O
we -X- _ O
finally -X- _ O
achieve -X- _ O
50.94 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
score. -X- _ O

We -X- _ O
further -X- _ O
gain -X- _ O
+0.62 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
score -X- _ O
after -X- _ O
applying -X- _ O
knowledge -X- _ O
distillation -X- _ O
and -X- _ O
+0.24 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
from -X- _ O
Forward-Translation. -X- _ B-MethodName

We -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
with -X- _ O
Œ≤1 -X- _ B-HyperparameterName
= -X- _ O
0.9, -X- _ B-HyperparameterValue
Œ≤2 -X- _ B-HyperparameterName
= -X- _ O
0.998. -X- _ B-HyperparameterValue

After -X- _ O
applying -X- _ O
large-scale -X- _ B-MethodName
Back-Translation, -X- _ I-MethodName
we -X- _ O
obtain -X- _ O
+2.0 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
score -X- _ O
on -X- _ O
the -X- _ O
baseline. -X- _ O

The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
8192 -X- _ B-HyperparameterValue
tokens -X- _ O
per -X- _ O
GPU -X- _ O
and -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
‚Äúupdate-freq‚Äù -X- _ B-HyperparameterName
parameter -X- _ O
in -X- _ O
Fairseq -X- _ B-DatasetName
to -X- _ O
2. -X- _ B-HyperparameterValue

For -X- _ O
training -X- _ O
strategies, -X- _ O
we -X- _ O
mainly -X- _ O
focus -X- _ O
on -X- _ O
scheduled -X- _ B-MethodName
sampling -X- _ I-MethodName
based -X- _ O
on -X- _ O
decoding -X- _ O
steps -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021b), -X- _ O
the -X- _ O
confidence-aware -X- _ B-MethodName
scheduled -X- _ I-MethodName
sampling -X- _ I-MethodName
(Mihaylova -X- _ O
and -X- _ O
Martins, -X- _ O
2019; -X- _ O
Duckworth -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
the -X- _ O
target -X- _ B-MethodName
denoising -X- _ I-MethodName
(Meng -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
method -X- _ O
and -X- _ O
the -X- _ O
Graduated -X- _ B-MethodName
Label -X- _ I-MethodName
Smoothing -X- _ I-MethodName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
for -X- _ O
in-domain -X- _ O
finetuning. -X- _ O

ÔªøIn -X- _ O
our -X- _ O
experiments, -X- _ O
we -X- _ O
employ -X- _ O
data -X- _ O
filtering, -X- _ O
large-scale -X- _ O
synthetic -X- _ O
data -X- _ O
generation -X- _ O
(i.e., -X- _ O
back-translation, -X- _ O
knowledge -X- _ O
distillation, -X- _ O
forward-translation, -X- _ O
iterative -X- _ O
in-domain -X- _ O
knowledge -X- _ O
transfer), -X- _ O
advanced -X- _ O
finetuning -X- _ O
approaches, -X- _ O
and -X- _ O
boosted -X- _ O
Self-BLEU -X- _ B-MetricName
based -X- _ O
model -X- _ O
ensemble. -X- _ O

Finally, -X- _ O
from -X- _ O
a -X- _ O
cognitive -X- _ O
plausibility -X- _ O
perspective, -X- _ O
holistic -X- _ B-MethodName
scoring -X- _ I-MethodName
resembles -X- _ O
much -X- _ O
more -X- _ O
closely -X- _ O
the -X- _ O
actual -X- _ O
situation -X- _ O
faced -X- _ O
by -X- _ O
humans -X- _ O
tasked -X- _ O
to -X- _ O
judge -X- _ O
grammatical -X- _ O
acceptability; -X- _ O
training -X- _ O
models -X- _ O
to -X- _ O
perform -X- _ O
well -X- _ O
with -X- _ O
holistic -X- _ B-MethodName
scoring -X- _ I-MethodName
should -X- _ O
be -X- _ O
considered -X- _ O
in -X- _ O
future -X- _ O
work. -X- _ O

For -X- _ O
clarity, -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
our -X- _ O
method -X- _ O
as -X- _ O
holistic -X- _ B-MethodName
scoring, -X- _ I-MethodName
and -X- _ O
that -X- _ O
of -X- _ O
Salazar -X- _ O
et -X- _ O
al. -X- _ O
(2020b) -X- _ O
as -X- _ O
MLM -X- _ B-MethodName
scoring. -X- _ I-MethodName

The -X- _ O
direction -X- _ O
of -X- _ O
this -X- _ O
effect -X- _ O
is -X- _ O
what -X- _ O
one -X- _ O
would -X- _ O
predict -X- _ O
under -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
input -X- _ O
to -X- _ O
children -X- _ O
aged -X- _ O
1-6 -X- _ O
years -X- _ O
but -X- _ O
not -X- _ O
beyond -X- _ O
(6-12 -X- _ O
years) -X- _ O
scaffolds -X- _ O
grammatical -X- _ O
development. -X- _ O

Moreover, -X- _ O
because -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
of -X- _ O
each -X- _ O
content -X- _ O
word -X- _ O
in -X- _ O
all -X- _ O
our -X- _ O
test -X- _ O
sentences -X- _ O
is -X- _ O
closely -X- _ O
counterbalanced -X- _ O
across -X- _ O
all -X- _ O
three -X- _ O
corpora -X- _ O
(see -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
details), -X- _ O
any -X- _ O
observed -X- _ O
differences -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
structural -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
word-frequency-related -X- _ O
differences -X- _ O
between -X- _ O
corpora. -X- _ O

To -X- _ O
enable -X- _ O
fair -X- _ O
comparisons, -X- _ O
we -X- _ O
use -X- _ O
this -X- _ O
method -X- _ O
to -X- _ O
evaluate -X- _ O
all -X- _ O
models -X- _ O
considered -X- _ O
in -X- _ O
this -X- _ O
paper. -X- _ O

We -X- _ O
also -X- _ O
added -X- _ O
2 -X- _ O
phenomena -X- _ O
not -X- _ O
in -X- _ O
BLiMP -X- _ B-DatasetName
("case", -X- _ O
and -X- _ O
"local -X- _ O
attractor" -X- _ O
to -X- _ O
challenge -X- _ O
subject-verb -X- _ O
agreement), -X- _ O
for -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
23 -X- _ O
paradigms -X- _ O
and -X- _ O
13 -X- _ O
phenomena. -X- _ O

Toward -X- _ O
that -X- _ O
end, -X- _ O
we -X- _ O
carefully -X- _ O
counterbalanced -X- _ O
every -X- _ O
word -X- _ O
list -X- _ O
used -X- _ O
to -X- _ O
construct -X- _ O
sentences -X- _ O
(e.g. -X- _ O
nouns, -X- _ O
adjectives, -X- _ O
verbs) -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
of -X- _ O
all -X- _ O
word -X- _ O
types -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
list -X- _ O
was -X- _ O
approximately -X- _ O
equal -X- _ O
(differed -X- _ O
no -X- _ O
more -X- _ O
than -X- _ O
1K) -X- _ O
across -X- _ B-DatasetName
AO-CHILDES, -X- _ I-DatasetName
AO-Newsela, -X- _ B-DatasetName
and -X- _ O
Wikipedia-1. -X- _ B-DatasetName

Thus, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
further -X- _ O
isolate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
domain, -X- _ O
we -X- _ O
included -X- _ O
a -X- _ O
fifth -X- _ O
corpus, -X- _ O
which -X- _ O
we -X- _ O
will -X- _ O
refer -X- _ O
to -X- _ O
as -X- _ O
AO-Newsela, -X- _ B-DatasetName
based -X- _ O
on -X- _ O
the -X- _ O
Newsela -X- _ B-DatasetName
corpus -X- _ I-DatasetName
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2015). -X- _ O

Our -X- _ O
main -X- _ O
corpus -X- _ O
of -X- _ O
interest -X- _ O
is -X- _ O
AO-CHILDES -X- _ B-DatasetName
(AgeOrdered-CHILDES, -X- _ B-DatasetName
Huebner -X- _ O
and -X- _ O
Willits, -X- _ O
2021). -X- _ O

Briefly, -X- _ O
BabyBERTa -X- _ B-MethodName
uses -X- _ O
only -X- _ O
8 -X- _ B-HyperparameterValue
layers, -X- _ B-HyperparameterName
8 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads, -X- _ I-HyperparameterName
256 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units, -X- _ I-HyperparameterName
and -X- _ O
an -X- _ B-HyperparameterName
intermediate -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
1024. -X- _ B-HyperparameterValue

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
examined -X- _ O
the -X- _ O
grammatical -X- _ O
knowledge -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
when -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
5M -X- _ O
word -X- _ O
corpus -X- _ O
of -X- _ O
language -X- _ O
acquisition -X- _ O
data -X- _ O
to -X- _ O
simulate -X- _ O
the -X- _ O
input -X- _ O
available -X- _ O
to -X- _ O
children -X- _ O
between -X- _ O
the -X- _ O
ages -X- _ O
1 -X- _ O
and -X- _ O
6. -X- _ O

As -X- _ O
such, -X- _ O
for -X- _ O
the -X- _ O
post-processing -X- _ O
phase, -X- _ O
we -X- _ O
aligned -X- _ O
input -X- _ O
words -X- _ O
with -X- _ O
their -X- _ O
normalized -X- _ O
counterparts -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Levenshtein -X- _ B-MetricName
distance -X- _ I-MetricName
between -X- _ O
them. -X- _ O

The -X- _ O
training -X- _ O
was -X- _ O
performed -X- _ O
on -X- _ O
an -X- _ O
NVIDIA -X- _ O
RTX -X- _ O
2070 -X- _ O
graphics -X- _ O
card. -X- _ O

The -X- _ O
dataset -X- _ O
comprises -X- _ O
Twitter -X- _ O
posts -X- _ O
from -X- _ O
all -X- _ O
languages, -X- _ O
but -X- _ O
some -X- _ O
languages -X- _ O
also -X- _ O
have -X- _ O
texts -X- _ O
from -X- _ O
additional -X- _ O
sources. -X- _ O

This -X- _ O
way, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
whole -X- _ O
sentence -X- _ O
into -X- _ O
consideration -X- _ O
when -X- _ O
correcting -X- _ O
the -X- _ O
text. -X- _ O

It -X- _ O
has -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
in -X- _ O
increasing -X- _ O
performance -X- _ O
on -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
POS -X- _ B-TaskName
tagging -X- _ I-TaskName
(van -X- _ O
der -X- _ O
Goot -X- _ O
and -X- _ O
√áetinoglu, -X- _ O
2021), -X- _ O
dependency -X- _ B-TaskName
parsing -X- _ I-TaskName
(van -X- _ O
der -X- _ O
Goot, -X- _ O
2019a) -X- _ O
and -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
(Mandal -X- _ O
and -X- _ O
Nanmaran, -X- _ O
2018). -X- _ O

Talking-Heads -X- _ B-MethodName
Attention -X- _ I-MethodName
(Shazeer -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
is -X- _ O
a -X- _ O
new -X- _ O
variation -X- _ O
that -X- _ O
inserts -X- _ O
two -X- _ O
additional -X- _ O
learned -X- _ O
linear -X- _ O
projection -X- _ O
weights, -X- _ O
Wl -X- _ O
and -X- _ O
Ww, -X- _ O
to -X- _ O
transform -X- _ O
the -X- _ O
attention-logits -X- _ O
and -X- _ O
the -X- _ O
attention -X- _ O
scores -X- _ O
respectively, -X- _ O
moving -X- _ O
information -X- _ O
across -X- _ O
attention -X- _ O
heads. -X- _ O

The -X- _ O
Talking-Heads -X- _ B-MethodName
Attention -X- _ I-MethodName
has -X- _ O
the -X- _ O
minimum -X- _ O
scores -X- _ O
among -X- _ O
all -X- _ O
the -X- _ O
variants. -X- _ O

Here -X- _ O
we -X- _ O
take -X- _ O
En‚ÜíZh -X- _ O
models -X- _ O
as -X- _ O
examples -X- _ O
to -X- _ O
conduct -X- _ O
the -X- _ O
diversity -X- _ O
and -X- _ O
ensemble -X- _ O
experiments. -X- _ O

Otherwise, -X- _ O
it -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
a -X- _ O
temporary -X- _ O
model -X- _ O
list -X- _ O
and -X- _ O
still -X- _ O
has -X- _ O
a -X- _ O
weak -X- _ O
chance -X- _ O
to -X- _ O
be -X- _ O
reused -X- _ O
in -X- _ O
the -X- _ O
future. -X- _ O

For -X- _ O
our -X- _ O
submitted -X- _ O
system, -X- _ O
we -X- _ O
search -X- _ O
from -X- _ O
over -X- _ O
500 -X- _ O
models. -X- _ O

The -X- _ O
Talking-Heads -X- _ B-MethodName
Attention -X- _ I-MethodName
has -X- _ O
the -X- _ O
minimum -X- _ O
scores -X- _ O
among -X- _ O
all -X- _ O
the -X- _ O
variants. -X- _ O

For -X- _ O
the -X- _ O
post-processing, -X- _ O
we -X- _ O
apply -X- _ O
de-truecaseing -X- _ B-MethodName
and -X- _ O
de-tokenizing -X- _ B-MethodName
on -X- _ O
the -X- _ O
English -X- _ O
and -X- _ O
German -X- _ O
translations -X- _ O
with -X- _ O
the -X- _ O
scripts -X- _ O
provided -X- _ O
in -X- _ O
Moses. -X- _ B-DatasetName

We -X- _ O
use -X- _ O
byte -X- _ B-MethodName
pair -X- _ I-MethodName
encoding -X- _ I-MethodName
BPE -X- _ I-MethodName
(Sennrich -X- _ O
et -X- _ O
al., -X- _ O
2016b) -X- _ O
with -X- _ O
32K -X- _ O
operations -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
languages. -X- _ O

For -X- _ O
monolingual -X- _ O
data, -X- _ O
we -X- _ O
select -X- _ O
data -X- _ O
from -X- _ O
News -X- _ B-DatasetName
Crawl, -X- _ I-DatasetName
Common -X- _ B-DatasetName
Crawl -X- _ I-DatasetName
and -X- _ O
Extended -X- _ B-DatasetName
Common -X- _ I-DatasetName
Crawl, -X- _ I-DatasetName
it -X- _ O
is -X- _ O
then -X- _ O
divided -X- _ O
into -X- _ O
several -X- _ O
parts, -X- _ O
each -X- _ O
containing -X- _ O
50M -X- _ O
sentences. -X- _ O

We -X- _ O
use -X- _ O
warmup -X- _ B-HyperparameterName
step -X- _ I-HyperparameterName
= -X- _ O
4000. -X- _ B-HyperparameterValue

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.0005 -X- _ B-HyperparameterValue
for -X- _ O
Fairseq -X- _ B-DatasetName
and -X- _ B-HyperparameterValue
2.0 -X- _ I-HyperparameterValue
for -X- _ O
OpenNMT. -X- _ B-DatasetName

We -X- _ O
combine -X- _ O
the -X- _ O
Average -X- _ B-MethodName
Attention -X- _ I-MethodName
Transformer -X- _ I-MethodName
(AAN) -X- _ I-MethodName
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
and -X- _ O
Multi-HeadAttention -X- _ B-MethodName
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
to -X- _ O
derive -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
effective -X- _ O
and -X- _ O
diverse -X- _ O
model -X- _ O
variants. -X- _ O

Besides -X- _ O
the -X- _ O
Pre-Norm -X- _ B-MethodName
Transformer, -X- _ I-MethodName
the -X- _ O
Post-Norm -X- _ B-MethodName
Transformer -X- _ I-MethodName
is -X- _ O
also -X- _ O
used -X- _ O
as -X- _ O
one -X- _ O
of -X- _ O
our -X- _ O
baselines -X- _ O
this -X- _ O
year. -X- _ O

Aggregated -X- _ O
results -X- _ O
for -X- _ O
all -X- _ O
method -X- _ O
and -X- _ O
model -X- _ O
combinations, -X- _ O
averaged -X- _ O
over -X- _ O
three -X- _ O
seeds. -X- _ O
Model -X- _ O
names -X- _ O
are -X- _ O
abbreviated -X- _ O
for -X- _ O
space: -X- _ O
FastT -X- _ B-MethodName
is -X- _ O
FastText, -X- _ B-MethodName
DRoB -X- _ B-MethodName
is -X- _ O
DistilRoBERTa, -X- _ B-MethodName
and -X- _ O
DeXL -X- _ B-MethodName
is -X- _ O
DeBERTa-XLarge. -X- _ B-MethodName
Avg -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
across -X- _ O
models -X- _ O
for -X- _ O
that -X- _ O
method. -X- _ O
FastText -X- _ B-MethodName
doesn‚Äôt -X- _ O
produce -X- _ O
context-dependent -X- _ O
representations, -X- _ O
and -X- _ O
so -X- _ O
is -X- _ O
not -X- _ O
usable -X- _ O
on -X- _ O
the -X- _ O
QA -X- _ O
task. -X- _ O

DistilRoBERTa -X- _ B-MethodName
represents -X- _ O
a -X- _ O
distilled -X- _ O
version -X- _ O
of -X- _ O
RoBERTa-base -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
It -X- _ O
contains -X- _ O
82 -X- _ O
million -X- _ O
parameters, -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
125 -X- _ O
million -X- _ O
parameters -X- _ O
found -X- _ O
in -X- _ O
RoBERTa. -X- _ B-MethodName

DeBERTa-XLarge -X- _ B-MethodName
is -X- _ O
our -X- _ O
large -X- _ O
model, -X- _ O
which -X- _ O
contains -X- _ O
750 -X- _ O
million -X- _ O
parameters -X- _ O
and -X- _ O
currently -X- _ O
is -X- _ O
the -X- _ O
state-of-the-art -X- _ O
on -X- _ O
many -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
tasks -X- _ O
(He -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
were -X- _ O
chosen -X- _ O
from -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
[1e-6, -X- _ B-HyperparameterValue
3e-6, -X- _ I-HyperparameterValue
1e-5, -X- _ I-HyperparameterValue
3e-5, -X- _ I-HyperparameterValue
1e-4]. -X- _ I-HyperparameterValue

Occasionally, -X- _ O
when -X- _ O
varying -X- _ O
dropout -X- _ B-HyperparameterName
had -X- _ O
no -X- _ O
effect, -X- _ O
we -X- _ O
consider -X- _ O
doubling -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
instead -X- _ O
from -X- _ O
16 -X- _ B-HyperparameterValue
to -X- _ O
32. -X- _ B-HyperparameterValue

In -X- _ O
our -X- _ O
experiments, -X- _ O
we -X- _ O
fine-tune -X- _ O
parameters -X- _ O
during -X- _ O
initial -X- _ O
training -X- _ O
with -X- _ O
only -X- _ O
six -X- _ O
runs, -X- _ O
which -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
three -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
and -X- _ O
two -X- _ O
levels -X- _ O
of -X- _ O
dropout -X- _ B-HyperparameterName
at -X- _ O
0.1 -X- _ B-HyperparameterValue
and -X- _ O
0.05. -X- _ B-HyperparameterValue

The -X- _ O
Social -X- _ B-DatasetName
Bias -X- _ I-DatasetName
Frames -X- _ I-DatasetName
dataset -X- _ O
collects -X- _ O
instances -X- _ O
of -X- _ O
biases -X- _ O
and -X- _ O
implied -X- _ O
stereotypes -X- _ O
found -X- _ O
in -X- _ O
text -X- _ O
(Sap -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O
We -X- _ O
extract -X- _ O
just -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
whether -X- _ O
a -X- _ O
statement -X- _ O
is -X- _ O
offensive -X- _ O
for -X- _ O
binary -X- _ O
classification. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
MultiNLI -X- _ B-DatasetName
dataset -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
(Williams -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

Our -X- _ O
third -X- _ O
task -X- _ O
uses -X- _ O
the -X- _ O
first -X- _ O
round -X- _ O
of -X- _ O
the -X- _ O
DynaSent -X- _ B-DatasetName
corpus -X- _ O
for -X- _ O
four-way -X- _ B-TaskName
sentiment -X- _ I-TaskName
analysis -X- _ I-TaskName
(Potts -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Our -X- _ O
final -X- _ O
task -X- _ O
is -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
with -X- _ O
examples -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
NewsQA -X- _ B-DatasetName
dataset -X- _ O
(Trischler -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

We -X- _ O
measured -X- _ O
the -X- _ O
running -X- _ O
time -X- _ O
of -X- _ O
EmojiCloud -X- _ B-MethodName
on -X- _ O
a -X- _ O
laptop -X- _ O
with -X- _ O
an -X- _ O
AMD -X- _ O
Ryzen -X- _ O
7 -X- _ O
4800HS -X- _ O
processor -X- _ O
and -X- _ O
16 -X- _ O
GB -X- _ O
RAM. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
word -X- _ B-MethodName
cloud -X- _ I-MethodName
(Bielenberg -X- _ O
and -X- _ O
Zacher, -X- _ O
2005; -X- _ O
Dubinko -X- _ O
et -X- _ O
al., -X- _ O
2007), -X- _ O
which -X- _ O
has -X- _ O
be -X- _ O
adopted -X- _ O
as -X- _ O
an -X- _ O
effective -X- _ O
way -X- _ O
to -X- _ O
visualize -X- _ O
the -X- _ O
frequency -X- _ O
and -X- _ O
importance -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
text -X- _ O
mining, -X- _ O
we -X- _ O
thought -X- _ O
the -X- _ O
word -X- _ O
cloud -X- _ O
of -X- _ O
emojis -X- _ O
seemed -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
good -X- _ O
solution. -X- _ O

This -X- _ O
paper -X- _ O
proposes -X- _ O
EmojiCloud, -X- _ B-MethodName
an -X- _ O
open-source -X- _ O
Python-based -X- _ O
emoji -X- _ O
cloud -X- _ O
visualization -X- _ O
tool, -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
quick -X- _ O
and -X- _ O
straightforward -X- _ O
understanding -X- _ O
of -X- _ O
emojis -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
frequency -X- _ O
and -X- _ O
importance. -X- _ O

All -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
more -X- _ O
than -X- _ O
60,000 -X- _ O
training -X- _ O
data -X- _ O
have -X- _ O
more -X- _ O
than -X- _ O
90 -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
recall, -X- _ B-MetricName
precision, -X- _ B-MetricName
and -X- _ O
f-measure -X- _ B-MetricName
score. -X- _ O

However, -X- _ O
the -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
English -X- _ O
word -X- _ O
segmentation -X- _ O
model -X- _ O
has -X- _ O
a -X- _ O
lower -X- _ O
recall, -X- _ B-MetricName
precision, -X- _ B-MetricName
and -X- _ O
f-measure -X- _ B-MetricName
scores -X- _ O
than -X- _ O
other -X- _ O
language -X- _ O
models; -X- _ O
even -X- _ O
Mongolian -X- _ O
has -X- _ O
fewest -X- _ O
training -X- _ O
data. -X- _ O

The -X- _ O
resulted -X- _ O
model -X- _ O
has -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
layer -X- _ O
with -X- _ O
128 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units, -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
32. -X- _ B-HyperparameterValue

We -X- _ O
train -X- _ O
a -X- _ O
monolingual -X- _ O
word -X- _ O
segmentation -X- _ O
model -X- _ O
for -X- _ O
each -X- _ O
given -X- _ O
language -X- _ O
with -X- _ O
identical -X- _ O
parameters, -X- _ O
50 -X- _ B-HyperparameterValue
epochs, -X- _ B-HyperparameterName
1 -X- _ B-HyperparameterValue
encoder -X- _ B-HyperparameterName
layer, -X- _ I-HyperparameterName
1 -X- _ B-HyperparameterValue
decoder -X- _ B-HyperparameterName
layer, -X- _ I-HyperparameterName
0.0001 -X- _ B-HyperparameterValue
learning -X- _ B-HyperparameterName
rate, -X- _ I-HyperparameterName
using -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2014) -X- _ O
and -X- _ O
the -X- _ O
cross-entropy -X- _ O
loss. -X- _ O

A -X- _ O
dataset -X- _ O
for -X- _ O
this -X- _ O
task, -X- _ O
the -X- _ O
organizer -X- _ O
integrated -X- _ O
all -X- _ O
basic -X- _ O
types -X- _ O
of -X- _ O
morphological -X- _ O
databases -X- _ O
(including -X- _ O
UniMorph -X- _ O
(Kirov -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
McCarthy -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Batsuren -X- _ O
et -X- _ O
al., -X- _ O
2022b) -X- _ O
‚Äì -X- _ O
inflectional -X- _ O
morphology; -X- _ O
MorphyNet -X- _ B-DatasetName
(Batsuren -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
‚Äì -X- _ O
derivational -X- _ O
morphology; -X- _ O
Universal -X- _ B-DatasetName
Dependencies -X- _ I-DatasetName
(Nivre -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
and -X- _ O
ten -X- _ O
editions -X- _ O
of -X- _ O
Wiktionary -X- _ O
‚Äì -X- _ O
compound -X- _ O
morphology -X- _ O
and -X- _ O
root -X- _ O
words) -X- _ O
cover -X- _ O
9 -X- _ O
languages. -X- _ O
8 -X- _ O
of -X- _ O
these -X- _ O
languages -X- _ O
were -X- _ O
available -X- _ O
initially, -X- _ O
while -X- _ O
1 -X- _ O
surprise -X- _ O
language, -X- _ O
Mongolia, -X- _ O
was -X- _ O
released -X- _ O
one -X- _ O
week -X- _ O
before -X- _ O
the -X- _ O
submission -X- _ O
deadline. -X- _ O

The -X- _ O
first -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
decision -X- _ O
trees -X- _ O
with -X- _ O
gradient -X- _ O
boosting, -X- _ O
while -X- _ O
the -X- _ O
second -X- _ O
applies -X- _ O
Bi-LSTM -X- _ B-MethodName
neural -X- _ O
network. -X- _ O

Recent -X- _ O
works -X- _ O
developed -X- _ O
two -X- _ O
more -X- _ O
supervised -X- _ O
machine -X- _ O
learning -X- _ O
models -X- _ O
for -X- _ O
morpheme -X- _ B-TaskName
segmentation -X- _ I-TaskName
with -X- _ O
classification -X- _ O
for -X- _ O
Russian -X- _ O
words -X- _ O
(Bolshakova -X- _ O
and -X- _ O
Sapin, -X- _ O
2019a), -X- _ O
(Bolshakova -X- _ O
and -X- _ O
Sapin, -X- _ O
2019b). -X- _ O

Morfessor -X- _ B-MethodName
system -X- _ O
(Creutz -X- _ O
and -X- _ O
Lagus, -X- _ O
2007), -X- _ O
(Smit -X- _ O
et -X- _ O
al., -X- _ O
2014) -X- _ O
exploits -X- _ O
unsupervised -X- _ O
machine -X- _ O
learning -X- _ O
methods -X- _ O
to -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
unlabelled -X- _ O
text. -X- _ O

The -X- _ O
task -X- _ O
of -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
has -X- _ O
seen -X- _ O
significant -X- _ O
progress -X- _ O
in -X- _ O
recent -X- _ O
times -X- _ O
with -X- _ O
the -X- _ O
advent -X- _ O
of -X- _ O
Transformer-based -X- _ O
models -X- _ O
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
for -X- _ O
this -X- _ O
year‚Äôs -X- _ O
SIGMORPHON -X- _ O
2022 -X- _ O
shared -X- _ O
task -X- _ O
on -X- _ O
morpheme -X- _ B-TaskName
segemntation -X- _ I-TaskName
(Batsuren -X- _ O
et -X- _ O
al., -X- _ O
2022a) -X- _ O
which -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
level, -X- _ O
participants -X- _ O
will -X- _ O
be -X- _ O
asked -X- _ O
to -X- _ O
segment -X- _ O
a -X- _ O
given -X- _ O
word -X- _ O
into -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
morphemes. -X- _ O

Morphological -X- _ O
analysis -X- _ O
is -X- _ O
the -X- _ O
heart -X- _ O
of -X- _ O
nearly -X- _ O
all -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ O
sentiment -X- _ B-TaskName
analysis, -X- _ I-TaskName
machine -X- _ B-TaskName
translation, -X- _ I-TaskName
information -X- _ B-TaskName
retrieval, -X- _ I-TaskName
etc. -X- _ O

We -X- _ O
develop -X- _ O
monolingual -X- _ O
models -X- _ O
for -X- _ O
world-level -X- _ O
morpheme -X- _ O
segmentation -X- _ O
and -X- _ O
focus -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
model -X- _ O
by -X- _ O
using -X- _ O
various -X- _ O
training -X- _ O
strategies -X- _ O
to -X- _ O
improve -X- _ O
accuracy -X- _ O
and -X- _ O
generalization -X- _ O
across -X- _ O
languages. -X- _ O

We -X- _ O
find -X- _ O
no -X- _ O
significant -X- _ O
difference -X- _ O
(t -X- _ O
= -X- _ O
0.442, -X- _ O
p -X- _ O
= -X- _ O
0.662) -X- _ O
in -X- _ O
BPP -X- _ B-MetricName
scores -X- _ O
across -X- _ O
predicate -X- _ O
types. -X- _ O

As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
2, -X- _ O
this -X- _ O
model -X- _ O
is -X- _ O
BERT, -X- _ B-MethodName
probed -X- _ O
with -X- _ O
a -X- _ O
classifier -X- _ O
trained -X- _ O
on -X- _ O
12.5% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
full -X- _ O
training -X- _ B-HyperparameterName
split. -X- _ I-HyperparameterName

Lastly, -X- _ O
LUKE‚Äôs -X- _ B-MethodName
performance, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
score -X- _ O
of -X- _ O
15.05, -X- _ B-MetricValue
is -X- _ O
significantly -X- _ O
lower -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
three -X- _ O
models -X- _ O
(t-tests -X- _ O
against -X- _ O
BERT, -X- _ B-MethodName
StructBERT -X- _ B-MethodName
and -X- _ O
GPT-2 -X- _ B-MethodName
yield -X- _ O
p-values -X- _ O
approaching -X- _ O
zero), -X- _ O
suggesting -X- _ O
that -X- _ O
its -X- _ O
ability -X- _ O
to -X- _ O
track -X- _ O
entities -X- _ O
does -X- _ O
not -X- _ O
significantly -X- _ O
help -X- _ O
in -X- _ O
solving -X- _ O
logical -X- _ O
deductions. -X- _ O

GPT-2‚Äôs -X- _ B-MethodName
high -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
across -X- _ O
splits -X- _ O
(on -X- _ O
average, -X- _ O
20.82) -X- _ B-MetricValue
indicates -X- _ O
a -X- _ O
severe -X- _ O
instability -X- _ O
in -X- _ O
its -X- _ O
capacity -X- _ O
to -X- _ O
correctly -X- _ O
encode -X- _ O
logical -X- _ O
reasoning -X- _ O
cues. -X- _ O

BERT -X- _ B-MethodName
and -X- _ O
StructBERT -X- _ B-MethodName
are -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
models -X- _ O
with -X- _ O
BPP -X- _ B-MetricName
scores -X- _ O
ranging -X- _ O
roughly -X- _ O
between -X- _ O
15 -X- _ B-MetricValue
and -X- _ O
40 -X- _ B-MetricValue
(except -X- _ O
for -X- _ O
the -X- _ O
smallest -X- _ O
training -X- _ B-HyperparameterName
split -X- _ I-HyperparameterName
sizes). -X- _ I-HyperparameterName

We -X- _ O
therefore -X- _ O
use -X- _ O
Scrambled -X- _ B-MethodName
to -X- _ O
compute -X- _ O
BPP -X- _ B-MetricName
scores, -X- _ O
as -X- _ O
it -X- _ O
yields -X- _ O
the -X- _ O
strictest -X- _ O
(or -X- _ O
most -X- _ O
selective; -X- _ O
Hewitt -X- _ O
and -X- _ O
Liang, -X- _ O
2019a) -X- _ O
baseline -X- _ O
setup. -X- _ O

For -X- _ O
the -X- _ O
Random -X- _ O
baseline, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
probing -X- _ O
classifier -X- _ O
on -X- _ O
randomly -X- _ O
initialised -X- _ O
vector -X- _ O
representations. -X- _ O

Humans -X- _ O
should -X- _ O
achieve -X- _ O
50% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
on -X- _ O
this -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
because -X- _ O
random -X- _ O
word -X- _ O
order -X- _ O
impedes -X- _ O
logical -X- _ O
reasoning. -X- _ O

We -X- _ O
split -X- _ O
AnaLog -X- _ B-DatasetName
into -X- _ O
a -X- _ O
main -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
set -X- _ O
using -X- _ O
an -X- _ O
80-20 -X- _ B-HyperparameterValue
split. -X- _ O

Diagnostic -X- _ O
probes -X- _ O
are -X- _ O
known -X- _ O
for -X- _ O
achieving -X- _ O
high -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
linguistic -X- _ O
tasks -X- _ O
despite -X- _ O
representations -X- _ O
not -X- _ O
necessarily -X- _ O
encoding -X- _ O
relevant -X- _ O
linguistic -X- _ O
information -X- _ O
(Hewitt -X- _ O
and -X- _ O
Liang, -X- _ O
2019b; -X- _ O
Belinkov, -X- _ O
2021). -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue, -X- _ O
following -X- _ O
the -X- _ O
approach -X- _ O
taken -X- _ O
by -X- _ O
Zhang -X- _ O
and -X- _ O
Bowman -X- _ O
(2018), -X- _ O
we -X- _ O
measure -X- _ O
probing -X- _ O
performance -X- _ O
as -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
classification -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
probing -X- _ O
classifier -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
dataset, -X- _ O
and -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
a -X- _ O
baseline. -X- _ O
We -X- _ O
call -X- _ O
this -X- _ O
baselined -X- _ O
probing -X- _ O
performance -X- _ O
(BPP), -X- _ O
adopting -X- _ O
the -X- _ O
terminology -X- _ O
proposed -X- _ O
by -X- _ O
Hewitt -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

For -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
StructBERT, -X- _ B-MethodName
we -X- _ O
prepend -X- _ O
the -X- _ O
[CLS] -X- _ O
token; -X- _ O
for -X- _ O
GPT-2, -X- _ B-MethodName
we -X- _ O
append -X- _ O
the -X- _ O
<|endoftext|> -X- _ O
token; -X- _ O
for -X- _ O
LUKE, -X- _ B-MethodName
we -X- _ O
append -X- _ O
the -X- _ O
token. -X- _ O

We -X- _ O
fit -X- _ O
a -X- _ O
binary -X- _ O
logistic -X- _ O
regression -X- _ O
classifier6‚Äîas -X- _ O
more -X- _ O
powerful -X- _ O
classifiers -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
produce -X- _ O
unreliable -X- _ O
results -X- _ O
(Hewitt -X- _ O
and -X- _ O
Liang, -X- _ O
2019a)‚Äîto -X- _ O
the -X- _ O
training -X- _ O
set, -X- _ O
obtain -X- _ O
predictions -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
set, -X- _ O
and -X- _ O
compute -X- _ O
accuracy -X- _ O
and -X- _ O
baselined -X- _ O
probing -X- _ O
scores, -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
section. -X- _ O

GPT-2 -X- _ B-MethodName
(Radford -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
An -X- _ O
autoregressive -X- _ O
Transformer-based -X- _ O
LM -X- _ O
which -X- _ O
is -X- _ O
known -X- _ O
for -X- _ O
its -X- _ O
high -X- _ O
performance -X- _ O
across -X- _ O
text-generation -X- _ O
tasks, -X- _ O
yet -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
frequently -X- _ O
tested -X- _ O
on -X- _ O
NLI -X- _ O
datasets. -X- _ O

We -X- _ O
expect -X- _ O
StructBERT -X- _ B-MethodName
to -X- _ O
provide -X- _ O
insight -X- _ O
on -X- _ O
whether -X- _ O
structural -X- _ O
cues -X- _ O
are -X- _ O
useful -X- _ O
in -X- _ O
solving -X- _ O
logic-based -X- _ O
NLI. -X- _ O

This -X- _ O
enables -X- _ O
LMs -X- _ O
to -X- _ O
output -X- _ O
representations -X- _ O
that -X- _ O
are -X- _ O
as -X- _ O
stable -X- _ O
as -X- _ O
possible. -X- _ O

For -X- _ O
the -X- _ O
restrictor -X- _ O
noun -X- _ O
in -X- _ O
universal -X- _ O
quantification -X- _ O
premises -X- _ O
(e.g., -X- _ O
director -X- _ O
in -X- _ O
the -X- _ O
UNI -X- _ O
premise -X- _ O
in -X- _ O
Table -X- _ O
1), -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
four -X- _ O
most -X- _ O
common -X- _ O
nouns -X- _ O
in -X- _ O
COCA -X- _ B-DatasetName
(Davies, -X- _ O
2010) -X- _ O
which -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
category -X- _ O
NOUN.PERSON -X- _ O
in -X- _ O
Wordnet -X- _ B-DatasetName
(Fellbaum, -X- _ O
1998), -X- _ O
do -X- _ O
not -X- _ O
begin -X- _ O
with -X- _ O
a -X- _ O
vowel, -X- _ O
and -X- _ O
are -X- _ O
semantically -X- _ O
compatible -X- _ O
with -X- _ O
our -X- _ O
predicates. -X- _ O

This -X- _ O
is -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
both -X- _ O
SuperGLUE -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
where -X- _ O
the -X- _ O
logical -X- _ O
connectives -X- _ O
vary -X- _ O
between -X- _ O
being -X- _ O
positioned -X- _ O
in -X- _ O
the -X- _ O
premise -X- _ O
or -X- _ O
hypothesis, -X- _ O
and -X- _ O
LogicNLI -X- _ B-MethodName
(Tian -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
where -X- _ O
premises -X- _ O
consist -X- _ O
of -X- _ O
multiple -X- _ O
facts -X- _ O
and -X- _ O
rules -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
isolate -X- _ O
logical -X- _ O
connectives. -X- _ O

We -X- _ O
extend -X- _ O
the -X- _ O
LAKNLI -X- _ B-DatasetName
dataset -X- _ O
(Ryb -X- _ O
and -X- _ O
Van -X- _ O
Schijndel, -X- _ O
2021) -X- _ O
and -X- _ O
present -X- _ O
AnaLog, -X- _ B-TaskName
an -X- _ O
NLI -X- _ O
dataset -X- _ O
that -X- _ O
explicitly -X- _ O
targets -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
logical -X- _ B-TaskName
reasoning. -X- _ I-TaskName

Yet, -X- _ O
Kim -X- _ O
et -X- _ O
al. -X- _ O
(2019b) -X- _ O
showed -X- _ O
that -X- _ O
BERT‚Äôs -X- _ B-MethodName
performance -X- _ O
is -X- _ O
only -X- _ O
11% -X- _ B-MetricValue
less -X- _ O
than -X- _ O
human -X- _ B-MethodName
performance -X- _ I-MethodName
on -X- _ O
comparative -X- _ B-TaskName
reasoning -X- _ I-TaskName
tasks, -X- _ O
and -X- _ O
10% -X- _ B-MetricValue
less -X- _ O
than -X- _ O
human -X- _ B-MethodName
performance -X- _ I-MethodName
on -X- _ O
spatial -X- _ B-TaskName
reasoning -X- _ I-TaskName
tasks. -X- _ O

Finally, -X- _ O
regarding -X- _ O
universal -X- _ O
quantification, -X- _ O
which -X- _ O
implicitly -X- _ O
involves -X- _ O
encoding -X- _ O
a -X- _ O
hidden -X- _ O
conditional -X- _ O
statement -X- _ O
(e.g. -X- _ O
‚àÄx.P(x) -X- _ O
‚Üí -X- _ O
Q(x)), -X- _ O
BERT‚Äôs -X- _ B-MethodName
performance -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
vary -X- _ O
substantially -X- _ O
(Kim -X- _ O
et -X- _ O
al., -X- _ O
2019b; -X- _ O
Tian -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Kim -X- _ O
et -X- _ O
al. -X- _ O
(2019b) -X- _ O
showed -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
achieves -X- _ O
10% -X- _ O
higher -X- _ O
accuracy -X- _ B-MetricName
than -X- _ O
humans -X- _ O
on -X- _ O
tasks -X- _ O
that -X- _ O
involve -X- _ O
conjunctions. -X- _ O

We -X- _ O
analyse -X- _ O
the -X- _ O
behaviour -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
model, -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
across -X- _ O
the -X- _ O
various -X- _ O
inference -X- _ O
categories -X- _ O
present -X- _ O
in -X- _ O
AnaLog, -X- _ B-TaskName
finding -X- _ O
that -X- _ O
its -X- _ O
reasoning -X- _ O
abilities -X- _ O
go -X- _ O
beyond -X- _ O
shallow -X- _ O
heuristics -X- _ O
and -X- _ O
yield -X- _ O
relatively -X- _ O
consistent -X- _ O
performance -X- _ O
on -X- _ O
deductive -X- _ O
and -X- _ O
analytical -X- _ O
reasoning, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
across -X- _ O
reasoning -X- _ O
domains -X- _ O
(spatial -X- _ O
and -X- _ O
comparative) -X- _ O
and -X- _ O
logical -X- _ O
connectives. -X- _ O

To -X- _ O
do -X- _ O
so, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
new -X- _ O
NLI -X- _ O
task, -X- _ O
AnaLog, -X- _ B-TaskName
1 -X- _ O
that -X- _ O
requires -X- _ O
LMs -X- _ O
to -X- _ O
encode -X- _ O
different -X- _ O
logical -X- _ O
reasoning -X- _ O
patterns -X- _ O
and -X- _ O
we -X- _ O
probe -X- _ O
the -X- _ O
behaviour -X- _ O
of -X- _ O
four -X- _ O
masked -X- _ O
and -X- _ O
autoregressive -X- _ O
LMs -X- _ O
on -X- _ O
this -X- _ O
new -X- _ O
dataset. -X- _ O

Yet, -X- _ O
LMs -X- _ O
typically -X- _ O
learn -X- _ O
to -X- _ O
solve -X- _ O
NLI -X- _ O
by -X- _ O
using -X- _ O
invalid -X- _ O
heuristics, -X- _ O
for -X- _ O
example -X- _ O
by -X- _ O
extracting -X- _ O
overlapping -X- _ O
patterns -X- _ O
between -X- _ O
premises -X- _ O
and -X- _ O
hypotheses -X- _ O
(McCoy -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
or -X- _ O
by -X- _ O
using -X- _ O
specific -X- _ O
lexical -X- _ O
items -X- _ O
and -X- _ O
sentence -X- _ O
grammaticality -X- _ O
as -X- _ O
simplistic -X- _ O
predictors -X- _ O
of -X- _ O
entailment -X- _ O
(Poliak -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

One -X- _ O
way -X- _ O
of -X- _ O
verifying -X- _ O
LMs‚Äô -X- _ O
reasoning -X- _ O
abilities -X- _ O
is -X- _ O
using -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
(NLI) -X- _ O
task -X- _ O
(Dagan -X- _ O
et -X- _ O
al., -X- _ O
2005; -X- _ O
Giampiccolo -X- _ O
et -X- _ O
al., -X- _ O
2007; -X- _ O
Bowman -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Bhagavatula -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Rudinger -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Because -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
approaches -X- _ O
to -X- _ O
these -X- _ O
tasks -X- _ O
rely -X- _ O
on -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
(LMs), -X- _ O
it -X- _ O
is -X- _ O
essential -X- _ O
to -X- _ O
understand -X- _ O
whether -X- _ O
LMs -X- _ O
can -X- _ O
perform -X- _ O
logical -X- _ B-TaskName
reasoning. -X- _ I-TaskName

Logical -X- _ B-TaskName
reasoning -X- _ I-TaskName
(Lakoff, -X- _ O
1970; -X- _ O
MacCartney -X- _ O
and -X- _ O
Manning, -X- _ O
2007; -X- _ O
Smith, -X- _ O
2020) -X- _ O
is -X- _ O
at -X- _ O
the -X- _ O
core -X- _ O
of -X- _ O
many -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ O
dialogue -X- _ B-TaskName
and -X- _ I-TaskName
story -X- _ I-TaskName
generation -X- _ I-TaskName
(Fan -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Welleck -X- _ O
et -X- _ O
al., -X- _ O
2019); -X- _ O
narrative -X- _ B-TaskName
understanding -X- _ I-TaskName
and -X- _ I-TaskName
summarisation -X- _ I-TaskName
(Mostafazadeh -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Vashishtha -X- _ O
et -X- _ O
al., -X- _ O
2020); -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
(Weber -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Shi -X- _ O
et -X- _ O
al., -X- _ O
2021); -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
(Massey -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Kassner -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Yanaka -X- _ O
et -X- _ O
al., -X- _ O
2021); -X- _ O
and -X- _ O
visual -X- _ B-TaskName
comprehension -X- _ I-TaskName
(Suhr -X- _ O
et -X- _ O
al., -X- _ O
2017, -X- _ O
2019; -X- _ O
Sethuraman -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

We -X- _ O
present -X- _ O
AnaLog, -X- _ B-TaskName
a -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
task -X- _ O
designed -X- _ O
to -X- _ O
probe -X- _ O
models -X- _ O
for -X- _ O
these -X- _ O
capabilities, -X- _ O
controlling -X- _ O
for -X- _ O
different -X- _ O
invalid -X- _ O
heuristics -X- _ O
the -X- _ O
models -X- _ O
may -X- _ O
adopt -X- _ O
instead -X- _ O
of -X- _ O
learning -X- _ O
the -X- _ O
desired -X- _ O
generalisations. -X- _ O

From -X- _ O
Table -X- _ O
3, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
Radical-added -X- _ B-MethodName
CGE -X- _ I-MethodName
obtains -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
Wordsim-240 -X- _ B-DatasetName
dataset, -X- _ O
outperforming -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
Word2vec -X- _ B-MethodName
by -X- _ O
0.0111. -X- _ O

We -X- _ O
compute -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
(Myers -X- _ O
et -X- _ O
al., -X- _ O
2010) -X- _ O
between -X- _ O
the -X- _ O
human-labeled -X- _ O
scores -X- _ O
and -X- _ O
similarity -X- _ O
scores -X- _ O
computed -X- _ O
by -X- _ O
embeddings. -X- _ O

The -X- _ O
similarity -X- _ O
embedding -X- _ O
score -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
pair -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
of -X- _ O
their -X- _ O
embeddings. -X- _ O

However, -X- _ O
we -X- _ O
confirm -X- _ O
that -X- _ O
no -X- _ O
stereotype -X- _ O
examples -X- _ O
exist -X- _ O
in -X- _ O
Chinese -X- _ B-DatasetName
Wordsim-240 -X- _ I-DatasetName
and -X- _ O
wordsim-295. -X- _ B-DatasetName

We -X- _ O
select -X- _ O
two -X- _ O
different -X- _ O
Chinese -X- _ O
word -X- _ O
similarity -X- _ O
datasets, -X- _ O
i.e., -X- _ O
Wordsim-240 -X- _ B-DatasetName
and -X- _ O
Wordsim-295 -X- _ B-DatasetName
provided -X- _ O
by -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
(2015). -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
Clopper-Pearson -X- _ B-MetricName
confidence -X- _ I-MetricName
intervals -X- _ O
following -X- _ O
Kaneko -X- _ O
and -X- _ O
Bollegala -X- _ O
(2019) -X- _ O
to -X- _ O
do -X- _ O
the -X- _ O
significance -X- _ O
test. -X- _ O

We -X- _ O
select -X- _ O
the -X- _ O
word-pair -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
cosine -X- _ O
similarity -X- _ O
with -X- _ O
# -X- _ O
¬ªhe -X- _ O
‚àí -X- _ O
# -X- _ O
¬ª -X- _ O
she -X- _ O
as -X- _ O
the -X- _ O
predicted -X- _ O
answer. -X- _ O

We -X- _ O
name -X- _ O
the -X- _ O
outof-domain -X- _ O
test -X- _ O
dataset -X- _ O
as -X- _ O
CSemBias-subset. -X- _ B-DatasetName

CSemBias -X- _ B-DatasetName
contains -X- _ O
20 -X- _ O
gender-stereotype -X- _ O
word -X- _ O
pairs -X- _ O
and -X- _ O
22 -X- _ O
gender-definitional -X- _ O
word -X- _ O
pairs, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
their -X- _ O
Cartesian -X- _ O
product -X- _ O
to -X- _ O
generate -X- _ O
440 -X- _ O
instances. -X- _ O

Concretely, -X- _ O
we -X- _ O
hire -X- _ O
three -X- _ O
native -X- _ O
Chinese -X- _ O
speakers -X- _ O
to -X- _ O
translate -X- _ O
the -X- _ O
original -X- _ O
English -X- _ B-DatasetName
SemBias -X- _ I-DatasetName
(Zhao -X- _ O
et -X- _ O
al., -X- _ O
2018b) -X- _ O
dataset -X- _ O
to -X- _ O
the -X- _ O
Chinese -X- _ O
version. -X- _ O

To -X- _ O
evaluate -X- _ O
debiasing -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model, -X- _ O
we -X- _ O
come -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
named -X- _ O
CSemBias -X- _ B-DatasetName
(Chinese -X- _ B-DatasetName
SemBias). -X- _ I-DatasetName

Words -X- _ O
with -X- _ O
a -X- _ O
frequency -X- _ B-HyperparameterName
of -X- _ O
less -X- _ O
than -X- _ O
5 -X- _ B-HyperparameterValue
were -X- _ O
ignored -X- _ O
during -X- _ O
training. -X- _ O

For -X- _ O
all -X- _ O
models, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
parameter -X- _ O
settings. -X- _ O
Following -X- _ O
Yu -X- _ O
et -X- _ O
al. -X- _ O
(2017), -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
word -X- _ B-HyperparameterName
vector -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
to -X- _ O
200, -X- _ B-HyperparameterValue
the -X- _ O
window -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
5, -X- _ B-HyperparameterValue
the -X- _ O
training -X- _ B-HyperparameterName
iteration -X- _ I-HyperparameterName
to -X- _ O
100, -X- _ B-HyperparameterValue
the -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
0.025, -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
subsampling -X- _ B-HyperparameterName
parameter -X- _ I-HyperparameterName
to -X- _ O
10‚àí4 -X- _ B-HyperparameterValue
. -X- _ O

To -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
other -X- _ O
structure-based -X- _ O
Chinese -X- _ O
embedding -X- _ O
models, -X- _ O
we -X- _ O
include -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
other -X- _ O
models -X- _ O
that -X- _ O
also -X- _ O
incorporate -X- _ O
component -X- _ O
information: -X- _ O
CWE -X- _ B-MethodName
is -X- _ O
a -X- _ O
character-enhanced -X- _ O
word -X- _ O
embedding -X- _ O
model -X- _ O
presented -X- _ O
in -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
(2015); -X- _ O
MGE -X- _ B-MethodName
and -X- _ O
JWE -X- _ B-MethodName
are -X- _ O
multi-granularity -X- _ O
embedding -X- _ O
model -X- _ O
that -X- _ O
make -X- _ O
full -X- _ O
use -X- _ O
of -X- _ O
word-character-radical -X- _ O
composition -X- _ O
(Yin -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Yu -X- _ O
et -X- _ O
al., -X- _ O
2017); -X- _ O
RECWE -X- _ B-MethodName
is -X- _ O
a -X- _ O
radical -X- _ O
enhanced -X- _ O
word -X- _ O
embedding -X- _ O
model -X- _ O
(Chen -X- _ O
and -X- _ O
Hu, -X- _ O
2018). -X- _ O

GP(GloVe) -X- _ B-MethodName
and -X- _ O
GP(GN): -X- _ B-MethodName
aims -X- _ O
to -X- _ O
remove -X- _ O
gender -X- _ O
biases -X- _ O
from -X- _ O
pre-trained -X- _ O
word -X- _ O
embeddings -X- _ O
GloVe -X- _ B-MethodName
and -X- _ O
GN-GloVe -X- _ B-MethodName
(Kaneko -X- _ O
and -X- _ O
Bollegala, -X- _ O
2019). -X- _ O

GN-GloVe: -X- _ B-MethodName
preserves -X- _ O
gender -X- _ O
information -X- _ O
in -X- _ O
certain -X- _ O
dimensions -X- _ O
of -X- _ O
embeddings -X- _ O
(Zhao -X- _ O
et -X- _ O
al., -X- _ O
2018b). -X- _ O

Hard-GloVe: -X- _ B-MethodName
we -X- _ O
use -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
hard-debiasing -X- _ O
(Bolukbasi -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
method -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
debiased -X- _ O
version -X- _ O
of -X- _ O
GloVe -X- _ B-MethodName
embeddings. -X- _ O

Along -X- _ O
with -X- _ O
each -X- _ O
character -X- _ O
is -X- _ O
its -X- _ O
radical, -X- _ O
and -X- _ O
we -X- _ O
crawled -X- _ O
the -X- _ O
radical -X- _ O
information -X- _ O
of -X- _ O
each -X- _ O
character -X- _ O
from -X- _ O
HTTPCN. -X- _ O

We -X- _ O
add -X- _ O
all -X- _ O
words -X- _ O
in -X- _ O
CSemBias -X- _ B-DatasetName
in -X- _ O
the -X- _ O
tokenize -X- _ O
vocab -X- _ O
dictionary -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
the -X- _ O
gender-related -X- _ O
words -X- _ O
are -X- _ O
successfully -X- _ O
recognized. -X- _ O

JIEBA -X- _ B-MethodName
is -X- _ O
used -X- _ O
for -X- _ O
Chinese -X- _ O
word -X- _ O
segmentation -X- _ O
and -X- _ O
POS -X- _ O
tagging. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
1GB -X- _ O
Chinese -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
Dump1 -X- _ I-DatasetName
as -X- _ O
our -X- _ O
training -X- _ O
corpus. -X- _ O

Table -X- _ O
1: -X- _ O
Representative -X- _ O
cases -X- _ O
in -X- _ O
CSemBias -X- _ B-DatasetName
dataset. -X- _ O

The -X- _ O
pivotal -X- _ O
idea -X- _ O
of -X- _ O
Radical-added -X- _ B-MethodName
CGE -X- _ I-MethodName
is -X- _ O
to -X- _ O
replace -X- _ O
the -X- _ O
stored -X- _ O
vectors -X- _ O
xt -X- _ O
in -X- _ O
CBOW -X- _ B-MethodName
with -X- _ O
realtime -X- _ O
compositions -X- _ O
of -X- _ O
wt -X- _ O
and -X- _ O
rt -X- _ O
, -X- _ O
but -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
objective -X- _ O
in -X- _ O
Equation -X- _ O
1. -X- _ O

Concretely, -X- _ O
given -X- _ O
the -X- _ O
word -X- _ O
sequence -X- _ O
D -X- _ O
= -X- _ O
(x1, -X- _ O
x2, -X- _ O
..., -X- _ O
xT -X- _ O
), -X- _ O
the -X- _ O
ultimate -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
average -X- _ O
log -X- _ O
probablity: -X- _ O
1 -X- _ O
T -X- _ O
PT -X- _ O
‚àíc -X- _ O
t=c -X- _ O
log -X- _ O
P(xt -X- _ O
|xt‚àíc, -X- _ O
..., -X- _ O
xt+c), -X- _ O
(1) -X- _ O
where -X- _ O
c -X- _ O
is -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
context. -X- _ I-HyperparameterName

We -X- _ O
will -X- _ O
take -X- _ O
CBOW -X- _ B-MethodName
for -X- _ O
example -X- _ O
and -X- _ O
demonstrate -X- _ O
our -X- _ O
frameworks -X- _ O
based -X- _ O
on -X- _ O
CBOW. -X- _ B-MethodName

Gender -X- _ O
bias -X- _ O
also -X- _ O
exists -X- _ O
in -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
(Prates -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
e.g., -X- _ O
translating -X- _ O
nurses -X- _ O
as -X- _ O
females -X- _ O
and -X- _ O
programmers -X- _ O
as -X- _ O
males, -X- _ O
regardless -X- _ O
of -X- _ O
context. -X- _ O

Following -X- _ O
this -X- _ O
work, -X- _ O
Yin -X- _ O
et -X- _ O
al. -X- _ O
(2016) -X- _ O
proposed -X- _ O
multi-granularity -X- _ B-MethodName
embedding -X- _ I-MethodName
(MGE), -X- _ B-MethodName
which -X- _ O
enriches -X- _ O
word -X- _ O
embeddings -X- _ O
by -X- _ O
incorporating -X- _ O
finer-grained -X- _ O
semantics -X- _ O
from -X- _ O
characters -X- _ O
and -X- _ O
radicals. -X- _ O

Chen -X- _ O
et -X- _ O
al. -X- _ O
(2015) -X- _ O
first -X- _ O
presented -X- _ O
a -X- _ O
character-enhanced -X- _ B-MethodName
word -X- _ I-MethodName
embedding -X- _ I-MethodName
model -X- _ O
(CWE). -X- _ O

CGE -X- _ B-MethodName
has -X- _ O
two -X- _ O
variations, -X- _ O
i.e., -X- _ O
Radical-added -X- _ B-MethodName
CGE -X- _ I-MethodName
and -X- _ O
Radical-enhanced -X- _ B-MethodName
CGE. -X- _ I-MethodName

Concretely, -X- _ O
CGE -X- _ B-MethodName
utilizes -X- _ O
and -X- _ O
emphasizes -X- _ O
the -X- _ O
rich -X- _ O
feminine -X- _ O
and -X- _ O
masculine -X- _ O
information -X- _ O
contained -X- _ O
in -X- _ O
radicals, -X- _ O
i.e., -X- _ O
a -X- _ O
kind -X- _ O
of -X- _ O
component -X- _ O
in -X- _ O
Chinese -X- _ O
characters, -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
procedure. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
first -X- _ O
Chinese -X- _ B-MethodName
Gender-neutral -X- _ I-MethodName
word -X- _ I-MethodName
Embedding -X- _ I-MethodName
model -X- _ O
(CGE) -X- _ O
based -X- _ O
on -X- _ O
Word2vec, -X- _ B-MethodName
which -X- _ O
learns -X- _ O
gender-neutral -X- _ O
word -X- _ O
embeddings -X- _ O
without -X- _ O
any -X- _ O
labeled -X- _ O
data. -X- _ O

We -X- _ O
use -X- _ O
Sparse-Corroborate-Dense, -X- _ B-MethodName
which -X- _ O
piggybacks -X- _ O
on -X- _ O
dense -X- _ O
retrieval -X- _ O
results, -X- _ O
but -X- _ O
boosts -X- _ O
the -X- _ O
ranking -X- _ O
of -X- _ O
some -X- _ O
passages -X- _ O
in -X- _ O
dense -X- _ O
retrieval, -X- _ O
and -X- _ O
add -X- _ O
in -X- _ O
additional -X- _ O
passages -X- _ O
not -X- _ O
found -X- _ O
by -X- _ O
dense -X- _ O
retrieval -X- _ O
to -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
top-K -X- _ B-HyperparameterName
list. -X- _ O

The -X- _ O
context -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
(number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
passages) -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
final -X- _ O
submission -X- _ O
is -X- _ O
20 -X- _ B-HyperparameterValue
passages. -X- _ O

Instead -X- _ O
of -X- _ O
concatenating -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
all -X- _ O
the -X- _ O
passages -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
encoder -X- _ O
like -X- _ O
in -X- _ O
the -X- _ O
baseline, -X- _ O
which -X- _ O
we -X- _ O
will -X- _ O
call -X- _ O
Fusion-in-Encoder, -X- _ B-MethodName
we -X- _ O
use -X- _ O
the -X- _ O
Fusion-in-Decoder -X- _ B-MethodName
(FiD) -X- _ B-MethodName
approach -X- _ O
(Izacard -X- _ O
and -X- _ O
Grave, -X- _ O
2020). -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
Hugging -X- _ O
Face -X- _ O
transformers -X- _ O
(Wolf -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
versions -X- _ O
of -X- _ O
mluke-base -X- _ B-MethodName
and -X- _ O
bert-base-multilingual-uncased. -X- _ B-MethodName

First, -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
retrieval -X- _ O
step, -X- _ O
we -X- _ O
replace -X- _ O
mBERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
with -X- _ O
mLUKE -X- _ B-MethodName
(Ri -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

We -X- _ O
merge -X- _ O
these -X- _ O
dense -X- _ O
retrieval -X- _ O
hits -X- _ O
with -X- _ O
BM25 -X- _ B-MethodName
sparse -X- _ O
retrieval -X- _ O
hits -X- _ O
using -X- _ O
an -X- _ O
algorithm -X- _ O
we -X- _ O
call -X- _ O
Sparse-Corroborate-Dense. -X- _ B-MethodName

LSTM -X- _ B-MethodName
is -X- _ O
a -X- _ O
type -X- _ O
of -X- _ O
recurrent -X- _ B-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
(RNN) -X- _ B-MethodName
that -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
underlying -X- _ O
features -X- _ O
in -X- _ O
temporal -X- _ O
data -X- _ O
without -X- _ O
the -X- _ O
added -X- _ O
drawbacks -X- _ O
of -X- _ O
general -X- _ O
RNN -X- _ B-MethodName
models -X- _ O
such -X- _ O
as -X- _ O
exploding -X- _ O
or -X- _ O
vanishing -X- _ O
gradients. -X- _ O

The -X- _ O
weighting -X- _ O
factor -X- _ O
for -X- _ O
each -X- _ O
class -X- _ O
was -X- _ O
identified -X- _ O
as -X- _ O
per -X- _ O
the -X- _ O
following -X- _ O
definition: -X- _ O
(1 -X- _ O
‚àí -X- _ O
Œ≤)/(1 -X- _ O
‚àí -X- _ O
Œ≤ -X- _ O
ni -X- _ O
) -X- _ O
(1) -X- _ O
where -X- _ O
Œ≤ -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
hyper-parameter -X- _ O
in -X- _ O
[0,1), -X- _ B-HyperparameterValue
and -X- _ O
ni -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
belonging -X- _ O
to -X- _ O
the -X- _ O
class -X- _ O
i. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
cost-sensitive -X- _ B-MethodName
re-weighting -X- _ I-MethodName
technique -X- _ O
developed -X- _ O
by -X- _ O
Cui -X- _ O
et -X- _ O
al -X- _ O
(Cui -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
suggested -X- _ O
by -X- _ O
Jurkiewicz -X- _ O
et -X- _ O
al -X- _ O
(Jurkiewicz -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
was -X- _ O
adopted. -X- _ O

The -X- _ O
"The -X- _ B-DatasetName
Don‚Äôt -X- _ I-DatasetName
Patronize -X- _ I-DatasetName
Me!" -X- _ I-DatasetName
dataset -X- _ O
offers -X- _ O
primarily -X- _ O
three -X- _ O
major -X- _ O
challenges, -X- _ O
which -X- _ O
are, -X- _ O
low -X- _ O
number -X- _ O
of -X- _ O
samples, -X- _ O
high -X- _ O
class -X- _ O
imbalance -X- _ O
and -X- _ O
the -X- _ O
low -X- _ O
context -X- _ O
in -X- _ O
the -X- _ O
textual -X- _ O
data -X- _ O
(smaller -X- _ O
sentence -X- _ O
length). -X- _ O

For -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
presented -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
"The -X- _ B-DatasetName
Don‚Äôt -X- _ I-DatasetName
Patronize -X- _ I-DatasetName
Me!" -X- _ I-DatasetName
dataset -X- _ O
(Perez-Almendros -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
was -X- _ O
used. -X- _ O

In -X- _ O
subtask-B -X- _ O
RoBERTa -X- _ B-MethodName
with -X- _ O
feed-forward -X- _ O
layers -X- _ O
got -X- _ O
the -X- _ O
best -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.3763 -X- _ B-MetricValue
as -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
variations. -X- _ O

For -X- _ O
subtask-A -X- _ O
RoBERTa -X- _ B-MethodName
with -X- _ O
LSTM, -X- _ B-MethodName
CNN -X- _ B-MethodName
and -X- _ O
feed-forward -X- _ O
layers -X- _ O
outperformed -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
variations -X- _ O
with -X- _ O
an -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.5924. -X- _ B-MetricValue

We -X- _ O
train -X- _ O
our -X- _ O
system -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
score -X- _ I-MetricName
s -X- _ B-MetricName
between -X- _ O
a -X- _ O
MWE -X- _ O
e -X- _ O
and -X- _ O
its -X- _ O
context -X- _ O
c, -X- _ O
which -X- _ O
is -X- _ O
s -X- _ B-MetricName
= -X- _ O
‚àí1 -X- _ B-MetricValue
when -X- _ O
e -X- _ O
is -X- _ O
idiomatic -X- _ O
in -X- _ O
c, -X- _ O
or -X- _ O
s -X- _ B-MetricName
= -X- _ O
1 -X- _ B-MetricValue
otherwise. -X- _ O

Our -X- _ O
final -X- _ O
scores -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
ensembling -X- _ O
the -X- _ O
predictions -X- _ O
of -X- _ O
N -X- _ B-HyperparameterName
= -X- _ O
9 -X- _ B-HyperparameterValue
model -X- _ O
checkpoints -X- _ O
and -X- _ O
taking -X- _ O
the -X- _ O
class -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
number -X- _ O
of -X- _ O
votes. -X- _ O

To -X- _ O
identify -X- _ O
entities, -X- _ O
instead, -X- _ O
we -X- _ O
employ -X- _ O
wikineural-multilingual-ner, -X- _ B-MethodName
a -X- _ O
Multilingual -X- _ B-MethodName
BERT -X- _ I-MethodName
(mBERT) -X- _ B-MethodName
model -X- _ O
fine-tuned -X- _ O
on -X- _ O
the -X- _ O
WikiNEuRal -X- _ B-DatasetName
dataset -X- _ O
(Tedeschi -X- _ O
et -X- _ O
al., -X- _ O
2021b). -X- _ O

Specifically, -X- _ O
we -X- _ O
successfully -X- _ O
tackle -X- _ O
the -X- _ O
idiom -X- _ B-TaskName
identification -X- _ I-TaskName
task -X- _ O
by -X- _ O
introducing -X- _ O
a -X- _ O
two-step -X- _ O
system -X- _ O
that: -X- _ O
i) -X- _ O
uses -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
(NER) -X- _ B-TaskName
to -X- _ O
pre-identify -X- _ O
non-idiomatic -X- _ O
expressions, -X- _ O
and -X- _ O
ii) -X- _ O
exploits -X- _ O
a -X- _ O
novel -X- _ O
Transformer-based -X- _ O
dual-encoder -X- _ O
architecture -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
semantic -X- _ O
similarities -X- _ O
between -X- _ O
the -X- _ O
remaining -X- _ O
potentially-idiomatic -X- _ O
expressions -X- _ O
and -X- _ O
their -X- _ O
contexts -X- _ O
and, -X- _ O
based -X- _ O
on -X- _ O
these, -X- _ O
predict -X- _ O
idiomaticity. -X- _ O

Specifically, -X- _ O
the -X- _ O
organizers -X- _ O
propose -X- _ O
two -X- _ O
subtasks: -X- _ O
‚Ä¢ -X- _ O
Subtask -X- _ O
A: -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
task -X- _ O
in -X- _ O
which -X- _ O
potentially-idiomatic -X- _ O
expressions -X- _ O
(PIEs) -X- _ O
must -X- _ O
be -X- _ O
labeled -X- _ O
as -X- _ O
either -X- _ O
"Idiomatic" -X- _ O
or -X- _ O
"Literal", -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
they -X- _ O
appear -X- _ O
in. -X- _ O
To -X- _ O
better -X- _ O
test -X- _ O
models‚Äô -X- _ O
generalization -X- _ O
capabilities, -X- _ O
two -X- _ O
different -X- _ O
settings -X- _ O
are -X- _ O
provided: -X- _ O
zero-shot -X- _ O
and -X- _ O
one-shot; -X- _ O
‚Ä¢ -X- _ O
Subtask -X- _ O
B: -X- _ O
requires -X- _ O
models -X- _ O
to -X- _ O
output -X- _ O
the -X- _ O
correct -X- _ O
Semantic -X- _ B-MetricName
Text -X- _ I-MetricName
Similarity -X- _ I-MetricName
(STS) -X- _ B-MetricName
scores -X- _ O
between -X- _ O
sentence -X- _ O
pairs -X- _ O
based -X- _ O
on -X- _ O
whether -X- _ O
or -X- _ O
not -X- _ O
each -X- _ O
sentence -X- _ O
contains -X- _ O
an -X- _ O
idiomatic -X- _ O
expression. -X- _ O
Subtask -X- _ O
B -X- _ O
is -X- _ O
also -X- _ O
available -X- _ O
in -X- _ O
two -X- _ O
settings: -X- _ O
pre-train -X- _ O
and -X- _ O
fine-tune. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
subtask -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
Transformer-based -X- _ O
dual-encoder -X- _ O
architecture -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
semantic -X- _ O
similarity -X- _ O
between -X- _ O
a -X- _ O
potentially-idiomatic -X- _ O
expression -X- _ O
and -X- _ O
its -X- _ O
context -X- _ O
and, -X- _ O
based -X- _ O
on -X- _ O
this, -X- _ O
predict -X- _ O
idiomaticity. -X- _ O

We -X- _ O
conducted -X- _ O
hyperparameter -X- _ O
optimization -X- _ O
using -X- _ O
the -X- _ O
HyperOpt -X- _ O
package -X- _ O
(Bergstra -X- _ O
et -X- _ O
al., -X- _ O
2013), -X- _ O
using -X- _ O
population-based -X- _ O
training -X- _ O
(Jaderberg -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

We -X- _ O
used -X- _ O
BertTokenizerFast -X- _ B-MethodName
to -X- _ O
tokenize -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
fine-tuned -X- _ O
on -X- _ O
the -X- _ O
pre-trained -X- _ O
BertForSequenceClassification -X- _ B-MethodName
model, -X- _ O
both -X- _ O
from -X- _ O
the -X- _ O
HuggingFace -X- _ O
Transformers -X- _ O
library -X- _ O
(Wolf -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Due -X- _ O
to -X- _ O
the -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
second -X- _ O
subtask, -X- _ O
we -X- _ O
also -X- _ O
chose -X- _ O
to -X- _ O
apply -X- _ O
transfer -X- _ O
learning -X- _ O
and -X- _ O
start -X- _ O
our -X- _ O
training -X- _ O
from -X- _ O
the -X- _ O
fine-tuned -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
first -X- _ O
subtask. -X- _ O

We -X- _ O
initially -X- _ O
actually -X- _ O
tried -X- _ O
training -X- _ O
on -X- _ O
just -X- _ O
the -X- _ O
labeled -X- _ O
spans, -X- _ O
but -X- _ O
these -X- _ O
did -X- _ O
not -X- _ O
provide -X- _ O
enough -X- _ O
context -X- _ O
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
to -X- _ O
fine-tune -X- _ O
to -X- _ O
the -X- _ O
data. -X- _ O

Our -X- _ O
final -X- _ O
model -X- _ O
was -X- _ O
a -X- _ O
fine-tuned -X- _ O
BERT -X- _ B-MethodName
model. -X- _ O

Therefore, -X- _ O
we -X- _ O
began -X- _ O
with -X- _ O
a -X- _ O
bag-of-words -X- _ O
model -X- _ O
where -X- _ O
we -X- _ O
summed -X- _ O
the -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
text, -X- _ O
then -X- _ O
performed -X- _ O
logistic -X- _ O
regression -X- _ O
to -X- _ O
output -X- _ O
a -X- _ O
binary -X- _ O
label -X- _ O
indicating -X- _ O
whether -X- _ O
or -X- _ O
not -X- _ O
the -X- _ O
text -X- _ O
contained -X- _ O
PCL. -X- _ O

GloVe -X- _ B-MethodName
embeddings -X- _ O
are -X- _ O
good -X- _ O
at -X- _ O
capturing -X- _ O
word -X- _ O
analogies -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
global -X- _ O
vectorization -X- _ O
and -X- _ O
its -X- _ O
ability -X- _ O
to -X- _ O
capture -X- _ O
sub-linear -X- _ O
relationships -X- _ O
in -X- _ O
the -X- _ O
vector -X- _ O
space -X- _ O
(Pennington -X- _ O
et -X- _ O
al., -X- _ O
2014). -X- _ O

We -X- _ O
tried -X- _ O
two -X- _ O
approaches: -X- _ O
1) -X- _ O
using -X- _ O
pre-trained -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ O
with -X- _ O
a -X- _ O
dimension -X- _ O
of -X- _ O
300, -X- _ B-HyperparameterValue
which -X- _ O
track -X- _ O
co-occurences -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
global -X- _ O
corpus -X- _ O
(Pennington -X- _ O
et -X- _ O
al., -X- _ O
2014), -X- _ O
and -X- _ O
2) -X- _ O
tokenizing -X- _ O
the -X- _ O
paragraphs -X- _ O
using -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
tokenizer -X- _ O
and -X- _ O
inputting -X- _ O
these -X- _ O
into -X- _ O
a -X- _ O
pre-trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

We -X- _ O
specifically -X- _ O
focused -X- _ O
on -X- _ O
a -X- _ O
purely -X- _ O
textual -X- _ O
analysis -X- _ O
and -X- _ O
did -X- _ O
not -X- _ O
provide -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
any -X- _ O
metadata -X- _ O
to -X- _ O
see -X- _ O
if -X- _ O
the -X- _ O
model -X- _ O
could -X- _ O
learn -X- _ O
the -X- _ O
PCL -X- _ O
patterns -X- _ O
just -X- _ O
from -X- _ O
the -X- _ O
text, -X- _ O
because -X- _ O
although -X- _ O
real -X- _ O
world -X- _ O
usage -X- _ O
would -X- _ O
likely -X- _ O
include -X- _ O
those -X- _ O
features, -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
itself -X- _ O
would -X- _ O
be -X- _ O
useful -X- _ O
and -X- _ O
more -X- _ O
universally -X- _ O
applicable. -X- _ O

Our -X- _ O
system‚Äôs -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
use -X- _ O
contextualized -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
feed -X- _ O
the -X- _ O
model, -X- _ O
and -X- _ O
thus -X- _ O
have -X- _ O
the -X- _ O
model -X- _ O
analyze -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
text. -X- _ O

Results -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
approach -X- _ O
is -X- _ O
viable -X- _ O
for -X- _ O
binary -X- _ O
classification -X- _ O
of -X- _ O
PCL, -X- _ O
but -X- _ O
breaks -X- _ O
when -X- _ O
attempting -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
PCL -X- _ O
techniques. -X- _ O

However, -X- _ O
due -X- _ O
to -X- _ O
time -X- _ O
limitations, -X- _ O
we -X- _ O
only -X- _ O
used -X- _ O
the -X- _ O
20 -X- _ B-HyperparameterValue
passages -X- _ O
setting -X- _ O
for -X- _ O
the -X- _ O
final -X- _ O
shared -X- _ O
task -X- _ O
submission. -X- _ O

The -X- _ O
dense -X- _ O
retrieval -X- _ O
dual -X- _ O
encoder -X- _ O
used -X- _ O
is -X- _ O
mLUKE. -X- _ B-MethodName
max_frac -X- _ B-HyperparameterName
used -X- _ O
for -X- _ O
Sparse-Corroborate-Dense -X- _ B-MethodName
is -X- _ O
0.2. -X- _ B-HyperparameterValue

Compared -X- _ O
to -X- _ O
dense -X- _ O
only, -X- _ O
it -X- _ O
is -X- _ O
better -X- _ O
on -X- _ O
both -X- _ O
MRR -X- _ B-MetricName
and -X- _ O
recall. -X- _ B-MetricName

First, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
universe -X- _ O
set -X- _ O
of -X- _ O
answers -X- _ O
for -X- _ O
the -X- _ O
questions, -X- _ O
which -X- _ O
not -X- _ O
only -X- _ O
contain -X- _ O
answers -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
language, -X- _ O
but -X- _ O
also -X- _ O
possibly -X- _ O
answers -X- _ O
in -X- _ O
English -X- _ O
using -X- _ O
the -X- _ O
English -X- _ O
answer -X- _ O
in -X- _ O
the -X- _ O
XOR-English -X- _ B-TaskName
Span -X- _ I-TaskName
task -X- _ I-TaskName
(Asai -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

We -X- _ O
picked -X- _ O
60 -X- _ B-HyperparameterValue
because -X- _ O
it -X- _ O
is -X- _ O
the -X- _ O
near -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
passages -X- _ O
we -X- _ O
can -X- _ O
feed -X- _ O
into -X- _ O
Fusion-in-Decoder -X- _ B-MethodName
bound -X- _ O
by -X- _ O
the -X- _ O
GPU -X- _ O
memory. -X- _ O

To -X- _ O
evaluate -X- _ O
the -X- _ O
passage -X- _ O
retrieval -X- _ O
component -X- _ O
for -X- _ O
XOR-TyDi -X- _ B-DatasetName
QA, -X- _ I-DatasetName
we -X- _ O
measure -X- _ O
MRR@60 -X- _ B-MetricName
and -X- _ O
Recall@60. -X- _ B-MetricName

Finally, -X- _ O
the -X- _ O
smaller -X- _ O
gain -X- _ O
comes -X- _ O
from -X- _ O
switching -X- _ O
dense -X- _ O
retrieval -X- _ O
only -X- _ O
to -X- _ O
Sparse-Corroborate-Dense, -X- _ B-MethodName
from -X- _ O
row -X- _ O
(i) -X- _ O
to -X- _ O
mLUKE -X- _ B-MethodName
+ -X- _ O
SP -X- _ B-MethodName
+ -X- _ O
FiD. -X- _ B-MethodName

We -X- _ O
only -X- _ O
have -X- _ O
3101 -X- _ O
rows -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
Khmer -X- _ O
for -X- _ O
our -X- _ O
reader -X- _ O
all -X- _ O
from -X- _ O
Wikipedia -X- _ B-DatasetName
language -X- _ I-DatasetName
links, -X- _ I-DatasetName
out -X- _ O
of -X- _ O
275990 -X- _ O
rows -X- _ O
in -X- _ O
total. -X- _ O

On -X- _ O
both -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
and -X- _ O
test -X- _ O
set, -X- _ O
we -X- _ O
outperform -X- _ O
the -X- _ O
baseline -X- _ O
on -X- _ O
all -X- _ O
languages -X- _ O
except -X- _ O
for -X- _ O
Khmer -X- _ O
(km) -X- _ O
on -X- _ O
MKQA. -X- _ B-DatasetName

We -X- _ O
obtain -X- _ O
macroaveraged -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
21.99 -X- _ B-MetricValue
across -X- _ O
all -X- _ O
languages -X- _ O
on -X- _ O
MKQA, -X- _ B-DatasetName
an -X- _ O
improvement -X- _ O
of -X- _ O
4.61 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ O
over -X- _ O
17.38 -X- _ B-MetricValue
obtained -X- _ O
by -X- _ O
baseline -X- _ O
1. -X- _ O

On -X- _ O
the -X- _ O
development -X- _ O
set, -X- _ O
we -X- _ O
obtain -X- _ O
macro-averaged -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
43.46 -X- _ B-MetricValue
across -X- _ O
all -X- _ O
languages -X- _ O
on -X- _ O
XORTyDi -X- _ B-DatasetName
QA, -X- _ I-DatasetName
an -X- _ O
improvement -X- _ O
of -X- _ O
3.70 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ O
over -X- _ O
39.76 -X- _ B-MetricValue
obtained -X- _ O
by -X- _ O
baseline -X- _ O
1. -X- _ O

We -X- _ O
use -X- _ O
max_frac -X- _ B-HyperparameterName
= -X- _ O
0.2 -X- _ B-HyperparameterValue
for -X- _ O
Sparse-Corroborate-Dense. -X- _ B-MethodName

Note -X- _ O
for -X- _ O
retrieval -X- _ O
we -X- _ O
use -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
60 -X- _ B-HyperparameterValue
to -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
retrieval -X- _ O
results -X- _ O
for -X- _ O
different -X- _ O
context -X- _ O
size -X- _ O
experiments, -X- _ O
but -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
submitted -X- _ O
system -X- _ O
take -X- _ O
the -X- _ O
top -X- _ O
20 -X- _ B-HyperparameterValue
from -X- _ O
this -X- _ O
list -X- _ O
for -X- _ O
the -X- _ O
reader. -X- _ O

We -X- _ O
use -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.00005 -X- _ B-HyperparameterValue
with -X- _ O
linear -X- _ O
learning -X- _ O
schedule -X- _ O
with -X- _ O
a -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
using -X- _ O
the -X- _ O
AdamW -X- _ O
optimizer. -X- _ O

For -X- _ O
training -X- _ O
Fusion-in-Decoder, -X- _ B-MethodName
we -X- _ O
combine -X- _ O
the -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
retrieval -X- _ O
results -X- _ O
with -X- _ O
sampled -X- _ O
Wikipedia -X- _ O
language -X- _ O
link -X- _ O
augmented -X- _ O
passages -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
total -X- _ B-HyperparameterName
percentage -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
examples -X- _ I-HyperparameterName
from -X- _ O
either -X- _ O
source -X- _ O
is -X- _ O
50%. -X- _ B-HyperparameterValue

First, -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
in -X- _ O
the -X- _ O
MIA -X- _ O
training -X- _ O
set -X- _ O
that -X- _ O
comes -X- _ O
from -X- _ O
Natural -X- _ B-DatasetName
Questions, -X- _ I-DatasetName
we -X- _ O
use -X- _ O
the -X- _ O
answer -X- _ O
to -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
corresponding -X- _ O
Wikipedia -X- _ O
page -X- _ O
using -X- _ O
the -X- _ O
Wikipedia -X- _ O
API. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
semantically -X- _ O
ground -X- _ O
the -X- _ O
entities -X- _ O
across -X- _ O
different -X- _ O
languages -X- _ O
together, -X- _ O
we -X- _ O
use -X- _ O
Wikipedia -X- _ B-DatasetName
language -X- _ I-DatasetName
links -X- _ I-DatasetName
to -X- _ O
augment -X- _ O
the -X- _ O
data -X- _ O
from -X- _ O
retriever -X- _ O
while -X- _ O
training -X- _ O
FiD -X- _ B-MethodName
based -X- _ O
reader, -X- _ O
like -X- _ O
the -X- _ O
CORA -X- _ B-MethodName
baseline. -X- _ O

For -X- _ O
each -X- _ O
query, -X- _ O
where -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
return -X- _ O
K -X- _ B-HyperparameterName
passage, -X- _ O
we -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
top -X- _ O
K -X- _ B-HyperparameterName
passages -X- _ O
globally -X- _ O
in -X- _ O
the -X- _ O
dense -X- _ O
indices -X- _ O
in -X- _ O
all -X- _ O
languages, -X- _ O
and -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
top -X- _ O
K -X- _ B-HyperparameterName
passages -X- _ O
in -X- _ O
the -X- _ O
sparse -X- _ O
index -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
as -X- _ O
the -X- _ O
question. -X- _ O

The -X- _ O
number -X- _ O
of -X- _ O
passages -X- _ O
from -X- _ O
the -X- _ O
sparse -X- _ O
hits -X- _ O
that -X- _ O
are -X- _ O
allowed -X- _ O
to -X- _ O
influence -X- _ O
the -X- _ O
final -X- _ O
ranked -X- _ O
list -X- _ O
is -X- _ O
no -X- _ O
more -X- _ O
than -X- _ O
‚åämax_frac -X- _ B-HyperparameterName
‚àó -X- _ O
K‚åã. -X- _ B-HyperparameterName

Figure -X- _ O
1 -X- _ O
has -X- _ O
an -X- _ O
illustration -X- _ O
of -X- _ O
this -X- _ O
algorithm -X- _ O
running -X- _ O
with -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
max_frac -X- _ B-HyperparameterName
= -X- _ O
0.6 -X- _ B-HyperparameterValue
for -X- _ O
a -X- _ O
Bengali -X- _ O
(bn) -X- _ O
question. -X- _ O

We -X- _ O
combine -X- _ O
results -X- _ O
from -X- _ O
dense -X- _ O
retrieval -X- _ O
and -X- _ O
sparse -X- _ O
retrieval -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
algorithm, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
Sparse-Corroborate-Dense. -X- _ B-MethodName

For -X- _ O
sparse -X- _ O
retrieval, -X- _ O
we -X- _ O
use -X- _ O
Pyserini -X- _ B-MethodName
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Lin -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
with -X- _ O
BM25 -X- _ B-MethodName
with -X- _ O
default -X- _ O
parameters. -X- _ O

For -X- _ O
dense -X- _ O
retrieval, -X- _ O
we -X- _ O
use -X- _ O
FAISS -X- _ B-MethodName
(Johnson -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
with -X- _ O
IndexFlatIP. -X- _ B-MethodName

Experiments -X- _ O
in -X- _ O
Mr. -X- _ B-MethodName
TyDi -X- _ I-MethodName
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
indicate -X- _ O
BM25 -X- _ B-MethodName
outperforms -X- _ O
DPR -X- _ B-MethodName
(Karpukhin -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
for -X- _ O
the -X- _ O
languages -X- _ O
in -X- _ O
XOR-TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
in -X- _ O
the -X- _ O
monolingual -X- _ B-TaskName
retrieval -X- _ I-TaskName
setting, -X- _ O
but -X- _ O
combining -X- _ O
the -X- _ O
sparse -X- _ O
score -X- _ O
and -X- _ O
DPR -X- _ O
score -X- _ O
in -X- _ O
sparse-dense -X- _ O
hybrids -X- _ O
perform -X- _ O
even -X- _ O
better. -X- _ O

We -X- _ O
use -X- _ O
both -X- _ O
sparse -X- _ O
retrieval -X- _ O
(i.e. -X- _ O
BM25) -X- _ B-MethodName
and -X- _ O
dense -X- _ O
retrieval -X- _ O
together -X- _ O
in -X- _ O
our -X- _ O
system. -X- _ O

For -X- _ O
more -X- _ O
than -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
questions -X- _ O
in -X- _ O
the -X- _ O
XOR-TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
dataset, -X- _ O
for -X- _ O
example, -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
found -X- _ O
in -X- _ O
a -X- _ O
passage -X- _ O
that‚Äôs -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
as -X- _ O
the -X- _ O
question. -X- _ O

Monolingual -X- _ B-TaskName
retrieval -X- _ I-TaskName
is -X- _ O
the -X- _ O
setting -X- _ O
where -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
retrieve -X- _ O
passages -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
as -X- _ O
the -X- _ O
question. -X- _ O

mLUKE -X- _ B-MethodName
is -X- _ O
a -X- _ O
multilingual -X- _ O
extension -X- _ O
of -X- _ O
LUKE -X- _ B-MethodName
(Yamada -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
a -X- _ O
pretrained -X- _ O
contextualized -X- _ O
representation -X- _ O
of -X- _ O
words -X- _ O
and -X- _ O
entities -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
training -X- _ O
objective -X- _ O
as -X- _ O
DPR -X- _ B-MethodName
and -X- _ O
also -X- _ O
use -X- _ O
the -X- _ O
last -X- _ O
layer‚Äôs -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
input -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
representation -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
passage. -X- _ O

MKQA -X- _ B-DatasetName
(Longpre -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
consists -X- _ O
of -X- _ O
10K -X- _ O
parallel -X- _ O
questions -X- _ O
and -X- _ O
answers -X- _ O
across -X- _ O
26 -X- _ O
typologically -X- _ O
diverse -X- _ O
locales. -X- _ O

A -X- _ O
system -X- _ O
should -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
succeed -X- _ O
at -X- _ O
both -X- _ O
monolingual -X- _ B-TaskName
retrieval -X- _ I-TaskName
and -X- _ O
cross-lingual -X- _ B-TaskName
retrieval. -X- _ I-TaskName

We -X- _ O
do -X- _ O
not -X- _ O
train -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
data -X- _ O
or -X- _ O
the -X- _ O
subsets -X- _ O
of -X- _ O
the -X- _ O
Natural -X- _ B-DatasetName
Questions -X- _ I-DatasetName
and -X- _ O
TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
(Clark -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
data, -X- _ O
which -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
create -X- _ O
MKQA -X- _ B-DatasetName
or -X- _ O
XOR-TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
data. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
official -X- _ O
training -X- _ O
data -X- _ O
consisting -X- _ O
of -X- _ O
76635 -X- _ O
English -X- _ O
questions -X- _ O
and -X- _ O
answers -X- _ O
from -X- _ O
Natural -X- _ B-DatasetName
Questions -X- _ I-DatasetName
(Kwiatkowski -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
61360 -X- _ O
questions -X- _ O
and -X- _ O
answers -X- _ O
from -X- _ O
XOR-TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
(Asai -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
dual -X- _ O
encoder -X- _ O
model. -X- _ O

Compared -X- _ O
to -X- _ O
official -X- _ O
baseline -X- _ O
1, -X- _ O
we -X- _ O
improve -X- _ O
the -X- _ O
macro-averaged -X- _ O
score -X- _ O
by -X- _ O
4.1 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points. -X- _ O

We -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
iterative -X- _ O
training -X- _ O
to -X- _ O
repeat -X- _ O
these -X- _ O
steps -X- _ O
multiple -X- _ O
times. -X- _ O

Finally, -X- _ O
we -X- _ O
feed -X- _ O
the -X- _ O
ranked -X- _ O
list -X- _ O
of -X- _ O
passages -X- _ O
into -X- _ O
a -X- _ O
reader -X- _ O
based -X- _ O
on -X- _ O
Fusion-in-Decoder -X- _ B-MethodName
(Ri -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
mT5 -X- _ B-MethodName
(Xue -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
final -X- _ O
answer. -X- _ O

During -X- _ O
retrieval, -X- _ O
we -X- _ O
perform -X- _ O
nearest -X- _ O
neighbor -X- _ O
search -X- _ O
using -X- _ O
the -X- _ O
query -X- _ O
vector -X- _ O
on -X- _ O
an -X- _ O
index -X- _ O
of -X- _ O
encoded -X- _ O
passage -X- _ O
vectors. -X- _ O

In -X- _ O
the -X- _ O
first -X- _ O
stage, -X- _ O
we -X- _ O
leverage -X- _ O
mLUKE -X- _ B-MethodName
(Ri -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
that -X- _ O
models -X- _ O
entities, -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
dual -X- _ O
encoder -X- _ O
that -X- _ O
encodes -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
passage -X- _ O
separately -X- _ O
(Karpukhin -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
two -X- _ O
stage -X- _ O
approach, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
CORA -X- _ B-MethodName
(Asai -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
baseline, -X- _ O
where -X- _ O
the -X- _ O
first -X- _ O
stage -X- _ O
performs -X- _ O
multilingual -X- _ B-TaskName
passage -X- _ I-TaskName
retrieval -X- _ I-TaskName
and -X- _ O
the -X- _ O
second -X- _ O
stage -X- _ O
performs -X- _ O
cross-lingual -X- _ B-TaskName
answer -X- _ I-TaskName
generation. -X- _ I-TaskName

The -X- _ O
shared -X- _ O
task -X- _ O
at -X- _ O
Multilingual -X- _ O
Information -X- _ O
Access -X- _ O
2022 -X- _ O
evaluates -X- _ O
cross-lingual -X- _ O
open-retrieval -X- _ O
question -X- _ O
answering -X- _ O
systems -X- _ O
using -X- _ O
two -X- _ O
datasets, -X- _ O
XOR-TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
(Asai -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
MKQA -X- _ B-DatasetName
(Longpre -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Cross-lingual -X- _ B-TaskName
open-retrieval -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
finding -X- _ O
an -X- _ O
answer -X- _ O
to -X- _ O
a -X- _ O
knowledge-seeking -X- _ O
question -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
as -X- _ O
the -X- _ O
question -X- _ O
from -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
documents -X- _ O
in -X- _ O
many -X- _ O
languages. -X- _ O

We -X- _ O
improve -X- _ O
over -X- _ O
the -X- _ O
official -X- _ O
baseline -X- _ O
by -X- _ O
over -X- _ O
4 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
sets. -X- _ O

On -X- _ O
the -X- _ O
test -X- _ O
set, -X- _ O
we -X- _ O
obtain -X- _ O
40.93 -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
XOR-TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
22.29 -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
MKQA, -X- _ B-DatasetName
for -X- _ O
an -X- _ O
average -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
31.61. -X- _ B-MetricValue

On -X- _ O
the -X- _ O
development -X- _ O
set, -X- _ O
we -X- _ O
obtain -X- _ O
43.46 -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
XOR-TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
21.99 -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
MKQA, -X- _ B-DatasetName
for -X- _ O
an -X- _ O
average -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
32.73. -X- _ B-MetricValue

We -X- _ O
show -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
using -X- _ O
entity -X- _ O
representations, -X- _ O
sparse -X- _ O
retrieval -X- _ O
signals -X- _ O
to -X- _ O
help -X- _ O
dense -X- _ O
retrieval, -X- _ O
and -X- _ O
Fusion-in-Decoder. -X- _ B-MethodName

We -X- _ O
describe -X- _ O
our -X- _ O
two-stage -X- _ O
system -X- _ O
for -X- _ O
the -X- _ O
Multilingual -X- _ O
Information -X- _ O
Access -X- _ O
(MIA) -X- _ O
2022 -X- _ O
Shared -X- _ O
Task -X- _ O
on -X- _ O
Cross-Lingual -X- _ B-TaskName
Open-Retrieval -X- _ I-TaskName
Question -X- _ I-TaskName
Answering. -X- _ I-TaskName

The -X- _ O
best -X- _ O
models -X- _ O
achieved -X- _ O
15th -X- _ B-MetricValue
and -X- _ O
12th -X- _ B-MetricValue
rank -X- _ B-MetricName
for -X- _ O
subtask-A -X- _ O
and -X- _ O
subtask-B -X- _ O
respectively. -X- _ O

Another -X- _ O
interesting -X- _ O
find -X- _ O
in -X- _ O
subtask-B -X- _ O
was -X- _ O
the -X- _ O
significantly -X- _ O
poor -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
and -X- _ O
CNN -X- _ B-MethodName
based -X- _ O
models -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
vanilla -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
i.e. -X- _ O
RB-FNN. -X- _ B-MethodName

The -X- _ O
effect -X- _ O
on -X- _ O
class -X- _ O
re-weighting -X- _ O
(refer -X- _ O
3.1.3) -X- _ O
and -X- _ O
data -X- _ O
augmentation -X- _ O
was -X- _ O
also -X- _ O
explored -X- _ O
(refer -X- _ O
Table -X- _ O
2 -X- _ O
and -X- _ O
Table -X- _ O
5). -X- _ O

The -X- _ O
minute -X- _ O
difference -X- _ O
in -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
models -X- _ O
for -X- _ O
the -X- _ O
evaluation -X- _ O
dataset -X- _ O
and -X- _ O
the -X- _ O
validation -X- _ O
dataset -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
did -X- _ O
not -X- _ O
overfit -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
despite -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
epochs. -X- _ O

The -X- _ O
model -X- _ O
achieved -X- _ O
a -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
0.4006 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
validation -X- _ O
dataset -X- _ O
and -X- _ O
0.3763 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
evaluation -X- _ O
dataset. -X- _ O

For -X- _ O
subtask-B -X- _ O
RB-FNN -X- _ B-MethodName
performed -X- _ O
best -X- _ O
out -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
under -X- _ O
the -X- _ O
AUG -X- _ O
experimental -X- _ O
settings. -X- _ O

The -X- _ O
design -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
models -X- _ O
remains -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
both -X- _ O
tasks -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
outputs -X- _ I-HyperparameterName
generated -X- _ O
by -X- _ O
them -X- _ O
(Figure -X- _ O
5). -X- _ O

While -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
dataset -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
received -X- _ O
an -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.6318 -X- _ B-MetricValue
with -X- _ O
a -X- _ O
precision -X- _ B-MetricName
of -X- _ O
0.5685 -X- _ B-MetricValue
and -X- _ O
recall -X- _ B-MetricName
of -X- _ O
0.7109. -X- _ B-MetricValue

For -X- _ O
subtask-A -X- _ O
RB-BLS-CNN -X- _ B-MethodName
under -X- _ O
WT -X- _ O
experiment -X- _ O
achieved -X- _ O
the -X- _ O
highest -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.5924 -X- _ B-MetricValue
with -X- _ O
a -X- _ O
precision -X- _ B-MetricName
of -X- _ O
0.5357 -X- _ B-MetricValue
and -X- _ O
recall -X- _ B-MetricName
of -X- _ O
0.6625 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
evaluation -X- _ O
dataset. -X- _ O

For -X- _ O
each -X- _ O
experiment, -X- _ O
training -X- _ O
was -X- _ O
done -X- _ O
for -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8. -X- _ B-HyperparameterValue

F1 -X- _ B-MetricName
score -X- _ O
for -X- _ O
subtask-A -X- _ O
and -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
for -X- _ O
subtask-B -X- _ O
were -X- _ O
chosen -X- _ O
by -X- _ O
the -X- _ O
task -X- _ O
organisers -X- _ O
as -X- _ O
the -X- _ O
criteria -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
model, -X- _ O
thus -X- _ O
the -X- _ O
same -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
created -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
subtasks -X- _ O
under -X- _ O
different -X- _ O
experimental -X- _ O
settings. -X- _ O

The -X- _ O
80-20 -X- _ B-HyperparameterValue
split -X- _ O
shared -X- _ O
by -X- _ O
the -X- _ O
task -X- _ O
organisers -X- _ O
was -X- _ O
used. -X- _ O

For -X- _ O
each -X- _ O
experiment, -X- _ O
the -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
on -X- _ O
80 -X- _ B-HyperparameterValue
per -X- _ I-HyperparameterValue
cent -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
data -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
20 -X- _ B-HyperparameterValue
per -X- _ I-HyperparameterValue
cent -X- _ I-HyperparameterValue
as -X- _ O
the -X- _ O
validation -X- _ O
set. -X- _ O

To -X- _ O
gauge -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
data -X- _ O
augmentation -X- _ O
and -X- _ O
loss -X- _ O
weighting -X- _ O
techniques -X- _ O
on -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
models -X- _ O
for -X- _ O
each -X- _ O
subtask -X- _ O
four -X- _ O
experiments -X- _ O
were -X- _ O
carried -X- _ O
out -X- _ O
(Table -X- _ O
6). -X- _ O

The -X- _ O
final -X- _ O
FNN -X- _ B-MethodName
layer -X- _ O
with -X- _ O
106 -X- _ B-HyperparameterValue
units -X- _ O
is -X- _ O
then -X- _ O
further -X- _ O
fed -X- _ O
to -X- _ O
a -X- _ O
single -X- _ O
FNN -X- _ O
layer -X- _ O
with -X- _ O
2 -X- _ B-HyperparameterValue
units -X- _ O
for -X- _ O
subtask-A -X- _ O
and -X- _ O
to -X- _ O
seven -X- _ O
separate -X- _ O
FNN -X- _ B-MethodName
layers -X- _ O
each -X- _ O
with -X- _ O
2 -X- _ B-HyperparameterValue
units -X- _ O
for -X- _ O
subtask-B. -X- _ O

After -X- _ O
each -X- _ O
CNN -X- _ B-MethodName
layer, -X- _ O
a -X- _ O
two-dimensional -X- _ O
max-pooling -X- _ O
operation -X- _ O
is -X- _ O
done -X- _ O
with -X- _ O
a -X- _ O
shape -X- _ O
of -X- _ O
2X2. -X- _ B-HyperparameterValue

The -X- _ O
first -X- _ O
CNN -X- _ B-MethodName
layer -X- _ O
comprises -X- _ O
64 -X- _ B-HyperparameterValue
10X10 -X- _ B-HyperparameterValue
filters -X- _ B-HyperparameterName
with -X- _ O
stride -X- _ B-HyperparameterName
1 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
second -X- _ O
layer -X- _ O
comprises -X- _ O
32 -X- _ B-HyperparameterValue
5X5 -X- _ B-HyperparameterValue
filters -X- _ B-HyperparameterName
with -X- _ O
stride -X- _ B-HyperparameterName
1. -X- _ B-HyperparameterValue

CNN -X- _ B-MethodName
based -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
perform -X- _ O
well -X- _ O
for -X- _ O
various -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
problems -X- _ O
(Chen, -X- _ O
2015) -X- _ O
(Safaya -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

For -X- _ O
this -X- _ O
model -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
layer -X- _ O
of -X- _ O
RoBERTaLARGE -X- _ B-MethodName
model -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
Bi-Directional -X- _ B-MethodName
LSTM -X- _ I-MethodName
layer -X- _ O
with -X- _ O
106 -X- _ B-HyperparameterValue
units. -X- _ B-HyperparameterName

For -X- _ O
subtask-A, -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
this -X- _ O
hidden -X- _ O
layer -X- _ O
is -X- _ O
passed -X- _ O
on -X- _ O
to -X- _ O
a -X- _ O
single -X- _ O
feed-forward -X- _ O
layer -X- _ O
with -X- _ O
2 -X- _ B-HyperparameterValue
units -X- _ B-HyperparameterName
for -X- _ O
binary -X- _ O
prediction, -X- _ O
while -X- _ O
for -X- _ O
subtaskB -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
shared -X- _ O
by -X- _ O
seven -X- _ O
feed-forward -X- _ O
layers -X- _ O
each -X- _ O
with -X- _ O
2 -X- _ B-HyperparameterValue
units -X- _ B-HyperparameterName
predicting -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
each -X- _ O
sub-category -X- _ O
of -X- _ O
PCL. -X- _ O

The -X- _ O
initial -X- _ O
feed-forward -X- _ O
layer -X- _ O
has -X- _ O
106 -X- _ B-HyperparameterValue
units. -X- _ B-HyperparameterName

The -X- _ O
model -X- _ O
employs -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
two -X- _ O
feed-forward -X- _ O
layers -X- _ O
added -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
RoBERTaLARGE. -X- _ B-MethodName

Adam -X- _ O
optimizer -X- _ O
was -X- _ O
utilized -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
set -X- _ O
to -X- _ O
1e-6 -X- _ B-HyperparameterValue
and -X- _ O
epsilon -X- _ B-HyperparameterName
at -X- _ O
1e-6. -X- _ B-HyperparameterValue

The -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
state -X- _ O
(shape -X- _ O
= -X- _ O
106 -X- _ B-HyperparameterValue
X -X- _ I-HyperparameterValue
1024) -X- _ I-HyperparameterValue
is -X- _ O
then -X- _ O
further -X- _ O
fed -X- _ O
down -X- _ O
the -X- _ O
network -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
final -X- _ O
prediction. -X- _ O

Each -X- _ O
design -X- _ O
includes -X- _ O
RoBERTaLARGE -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
as -X- _ O
it‚Äôs -X- _ O
base -X- _ O
layer. -X- _ O

Helsinki-NLP -X- _ B-MethodName
models -X- _ O
were -X- _ O
used -X- _ O
to -X- _ O
translate -X- _ O
a -X- _ O
sentence -X- _ O
from -X- _ O
English -X- _ O
to -X- _ O
French -X- _ O
and -X- _ O
back -X- _ O
to -X- _ O
English. -X- _ O

For -X- _ O
data -X- _ O
augmentation -X- _ O
back-translation -X- _ O
method -X- _ O
was -X- _ O
explored. -X- _ O

Thus, -X- _ O
to -X- _ O
prevent -X- _ O
loss -X- _ O
of -X- _ O
information -X- _ O
Tokenisation -X- _ O
was -X- _ O
done -X- _ O
with -X- _ O
a -X- _ O
length -X- _ O
of -X- _ O
100. -X- _ B-HyperparameterValue

Each -X- _ O
sample -X- _ O
was -X- _ O
tokenised -X- _ O
using -X- _ O
RoBERTa -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
tokenizer. -X- _ O

To -X- _ O
deal -X- _ O
with -X- _ O
high -X- _ O
class-imbalance -X- _ O
and -X- _ O
lower -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
data -X- _ O
augmentation -X- _ O
techniques, -X- _ O
loss -X- _ O
weighting -X- _ O
strategies -X- _ O
were -X- _ O
adopted -X- _ O
and -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
low -X- _ O
context -X- _ O
issue, -X- _ O
keywords -X- _ O
shared -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
were -X- _ O
used -X- _ O
to -X- _ O
provide -X- _ O
added -X- _ O
context -X- _ O
to -X- _ O
the -X- _ O
models. -X- _ O

The -X- _ O
dataset -X- _ O
contains -X- _ O
paragraphs -X- _ O
in -X- _ O
the -X- _ O
English -X- _ O
language -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
News -X- _ B-DatasetName
on -X- _ I-DatasetName
Web -X- _ I-DatasetName
(NoW) -X- _ I-DatasetName
corpus. -X- _ O

In -X- _ O
the -X- _ O
past -X- _ O
topics -X- _ O
such -X- _ O
as -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
(Feldman, -X- _ O
2013), -X- _ O
offensive -X- _ B-TaskName
speech -X- _ I-TaskName
identification -X- _ I-TaskName
(Safaya -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
identification -X- _ I-TaskName
(Shu -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
have -X- _ O
been -X- _ O
significantly -X- _ O
worked -X- _ O
upon. -X- _ O

For -X- _ O
subtask-A, -X- _ O
this -X- _ O
work -X- _ O
achieved -X- _ O
15th -X- _ B-MetricValue
rank -X- _ B-MetricName
in -X- _ O
the -X- _ O
leader -X- _ O
board -X- _ O
and -X- _ O
12th -X- _ B-MetricValue
rank -X- _ B-MetricName
for -X- _ O
subtask-B -X- _ O
details -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
discussed -X- _ O
in -X- _ O
section -X- _ O
3.2. -X- _ O

Different -X- _ O
variations -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
involved -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
feedforward -X- _ O
layers, -X- _ O
LSTMs, -X- _ B-MethodName
CNN -X- _ B-MethodName
and -X- _ O
their -X- _ O
combinations. -X- _ O

To -X- _ O
tackle -X- _ O
these -X- _ O
tasks, -X- _ O
RoBERTa -X- _ B-MethodName
based -X- _ O
models -X- _ O
were -X- _ O
developed. -X- _ O

The -X- _ O
best -X- _ O
models -X- _ O
achieved -X- _ O
15th -X- _ B-MetricValue
rank -X- _ B-MetricName
with -X- _ O
an -X- _ O
F1-score -X- _ B-MetricName
of -X- _ O
0.5924 -X- _ B-MetricValue
for -X- _ O
subtask-A -X- _ O
and -X- _ O
12th -X- _ B-MetricValue
in -X- _ O
subtask-B -X- _ O
with -X- _ O
a -X- _ O
macro-F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.3763. -X- _ B-MetricValue

This -X- _ O
work -X- _ O
explores -X- _ O
different -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
pre-trained -X- _ O
RoBERTa -X- _ B-MethodName
language -X- _ O
model -X- _ O
coupled -X- _ O
with -X- _ O
LSTM -X- _ B-MethodName
and -X- _ O
CNN -X- _ B-MethodName
layers. -X- _ O

As -X- _ O
future -X- _ O
work, -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
follow -X- _ O
the -X- _ O
research -X- _ O
line -X- _ O
proposed -X- _ O
by -X- _ O
Tedeschi -X- _ O
et -X- _ O
al. -X- _ O
(2022), -X- _ O
and -X- _ O
explore -X- _ O
the -X- _ O
identification -X- _ B-TaskName
of -X- _ I-TaskName
idioms -X- _ I-TaskName
directly -X- _ O
on -X- _ O
raw -X- _ O
texts, -X- _ O
i.e., -X- _ O
without -X- _ O
pre-identified -X- _ O
potentially -X- _ O
idiomatic -X- _ O
expressions, -X- _ O
and -X- _ O
study -X- _ O
a -X- _ O
broader -X- _ O
set -X- _ O
of -X- _ O
languages. -X- _ O

Our -X- _ O
experiments -X- _ O
showed -X- _ O
that: -X- _ O
i) -X- _ O
our -X- _ O
dual-encoder -X- _ O
architecture -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
successfully -X- _ O
solve -X- _ O
the -X- _ O
idiom -X- _ B-TaskName
identification -X- _ I-TaskName
task -X- _ O
by -X- _ O
consistently -X- _ O
outperforming -X- _ O
the -X- _ O
strong -X- _ O
baselines -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
task -X- _ O
organizers, -X- _ O
and -X- _ O
ii) -X- _ O
the -X- _ O
inclusion -X- _ O
of -X- _ O
NER -X- _ B-TaskName
in -X- _ O
the -X- _ O
pipeline -X- _ O
provided -X- _ O
further -X- _ O
improvements -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
7.5 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points. -X- _ O

We -X- _ O
started -X- _ O
by -X- _ O
exploiting -X- _ O
the -X- _ O
semantic -X- _ O
idiosyncrasy -X- _ O
property -X- _ O
of -X- _ O
idiomatic -X- _ O
expressions -X- _ O
and -X- _ O
introduced -X- _ O
a -X- _ B-MethodName
novel -X- _ I-MethodName
dual-encoder -X- _ I-MethodName
Transformer-based -X- _ I-MethodName
architecture -X- _ I-MethodName
that -X- _ O
encodes -X- _ O
both -X- _ O
the -X- _ O
potentially -X- _ O
idiomatic -X- _ O
expression -X- _ O
(PIE) -X- _ O
and -X- _ O
its -X- _ O
context, -X- _ O
and -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
similarity -X- _ O
predicts -X- _ O
idiomaticity. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
presented -X- _ O
our -X- _ O
NER4ID -X- _ B-MethodName
submission -X- _ O
to -X- _ O
SemEval-2022 -X- _ O
Task -X- _ O
2 -X- _ O
focusing -X- _ O
on -X- _ O
the -X- _ O
Multilingual -X- _ B-TaskName
Idiomaticity -X- _ I-TaskName
Detection -X- _ I-TaskName
subtask. -X- _ O

Likewise, -X- _ O
in -X- _ O
the -X- _ O
one-shot -X- _ O
setting -X- _ O
we -X- _ O
point -X- _ O
out -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
5.6 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ O
for -X- _ O
the -X- _ O
overall -X- _ O
architecture, -X- _ O
and -X- _ O
of -X- _ O
2.3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ O
for -X- _ O
the -X- _ O
dual -X- _ O
encoder. -X- _ O

Specifically, -X- _ O
in -X- _ O
the -X- _ O
zero-shot -X- _ O
setting -X- _ O
we -X- _ O
observe -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
12 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ O
for -X- _ O
the -X- _ O
complete -X- _ O
system -X- _ O
(Figure -X- _ O
1), -X- _ O
and -X- _ O
of -X- _ O
4.5 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
dual-encoder -X- _ O
architecture -X- _ O
(Section -X- _ O
3.1). -X- _ O

Then, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
dual-encoder -X- _ O
architecture -X- _ O
(Section -X- _ O
3.1) -X- _ O
and -X- _ O
of -X- _ O
our -X- _ O
entire -X- _ O
idiomaticity -X- _ O
detection -X- _ O
system -X- _ O
that -X- _ O
includes -X- _ O
the -X- _ O
NER -X- _ B-TaskName
module -X- _ O
(Section -X- _ O
3.2), -X- _ O
we -X- _ O
compare -X- _ O
them -X- _ O
with -X- _ O
the -X- _ O
strong -X- _ O
mBERT-based -X- _ B-MethodName
baselines -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
task -X- _ O
organizers -X- _ O
(Tayyar -X- _ O
Madabushi -X- _ O
et -X- _ O
al., -X- _ O
2022): -X- _ O
for -X- _ O
the -X- _ O
zero-shot -X- _ O
setting, -X- _ O
their -X- _ O
model -X- _ O
takes -X- _ O
as -X- _ O
input -X- _ O
the -X- _ O
context, -X- _ O
while -X- _ O
for -X- _ O
the -X- _ O
one-shot -X- _ O
setting, -X- _ O
they -X- _ O
exclude -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
provide -X- _ O
as -X- _ O
input -X- _ O
only -X- _ O
the -X- _ O
sentence -X- _ O
containing -X- _ O
the -X- _ O
PIE, -X- _ O
where -X- _ O
the -X- _ O
latter -X- _ O
is -X- _ O
separated -X- _ O
from -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
‚Äú[SEP]‚Äù -X- _ O
special -X- _ O
token. -X- _ O

Similar -X- _ O
to -X- _ O
Tayyar -X- _ O
Madabushi -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
slight -X- _ O
drop -X- _ O
in -X- _ O
performance -X- _ O
(i.e., -X- _ O
-0.3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points, -X- _ O
on -X- _ O
average -X- _ O
on -X- _ O
the -X- _ O
zero-shot -X- _ O
and -X- _ O
one-shot -X- _ O
settings) -X- _ O
and -X- _ O
longer -X- _ O
training -X- _ O
times, -X- _ O
hence -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
include -X- _ O
context -X- _ O
in -X- _ O
our -X- _ O
experiments. -X- _ O

In -X- _ O
the -X- _ O
zero-shot -X- _ O
setting, -X- _ O
potentially -X- _ O
idiomatic -X- _ O
expressions -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
are -X- _ O
completely -X- _ O
disjoint -X- _ O
from -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
sets. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
to -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
optimal -X- _ O
value -X- _ O
of -X- _ O
N -X- _ B-HyperparameterName
by -X- _ O
choosing -X- _ O
from -X- _ O
N -X- _ B-HyperparameterName
= -X- _ O
{1, -X- _ B-HyperparameterValue
3, -X- _ I-HyperparameterValue
5, -X- _ I-HyperparameterValue
7, -X- _ I-HyperparameterValue
9, -X- _ I-HyperparameterValue
11, -X- _ I-HyperparameterValue
13}. -X- _ I-HyperparameterValue

Each -X- _ O
training -X- _ O
(i.e. -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
configuration) -X- _ O
required -X- _ O
‚àº1min/epoch -X- _ O
on -X- _ O
average, -X- _ O
for -X- _ O
a -X- _ O
mean -X- _ O
of -X- _ O
‚àº30 -X- _ B-HyperparameterValue
epochs. -X- _ B-HyperparameterName

We -X- _ O
compare -X- _ O
systems -X- _ O
by -X- _ O
means -X- _ O
of -X- _ O
their -X- _ O
Macro -X- _ B-MethodName
F1 -X- _ I-MethodName
scores, -X- _ O
as -X- _ O
specified -X- _ O
by -X- _ O
the -X- _ O
competition -X- _ O
rules. -X- _ O

Additionally, -X- _ O
we -X- _ O
set -X- _ O
Œ¥ -X- _ B-HyperparameterName
= -X- _ O
04 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
use -X- _ O
32 -X- _ B-HyperparameterValue
as -X- _ O
batch -X- _ B-HyperparameterName
size, -X- _ I-HyperparameterName
with -X- _ O
4 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
gradient -X- _ I-HyperparameterName
accumulation. -X- _ I-HyperparameterName

We -X- _ O
fine-tune -X- _ O
our -X- _ O
idiom -X- _ O
identification -X- _ O
system -X- _ O
for -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
MeanSquared -X- _ B-MetricName
Error -X- _ I-MetricName
loss -X- _ I-MetricName
criterion, -X- _ O
adopting -X- _ O
an -X- _ O
early -X- _ O
stopping -X- _ O
strategy -X- _ O
with -X- _ O
a -X- _ O
patience -X- _ B-HyperparameterName
value -X- _ I-HyperparameterName
of -X- _ O
20, -X- _ B-HyperparameterValue
Adam -X- _ O
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2015) -X- _ O
optimizer, -X- _ O
and -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
10‚àí5 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
implement -X- _ O
our -X- _ O
dual-encoder -X- _ O
architecture -X- _ O
(Section -X- _ O
3.1) -X- _ O
with -X- _ O
PyTorch -X- _ O
(Paszke -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
using -X- _ O
the -X- _ O
Transformers -X- _ O
library -X- _ O
(Wolf -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
to -X- _ O
load -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
BERT-base-cased -X- _ B-MethodName
for -X- _ O
English -X- _ O
and -X- _ O
of -X- _ O
BERT-base-portuguese-cased -X- _ B-MethodName
for -X- _ O
Portuguese -X- _ O
and -X- _ O
Galician. -X- _ O

Specifically, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
auxiliary -X- _ O
NER -X- _ B-TaskName
module -X- _ O
in -X- _ O
our -X- _ O
classification -X- _ O
pipeline -X- _ O
that, -X- _ O
given -X- _ O
as -X- _ O
input -X- _ O
a -X- _ O
raw -X- _ O
text -X- _ O
sequence -X- _ O
of -X- _ O
n -X- _ O
tokens -X- _ O
X -X- _ O
= -X- _ O
x1, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
xn -X- _ O
containing -X- _ O
a -X- _ O
potentially -X- _ O
idiomatic -X- _ O
expression -X- _ O
p, -X- _ O
predicts -X- _ O
all -X- _ O
the -X- _ O
entities -X- _ O
E -X- _ O
= -X- _ O
e1, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
em -X- _ O
in -X- _ O
X. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
cope -X- _ O
with -X- _ O
this -X- _ O
issue, -X- _ O
we -X- _ O
exploit -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition, -X- _ I-TaskName
i.e. -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
identifying -X- _ O
specific -X- _ O
words -X- _ O
as -X- _ O
belonging -X- _ O
to -X- _ O
predefined -X- _ O
semantic -X- _ O
types, -X- _ O
such -X- _ O
as -X- _ O
Person, -X- _ O
Location -X- _ O
and -X- _ O
Organization -X- _ O
(Nadeau -X- _ O
and -X- _ O
Sekine, -X- _ O
2007). -X- _ O

Nevertheless, -X- _ O
its -X- _ O
constituents -X- _ O
(i.e. -X- _ O
blood -X- _ O
and -X- _ O
bath) -X- _ O
are -X- _ O
unrelated -X- _ O
to -X- _ O
the -X- _ O
context, -X- _ O
hence -X- _ O
misleading -X- _ O
our -X- _ O
dual-encoder -X- _ O
architecture -X- _ O
(Section -X- _ O
3.1) -X- _ O
to -X- _ O
classify -X- _ O
it -X- _ O
as -X- _ O
idiomatic. -X- _ O

Both -X- _ O
encoders -X- _ O
are -X- _ O
BERT-based -X- _ B-MethodName
architectures -X- _ O
that -X- _ O
take -X- _ O
as -X- _ O
input -X- _ O
the -X- _ O
tokenized -X- _ O
versions -X- _ O
of -X- _ O
expressions -X- _ O
and -X- _ O
their -X- _ O
contexts, -X- _ O
respectively, -X- _ O
surrounded -X- _ O
by -X- _ O
the -X- _ O
special -X- _ O
tokens -X- _ O
[CLS] -X- _ O
and -X- _ O
[SEP]. -X- _ O

Œ¥ -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
manually-tuned -X- _ O
threshold. -X- _ O

We -X- _ O
first -X- _ O
describe -X- _ O
our -X- _ O
architecture -X- _ O
for -X- _ O
idiomaticity -X- _ B-TaskName
detection -X- _ I-TaskName
(Section -X- _ O
3.1), -X- _ O
and -X- _ O
then -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
can -X- _ O
be -X- _ O
included -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
more -X- _ O
robust -X- _ O
idiom -X- _ O
identification -X- _ O
system -X- _ O
(Section -X- _ O
3.2). -X- _ O

Finally, -X- _ O
we -X- _ O
extensively -X- _ O
evaluate -X- _ O
our -X- _ O
system -X- _ O
on -X- _ O
both -X- _ O
one-shot -X- _ O
and -X- _ O
zero-shot -X- _ O
settings. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
NER4ID -X- _ B-MethodName
submission -X- _ O
to -X- _ O
the -X- _ O
SemEval-2022 -X- _ O
Task -X- _ O
2 -X- _ O
which -X- _ O
focuses -X- _ O
on -X- _ O
Subtask -X- _ O
A. -X- _ O

Indeed, -X- _ O
their -X- _ O
identification -X- _ O
and -X- _ O
understanding -X- _ O
is -X- _ O
crucial -X- _ O
not -X- _ O
only -X- _ O
for -X- _ O
Natural -X- _ O
Language -X- _ O
Understanding -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
Word -X- _ B-TaskName
Sense -X- _ I-TaskName
Disambiguation -X- _ I-TaskName
(Bevilacqua -X- _ O
et -X- _ O
al., -X- _ O
2021b), -X- _ O
Semantic -X- _ B-TaskName
Role -X- _ I-TaskName
Labeling -X- _ I-TaskName
(Conia -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
Semantic -X- _ B-TaskName
Parsing -X- _ I-TaskName
(Bevilacqua -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
but -X- _ O
also -X- _ O
for -X- _ O
Machine -X- _ B-TaskName
Translation -X- _ I-TaskName
(Edunov -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
Question -X- _ B-TaskName
Answering -X- _ I-TaskName
(Mishra -X- _ O
and -X- _ O
Jain, -X- _ O
2016) -X- _ O
and -X- _ O
Text -X- _ B-TaskName
Summarization -X- _ I-TaskName
(Chu -X- _ O
and -X- _ O
Wang, -X- _ O
2018), -X- _ O
inter -X- _ O
alia. -X- _ O

Our -X- _ O
model -X- _ O
achieves -X- _ O
92.1 -X- _ B-MetricValue
F1 -X- _ B-MetricName
in -X- _ O
the -X- _ O
one-shot -X- _ O
setting -X- _ O
and -X- _ O
shows -X- _ O
strong -X- _ O
robustness -X- _ O
towards -X- _ O
unseen -X- _ O
idioms -X- _ O
achieving -X- _ O
77.4 -X- _ B-MetricValue
F1 -X- _ B-MetricName
in -X- _ O
the -X- _ O
zeroshot -X- _ O
setting. -X- _ O

Then, -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
and -X- _ O
to -X- _ O
what -X- _ O
extent -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
can -X- _ O
be -X- _ O
exploited -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
confusion -X- _ O
of -X- _ O
idiom -X- _ O
identification -X- _ O
systems -X- _ O
and, -X- _ O
therefore, -X- _ O
improve -X- _ O
performance. -X- _ O

This -X- _ O
motivated -X- _ O
the -X- _ O
organization -X- _ O
of -X- _ O
the -X- _ O
SemEval-2022 -X- _ O
Task -X- _ O
2, -X- _ O
which -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
multilingual -X- _ O
subtasks: -X- _ O
one -X- _ O
about -X- _ O
idiomaticity -X- _ B-TaskName
detection, -X- _ I-TaskName
and -X- _ O
the -X- _ O
other -X- _ O
about -X- _ O
sentence -X- _ O
embeddings. -X- _ O

Comparing -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
that -X- _ O
ensemble -X- _ O
to -X- _ O
a -X- _ O
traditional -X- _ O
approach -X- _ O
to -X- _ O
this -X- _ O
problem -X- _ O
which -X- _ O
uses -X- _ O
many -X- _ O
of -X- _ O
those -X- _ O
methods -X- _ O
simultaneously -X- _ O
would -X- _ O
show -X- _ O
whether -X- _ O
or -X- _ O
not -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
strong -X- _ O
overlap -X- _ O
between -X- _ O
sources, -X- _ O
locations, -X- _ O
etc. -X- _ O
and -X- _ O
PCL, -X- _ O
or -X- _ O
whether -X- _ O
only -X- _ O
the -X- _ O
text -X- _ O
itself -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
indicator -X- _ O
of -X- _ O
a -X- _ O
sign -X- _ O
of -X- _ O
PCL. -X- _ O

In -X- _ O
the -X- _ O
future, -X- _ O
we -X- _ O
would -X- _ O
explore -X- _ O
creating -X- _ O
an -X- _ O
ensemble -X- _ O
of -X- _ O
models, -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
which -X- _ O
uses -X- _ O
textual -X- _ O
analysis, -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
would -X- _ O
focus -X- _ O
on -X- _ O
things -X- _ O
like -X- _ O
meta -X- _ O
data -X- _ O
and -X- _ O
word -X- _ O
frequencies -X- _ O
which -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
context. -X- _ O

We -X- _ O
did -X- _ O
not -X- _ O
perform -X- _ O
any -X- _ O
quantitative -X- _ O
analysis -X- _ O
or -X- _ O
ablations, -X- _ O
but -X- _ O
given -X- _ O
the -X- _ O
chance -X- _ O
we -X- _ O
would -X- _ O
augment -X- _ O
the -X- _ O
less -X- _ O
frequent -X- _ O
PCL -X- _ O
categories -X- _ O
and -X- _ O
see -X- _ O
if -X- _ O
that -X- _ O
would -X- _ O
fix -X- _ O
the -X- _ O
prediction -X- _ O
issues -X- _ O
for -X- _ O
subtask -X- _ O
2, -X- _ O
even -X- _ O
if -X- _ O
it -X- _ O
wouldn‚Äôt -X- _ O
necessarily -X- _ O
improve -X- _ O
accuracy. -X- _ B-MetricName

We -X- _ O
placed -X- _ O
32/79 -X- _ B-MetricValue
for -X- _ O
subtask -X- _ O
1, -X- _ O
and -X- _ O
40/49 -X- _ B-MetricValue
for -X- _ O
subtask -X- _ O
2. -X- _ O

Our -X- _ O
model -X- _ O
had -X- _ O
precision -X- _ B-MetricName
0.4017, -X- _ B-MetricValue
recall -X- _ B-MetricName
0.7666, -X- _ B-MetricValue
and -X- _ O
F1 -X- _ B-MetricName
0.5271 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
evaluation -X- _ O
data -X- _ O
for -X- _ O
subtask -X- _ O
1, -X- _ O
and -X- _ O
has -X- _ O
an -X- _ O
average -X- _ O
F1 -X- _ B-MetricName
of -X- _ O
0.0963 -X- _ B-MetricValue
for -X- _ O
subtask -X- _ O
2. -X- _ O

We -X- _ O
used -X- _ O
a -X- _ O
train/test -X- _ B-HyperparameterName
split -X- _ I-HyperparameterName
of -X- _ O
70/30 -X- _ B-HyperparameterValue
and -X- _ O
evaluated -X- _ O
based -X- _ O
on -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
F1. -X- _ B-MetricName

Our -X- _ O
final -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
using -X- _ O
Adam -X- _ O
optimization -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2.31468e-05 -X- _ B-HyperparameterValue
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2014); -X- _ O
we -X- _ O
trained -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
6 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8. -X- _ B-HyperparameterValue

We -X- _ O
propose -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
a -X- _ O
contextual -X- _ O
embedding -X- _ O
based-neural -X- _ O
model -X- _ O
on -X- _ O
strictly -X- _ O
textual -X- _ O
inputs -X- _ O
to -X- _ O
detect -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
patronizing -X- _ O
or -X- _ O
condescending -X- _ O
language -X- _ O
(PCL). -X- _ O

The -X- _ O
dataset -X- _ O
provided -X- _ O
was -X- _ O
the -X- _ O
Don‚Äôt -X- _ B-DatasetName
Patronize -X- _ I-DatasetName
Me! -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
(P‚Äôerez-Almendros -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
paragraphs -X- _ O
mentioning -X- _ O
vulnerable -X- _ O
communities -X- _ O
and -X- _ O
published -X- _ O
in -X- _ O
media -X- _ O
in -X- _ O
20 -X- _ O
English -X- _ O
speaking -X- _ O
countries. -X- _ O

We -X- _ O
ranked -X- _ O
32/70 -X- _ B-MetricValue
on -X- _ O
subtask -X- _ O
1, -X- _ O
which -X- _ O
is -X- _ O
detecting -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
PCL, -X- _ O
and -X- _ O
ranked -X- _ O
40/49 -X- _ B-MetricValue
on -X- _ O
subtask -X- _ O
2, -X- _ O
which -X- _ O
involves -X- _ O
identifying -X- _ O
the -X- _ O
PCL -X- _ O
techniques -X- _ O
used. -X- _ O

We -X- _ O
finetuned -X- _ O
a -X- _ O
pre-trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
to -X- _ O
detect -X- _ O
whether -X- _ O
or -X- _ O
not -X- _ O
a -X- _ O
paragraph -X- _ O
contained -X- _ O
PCL -X- _ O
(Subtask -X- _ O
1), -X- _ O
and -X- _ O
furthermore -X- _ O
finetuned -X- _ O
another -X- _ O
pre-trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
linguistic -X- _ O
techniques -X- _ O
used -X- _ O
to -X- _ O
convey -X- _ O
the -X- _ O
PCL -X- _ O
(Subtask -X- _ O
2). -X- _ O

acknowledgments -X- _ O
we -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
feedback -X- _ O
. -X- _ O

we -X- _ O
hope -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
will -X- _ O
catalyze -X- _ O
new -X- _ O
developments -X- _ O
in -X- _ O
transfer -X- _ O
learning -X- _ O
for -X- _ O
nlp -X- _ O
. -X- _ O

our -X- _ O
method -X- _ O
signiÔ¨Åcantly -X- _ O
outperformed -X- _ O
existing -X- _ O
transfer -X- _ O
learning -X- _ O
techniques -X- _ O
and -X- _ O
the -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
six -X- _ O
representative -X- _ O
text -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

we -X- _ O
have -X- _ O
also -X- _ O
proposed -X- _ O
several -X- _ O
novel -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
techniques -X- _ O
that -X- _ O
in -X- _ O
conjunction -X- _ O
prevent -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
and -X- _ O
enable -X- _ O
robust -X- _ O
learning -X- _ O
across -X- _ O
a -X- _ O
diverse -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O

7 -X- _ O
conclusion -X- _ O
we -X- _ O
have -X- _ O
proposed -X- _ O
ulmfit -X- _ B-MethodName
, -X- _ O
an -X- _ O
effective -X- _ O
and -X- _ O
extremely -X- _ O
sample -X- _ O
- -X- _ O
efÔ¨Åcient -X- _ O
transfer -X- _ O
learning -X- _ O
method -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
nlp -X- _ O
task -X- _ O
. -X- _ O

finally -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
have -X- _ O
provided -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
analyses -X- _ O
and -X- _ O
ablations -X- _ O
, -X- _ O
more -X- _ O
studies -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
what -X- _ O
knowledge -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
captures -X- _ O
, -X- _ O
how -X- _ O
this -X- _ O
changes -X- _ O
during -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
and -X- _ O
what -X- _ O
information -X- _ O
different -X- _ O
tasks -X- _ O
require -X- _ O
. -X- _ O

while -X- _ O
an -X- _ O
extension -X- _ O
to -X- _ O
sequence -X- _ O
labeling -X- _ O
is -X- _ O
straightforward -X- _ O
, -X- _ O
other -X- _ O
tasks -X- _ O
with -X- _ O
more -X- _ O
complex -X- _ O
interactions -X- _ O
such -X- _ O
as -X- _ O
entailment -X- _ O
or -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
may -X- _ O
require -X- _ O
novel -X- _ O
ways -X- _ O
to -X- _ O
pretrain -X- _ B-MethodName
and -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
. -X- _ O

another -X- _ O
direction -X- _ O
is -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
method -X- _ O
to -X- _ O
novel -X- _ O
tasks -X- _ O
and -X- _ O
models -X- _ O
. -X- _ O

2016 -X- _ O
) -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
general -X- _ O
or -X- _ O
better -X- _ O
suited -X- _ O
for -X- _ O
certain -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
ideally -X- _ O
in -X- _ O
a -X- _ O
weakly -X- _ O
- -X- _ O
supervised -X- _ O
manner -X- _ O
to -X- _ O
retain -X- _ O
its -X- _ O
universal -X- _ O
properties -X- _ O
. -X- _ O

language -X- _ O
modeling -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
augmented -X- _ O
with -X- _ O
additional -X- _ O
tasks -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
fashion -X- _ O
( -X- _ O
caruana -X- _ O
, -X- _ O
1993 -X- _ O
) -X- _ O
or -X- _ O
enriched -X- _ O
with -X- _ O
additional -X- _ O
supervision -X- _ O
, -X- _ O
e.g. -X- _ O
syntax -X- _ O
- -X- _ O
sensitive -X- _ O
dependencies -X- _ O
( -X- _ O
linzen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2018)‚Äîfocusing -X- _ O
on -X- _ O
predicting -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
ones -X- _ O
might -X- _ O
retain -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
performance -X- _ O
while -X- _ O
speeding -X- _ O
up -X- _ O
training -X- _ O
. -X- _ O

2016 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
recent -X- _ O
work -X- _ O
shows -X- _ O
that -X- _ O
an -X- _ O
alignment -X- _ O
between -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
task -X- _ O
label -X- _ O
sets -X- _ O
is -X- _ O
important -X- _ O
( -X- _ O
mahajan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

one -X- _ O
possible -X- _ O
direction -X- _ O
is -X- _ O
to -X- _ O
improve -X- _ O
language -X- _ O
model -X- _ O
pretraining -X- _ B-MethodName
and -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
and -X- _ O
make -X- _ O
them -X- _ O
more -X- _ O
scalable -X- _ O
: -X- _ O
for -X- _ O
imagenet -X- _ O
, -X- _ O
predicting -X- _ O
far -X- _ O
fewer -X- _ O
classes -X- _ O
only -X- _ O
incurs -X- _ O
a -X- _ O
small -X- _ O
performance -X- _ O
drop -X- _ O
( -X- _ O
huh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2018 -X- _ O
): -X- _ O
a -X- _ O
) -X- _ O
nlp -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
english -X- _ O
languages -X- _ O
, -X- _ O
where -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
supervised -X- _ O
pretraining -X- _ O
tasks -X- _ O
is -X- _ O
scarce -X- _ O
; -X- _ O
b -X- _ O
) -X- _ O
new -X- _ O
nlp -X- _ O
tasks -X- _ O
where -X- _ O
no -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
architecture -X- _ O
exists -X- _ O
; -X- _ O
and -X- _ O
c -X- _ O
) -X- _ O
tasks -X- _ O
with -X- _ O
limited -X- _ O
amounts -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
( -X- _ O
and -X- _ O
some -X- _ O
amounts -X- _ O
of -X- _ O
unlabeled -X- _ O
data).given -X- _ O
that -X- _ O
transfer -X- _ O
learning -X- _ O
and -X- _ O
particularly -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
for -X- _ O
nlp -X- _ O
is -X- _ O
under -X- _ O
- -X- _ O
explored -X- _ O
, -X- _ O
many -X- _ O
future -X- _ O
directions -X- _ O
are -X- _ O
possible -X- _ O
. -X- _ O

6 -X- _ O
discussion -X- _ O
and -X- _ O
future -X- _ O
directions -X- _ O
while -X- _ O
we -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
ulmfit -X- _ O
can -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
widely -X- _ O
used -X- _ O
text -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
language -X- _ O
model -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
will -X- _ O
be -X- _ O
particularly -X- _ O
useful -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
settings -X- _ O
compared -X- _ O
to -X- _ O
existing -X- _ O
transfer -X- _ O
learning -X- _ O
approaches -X- _ O
( -X- _ O
conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

on -X- _ O
imdb -X- _ B-DatasetName
we -X- _ O
lower -X- _ O
the -X- _ O
test -X- _ O
error -X- _ B-MetricName
from -X- _ O
5:30of -X- _ B-MetricValue
a -X- _ O
single -X- _ O
model -X- _ O
to4:58for -X- _ B-MetricValue
the -X- _ O
bidirectional -X- _ O
model -X- _ O
. -X- _ O

impact -X- _ O
of -X- _ O
bidirectionality -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
training -X- _ O
a -X- _ O
second -X- _ O
model -X- _ O
, -X- _ O
ensembling -X- _ O
the -X- _ O
predictions -X- _ O
of -X- _ O
a -X- _ O
forward -X- _ O
and -X- _ O
backwards -X- _ O
lm -X- _ O
- -X- _ O
classiÔ¨Åer -X- _ O
brings -X- _ O
a -X- _ O
performance -X- _ O
boost -X- _ O
of -X- _ O
around -X- _ B-MetricValue
0:5‚Äì0:7 -X- _ I-MetricValue
. -X- _ O

in -X- _ O
contrast -X- _ O
, -X- _ O
ulmfit -X- _ B-MethodName
is -X- _ O
more -X- _ O
stable -X- _ O
and -X- _ O
suffers -X- _ O
from -X- _ O
no -X- _ O
such -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
; -X- _ O
performance -X- _ O
remains -X- _ O
similar -X- _ O
or -X- _ O
improves -X- _ O
until -X- _ O
late -X- _ O
epochs -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
positive -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
schedule -X- _ O
. -X- _ O

the -X- _ O
error -X- _ B-MetricName
then -X- _ O
increases -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
starts -X- _ O
to -X- _ O
overÔ¨Åt -X- _ O
and -X- _ O
knowledge -X- _ O
captured -X- _ O
through -X- _ O
pretraining -X- _ O
is -X- _ O
lost -X- _ O
. -X- _ O

on -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ B-MethodName
full -X- _ I-MethodName
model -X- _ I-MethodName
leads -X- _ O
to -X- _ O
the -X- _ O
lowest -X- _ O
error -X- _ O
comparatively -X- _ O
early -X- _ O
in -X- _ O
training -X- _ O
, -X- _ O
e.g. -X- _ O
already -X- _ O
after -X- _ O
the -X- _ O
Ô¨Årst -X- _ O
epoch -X- _ O
on -X- _ O
imdb.336 -X- _ B-DatasetName
figure -X- _ O
4 -X- _ O
: -X- _ O
validation -X- _ B-MetricName
error -X- _ I-MetricName
rate -X- _ I-MetricName
curves -X- _ O
for -X- _ O
Ô¨Ånetuning -X- _ B-MethodName
the -X- _ O
classiÔ¨Åer -X- _ O
with -X- _ O
ulmfit -X- _ B-MethodName
and -X- _ O
‚Äò -X- _ O
full -X- _ B-MethodName
‚Äô -X- _ O
on -X- _ O
imdb -X- _ B-DatasetName
, -X- _ B-DatasetName
trec-6 -X- _ I-DatasetName
, -X- _ O
and -X- _ O
ag -X- _ B-DatasetName
( -X- _ O
top -X- _ O
to -X- _ O
bottom -X- _ O
) -X- _ O
. -X- _ O

to -X- _ O
better -X- _ O
understand -X- _ O
the -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
behavior -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
validation -X- _ O
error -X- _ B-MetricName
of -X- _ O
the -X- _ O
classiÔ¨Åer -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
ulmfit -X- _ B-MethodName
and -X- _ O
‚Äò -X- _ O
full -X- _ B-MethodName
‚Äô -X- _ O
during -X- _ O
training -X- _ O
in -X- _ O
figure -X- _ O
4 -X- _ O
. -X- _ O

classiÔ¨Åer -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
behavior -X- _ O
while -X- _ O
our -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
how -X- _ O
we -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
the -X- _ O
classiÔ¨Åer -X- _ O
makes -X- _ O
a -X- _ O
signiÔ¨Åcant -X- _ O
difference -X- _ O
, -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
for -X- _ O
inductive -X- _ O
transfer -X- _ O
is -X- _ O
currently -X- _ O
under -X- _ O
- -X- _ O
explored -X- _ O
in -X- _ O
nlp -X- _ O
as -X- _ O
it -X- _ O
mostly -X- _ O
has -X- _ O
been -X- _ O
thought -X- _ O
to -X- _ O
be -X- _ O
unhelpful -X- _ O
( -X- _ O
mou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

importantly -X- _ O
, -X- _ O
ulmfit -X- _ B-MethodName
is -X- _ O
the -X- _ O
only -X- _ O
method -X- _ O
that -X- _ O
shows -X- _ O
excellent -X- _ O
performance -X- _ O
across -X- _ O
the -X- _ O
board -X- _ O
‚Äî -X- _ O
and -X- _ O
is -X- _ O
therefore -X- _ O
the -X- _ O
only -X- _ O
universal -X- _ O
method -X- _ O
. -X- _ O

finally -X- _ O
, -X- _ O
full -X- _ B-MethodName
ulmfit -X- _ B-MethodName
classiÔ¨Åer -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
bottom -X- _ O
row -X- _ O
) -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
imdb -X- _ B-DatasetName
and -X- _ O
trec-6 -X- _ B-DatasetName
and -X- _ O
competitive -X- _ O
performance -X- _ O
on -X- _ O
ag -X- _ B-DatasetName
. -X- _ O

cosine -X- _ B-MethodName
annealing -X- _ I-MethodName
is -X- _ O
competitive -X- _ O
with -X- _ O
slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
on -X- _ O
large -X- _ O
data -X- _ O
, -X- _ O
but -X- _ O
under -X- _ O
- -X- _ O
performs -X- _ O
on -X- _ O
smaller -X- _ O
datasets -X- _ O
. -X- _ O

discr -X- _ B-MethodName
‚Äô -X- _ O
consistently -X- _ O
boosts -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
‚Äò -X- _ O
full -X- _ B-MethodName
‚Äô -X- _ O
and -X- _ O
‚Äò -X- _ O
freez -X- _ B-MethodName
‚Äô -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
large -X- _ O
ag -X- _ B-DatasetName
. -X- _ O

freez -X- _ B-MethodName
‚Äô -X- _ O
provides -X- _ O
similar -X- _ O
performance -X- _ O
as -X- _ O
‚Äò -X- _ O
full -X- _ B-MethodName
‚Äô -X- _ O
. -X- _ O
‚Äò -X- _ O

chainthaw -X- _ O
‚Äô -X- _ O
achieves -X- _ O
competitive -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
smaller -X- _ O
datasets -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
outperformed -X- _ O
signiÔ¨Åcantly -X- _ O
on -X- _ O
the -X- _ O
large -X- _ O
ag -X- _ B-DatasetName
. -X- _ O
‚Äò -X- _ O

last -X- _ O
‚Äô -X- _ O
, -X- _ O
the -X- _ O
standard -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
method -X- _ O
in -X- _ O
cv -X- _ O
, -X- _ O
severely -X- _ O
underÔ¨Åts -X- _ O
and -X- _ O
is -X- _ O
never -X- _ O
able -X- _ O
to -X- _ O
lower -X- _ O
the -X- _ O
training -X- _ O
error -X- _ B-MetricName
to -X- _ O
0 -X- _ O
. -X- _ O
‚Äò -X- _ O

fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
classiÔ¨Åer -X- _ O
signiÔ¨Åcantly -X- _ O
improves -X- _ O
over -X- _ O
training -X- _ O
from -X- _ B-MethodName
scratch -X- _ I-MethodName
, -X- _ O
particularly -X- _ O
on -X- _ O
the -X- _ O
small -X- _ O
trec-6 -X- _ B-DatasetName
. -X- _ O
‚Äò -X- _ O

we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
l= -X- _ B-HyperparameterName
0:01for -X- _ B-HyperparameterValue
‚Äò -X- _ O
discr -X- _ B-MethodName
‚Äô -X- _ O
, -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
8to -X- _ B-HyperparameterValue
avoid -X- _ O
overÔ¨Åtting -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
train -X- _ O
the -X- _ O
vanilla -X- _ B-MethodName
lm -X- _ I-MethodName
classiÔ¨Åer -X- _ O
for -X- _ O
5epochs -X- _ B-HyperparameterValue
and -X- _ O
keep -X- _ O
dropout -X- _ B-HyperparameterName
of -X- _ O
0:4 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
classiÔ¨Åer -X- _ O
. -X- _ O

we -X- _ O
compare -X- _ O
the -X- _ O
latter -X- _ O
to -X- _ O
an -X- _ O
alternative -X- _ O
, -X- _ O
aggressive -X- _ O
cosine -X- _ B-MethodName
annealing -X- _ I-MethodName
schedule -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
cos -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
( -X- _ O
loshchilov -X- _ O
and -X- _ O
hutter -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

we -X- _ O
furthermore -X- _ O
assess -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
discriminative -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
discr -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
and -X- _ O
slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
stlr -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ B-MethodName
gradual -X- _ I-MethodName
unfreezing -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
freez -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
. -X- _ O

2014 -X- _ O
) -X- _ O
, -X- _ O
‚Äò -X- _ O
chain -X- _ O
- -X- _ O
thaw -X- _ O
‚Äô -X- _ O
( -X- _ O
felbo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

impact -X- _ O
of -X- _ O
classiÔ¨Åer -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
we -X- _ O
compare -X- _ O
training -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ B-MethodName
full -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
full -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
, -X- _ O
only -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ I-MethodName
last -X- _ I-MethodName
layer -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
last -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
( -X- _ O
donahue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

discr -X- _ B-MethodName
‚Äô -X- _ O
and -X- _ O
‚Äò -X- _ O
stlr -X- _ B-MethodName
‚Äô -X- _ O
improve -X- _ O
performance -X- _ O
across -X- _ O
all -X- _ O
three -X- _ O
datasets -X- _ O
and -X- _ O
are -X- _ O
necessary -X- _ O
on -X- _ O
the -X- _ O
smaller -X- _ B-DatasetName
trec-6 -X- _ I-DatasetName
, -X- _ O
where -X- _ O
regular -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
is -X- _ O
not -X- _ O
beneÔ¨Åcial -X- _ O
. -X- _ O

fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
lm -X- _ O
is -X- _ O
most -X- _ O
beneÔ¨Åcial -X- _ O
for -X- _ O
larger -X- _ O
datasets -X- _ O
. -X- _ O
‚Äò -X- _ O

2010 -X- _ O
) -X- _ O
( -X- _ O
‚Äò -X- _ O
full -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
most -X- _ O
commonly -X- _ O
used -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
method -X- _ O
, -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
discriminative -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
discr -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
and -X- _ O
slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
stlr -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
in -X- _ O
table -X- _ O
6 -X- _ O
. -X- _ O

impact -X- _ O
of -X- _ O
lm -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
we -X- _ O
compare -X- _ O
no -X- _ O
Ô¨Ånetuning -X- _ B-MethodName
against -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
full -X- _ O
model -X- _ O
( -X- _ O
erhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

on -X- _ O
the -X- _ O
smaller -X- _ B-DatasetName
trec-6 -X- _ I-DatasetName
, -X- _ O
a -X- _ O
vanilla -X- _ O
lm -X- _ O
without -X- _ O
dropout -X- _ O
runs -X- _ O
the -X- _ O
risk -X- _ O
of -X- _ O
overÔ¨Åtting -X- _ O
, -X- _ O
which -X- _ O
decreases -X- _ O
performance -X- _ O
. -X- _ O

using -X- _ O
our -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
techniques -X- _ O
, -X- _ O
even -X- _ O
a -X- _ O
regular -X- _ O
lm -X- _ O
reaches -X- _ O
surprisingly -X- _ O
good -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
larger -X- _ O
datasets -X- _ O
. -X- _ O

impact -X- _ O
of -X- _ O
lm -X- _ O
quality -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
gauge -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
choosing -X- _ O
an -X- _ O
appropriate -X- _ O
lm -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
a -X- _ O
vanilla -X- _ O
lm -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
without -X- _ O
any -X- _ O
dropout8with -X- _ O
the -X- _ O
awd -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
lm -X- _ I-MethodName
with -X- _ O
tuned -X- _ O
dropout -X- _ O
parameters -X- _ O
in -X- _ O
table -X- _ O
5 -X- _ O
. -X- _ O

however -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
large -X- _ O
datasets -X- _ O
, -X- _ O
pretraining -X- _ B-MethodName
improves -X- _ O
performance.335lm -X- _ O
imdb -X- _ B-DatasetName
trec-6 -X- _ B-DatasetName
ag -X- _ B-DatasetName
vanilla -X- _ B-MethodName
lm -X- _ I-MethodName
5.98 -X- _ O
7.41 -X- _ O
5.76 -X- _ O
awd -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
lm -X- _ B-MethodName
5.00 -X- _ O
5.69 -X- _ O
5.38 -X- _ O
table -X- _ O
5 -X- _ O
: -X- _ O
validation -X- _ B-MetricName
error -X- _ I-MetricName
rates -X- _ I-MetricName
for -X- _ O
ulmfit -X- _ B-MethodName
with -X- _ O
a -X- _ O
vanilla -X- _ B-MethodName
lm -X- _ I-MethodName
and -X- _ I-MethodName
the -X- _ I-MethodName
awd -X- _ I-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
lm -X- _ I-MethodName
. -X- _ O

pretraining -X- _ B-MethodName
is -X- _ O
most -X- _ O
useful -X- _ O
for -X- _ O
small -X- _ O
and -X- _ O
medium -X- _ O
- -X- _ O
sized -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
most -X- _ O
common -X- _ O
in -X- _ O
commercial -X- _ O
applications -X- _ O
. -X- _ O

impact -X- _ O
of -X- _ O
pretraining -X- _ B-MethodName
we -X- _ O
compare -X- _ O
using -X- _ O
no -X- _ O
pretraining -X- _ B-MethodName
with -X- _ O
pretraining -X- _ B-MethodName
on -X- _ O
wikitext-103 -X- _ B-DatasetName
( -X- _ O
merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

on -X- _ O
trec-6 -X- _ B-DatasetName
, -X- _ O
ulmfit -X- _ B-MethodName
signiÔ¨Åcantly -X- _ O
improves -X- _ O
upon -X- _ O
training -X- _ O
from -X- _ B-MethodName
scratch -X- _ I-MethodName
; -X- _ O
as -X- _ O
examples -X- _ O
are -X- _ O
shorter -X- _ O
and -X- _ O
fewer -X- _ O
, -X- _ O
supervised -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
ulmfit -X- _ B-MethodName
achieve -X- _ O
similar -X- _ O
results -X- _ O
. -X- _ O

if -X- _ O
we -X- _ O
allow -X- _ O
ulmfit -X- _ B-MethodName
to -X- _ O
also -X- _ O
utilize -X- _ O
unlabeled -X- _ O
examples -X- _ O
( -X- _ O
50k -X- _ O
for -X- _ O
imdb -X- _ B-DatasetName
, -X- _ O
100k -X- _ O
for -X- _ O
ag -X- _ B-DatasetName
) -X- _ O
, -X- _ O
at -X- _ O
100labeled -X- _ O
examples -X- _ O
, -X- _ O
we -X- _ O
match -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
training -X- _ O
from -X- _ O
scratch -X- _ O
with -X- _ O
50and100more -X- _ O
data -X- _ O
on -X- _ O
ag -X- _ B-DatasetName
and -X- _ O
imdb -X- _ B-DatasetName
respectively -X- _ O
. -X- _ O

on -X- _ O
imdb -X- _ B-DatasetName
and -X- _ O
ag -X- _ B-DatasetName
, -X- _ O
supervised -X- _ O
ulmfit -X- _ B-MethodName
with -X- _ O
only -X- _ O
100 -X- _ O
labeled -X- _ O
examples -X- _ O
matches -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
training -X- _ O
from -X- _ O
scratch -X- _ O
with -X- _ O
10and20 -X- _ O
more -X- _ O
data -X- _ O
respectively -X- _ O
, -X- _ O
clearly -X- _ O
demonstrating -X- _ O
the -X- _ O
beneÔ¨Åt -X- _ O
of -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
lm -X- _ O
pretraining -X- _ B-MethodName
. -X- _ O

we -X- _ O
split -X- _ O
off -X- _ O
balanced -X- _ O
fractions -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
keep -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
Ô¨Åxed -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
as -X- _ O
before -X- _ O
. -X- _ O

we -X- _ O
compare -X- _ O
ulmfit -X- _ B-MethodName
to -X- _ O
training -X- _ O
from -X- _ O
scratch -X- _ O
‚Äî -X- _ O
which -X- _ O
is -X- _ O
necessary -X- _ O
for -X- _ O
hypercolumn -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
. -X- _ O

we -X- _ O
evaluate -X- _ O
ulmfit -X- _ B-MethodName
on -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
labeled -X- _ O
examples -X- _ O
in -X- _ O
two -X- _ O
settings -X- _ O
: -X- _ O
only -X- _ O
labeled -X- _ O
examples -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
lm -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
supervised -X- _ O
‚Äô -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
all -X- _ O
task -X- _ O
data -X- _ O
is -X- _ O
available -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
the -X- _ O
lm -X- _ O
( -X- _ O
‚Äò -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
‚Äô -X- _ O
) -X- _ O
. -X- _ O

we -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
the -X- _ O
classiÔ¨Åer -X- _ O
for -X- _ O
50epochs -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
all -X- _ O
methods -X- _ O
but -X- _ O
ulmfit -X- _ B-MethodName
with -X- _ O
early -X- _ O
stopping -X- _ O
. -X- _ O

for -X- _ O
all -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
off -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
report -X- _ O
error -X- _ B-MetricName
rates -X- _ I-MetricName
on -X- _ O
this -X- _ O
validation -X- _ O
set -X- _ O
with -X- _ O
unidirectional -X- _ O
lms -X- _ O
. -X- _ O

we -X- _ O
run -X- _ O
experiments -X- _ O
on -X- _ O
three -X- _ O
corpora -X- _ O
, -X- _ O
imdb -X- _ B-DatasetName
, -X- _ O
trec6 -X- _ B-DatasetName
, -X- _ O
and -X- _ O
ag -X- _ B-DatasetName
that -X- _ O
are -X- _ O
representative -X- _ O
of -X- _ O
different -X- _ O
tasks -X- _ O
, -X- _ O
genres -X- _ O
, -X- _ O
and -X- _ O
sizes -X- _ O
. -X- _ O

5 -X- _ O
analysis -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
each -X- _ O
contribution -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
analyses -X- _ O
and -X- _ O
ablations -X- _ O
. -X- _ O

on -X- _ O
dbpedia -X- _ B-DatasetName
, -X- _ O
yelp -X- _ B-DatasetName
- -X- _ I-DatasetName
bi -X- _ I-DatasetName
, -X- _ O
and -X- _ B-DatasetName
yelp -X- _ I-DatasetName
- -X- _ I-DatasetName
full -X- _ I-DatasetName
, -X- _ O
we -X- _ O
reduce -X- _ O
the -X- _ O
error -X- _ B-MetricName
by -X- _ O
4.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
18.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
2.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
respectively -X- _ O
. -X- _ O

on -X- _ O
ag -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
similarly -X- _ O
dramatic -X- _ O
error -X- _ B-MetricName
reduction -X- _ O
by -X- _ O
23.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
compared -X- _ O
to -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
. -X- _ O

our -X- _ O
method -X- _ O
again -X- _ O
outperforms -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
signiÔ¨Åcantly -X- _ O
. -X- _ O

we -X- _ O
show -X- _ O
the -X- _ O
test -X- _ O
error -X- _ B-MetricName
rates -X- _ I-MetricName
on -X- _ O
the -X- _ O
larger -X- _ O
ag -X- _ B-DatasetName
, -X- _ O
dbpedia -X- _ B-DatasetName
, -X- _ O
yelp -X- _ B-DatasetName
- -X- _ I-DatasetName
bi -X- _ I-DatasetName
, -X- _ O
and -X- _ O
yelp -X- _ B-DatasetName
- -X- _ I-DatasetName
full -X- _ I-DatasetName
datasets -X- _ O
in -X- _ O
table -X- _ O
3 -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
consistently -X- _ O
outperform -X- _ O
their -X- _ O
approach -X- _ O
on -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O

note -X- _ O
that -X- _ O
despite -X- _ O
pretraining -X- _ B-MethodName
on -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
less -X- _ O
data -X- _ O
than -X- _ O
the -X- _ O
7 -X- _ O
million -X- _ O
sentence -X- _ O
pairs -X- _ O
used -X- _ O
by -X- _ O
mccann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O

nevertheless -X- _ O
, -X- _ O
the -X- _ O
competitive -X- _ O
performance -X- _ O
on -X- _ O
trec-6 -X- _ B-DatasetName
demonstrates -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
performs -X- _ O
well -X- _ O
across -X- _ O
different -X- _ O
dataset -X- _ O
sizes -X- _ O
and -X- _ O
can -X- _ O
deal -X- _ O
with -X- _ O
examples -X- _ O
that -X- _ O
range -X- _ O
from -X- _ O
single -X- _ O
sentences -X- _ O
‚Äî -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
trec-6 -X- _ B-DatasetName
‚Äî -X- _ O
to -X- _ O
several -X- _ O
paragraphs -X- _ O
for -X- _ O
imdb -X- _ B-DatasetName
. -X- _ O

on -X- _ O
trec-6 -X- _ B-DatasetName
, -X- _ O
our -X- _ O
improvement -X- _ O
‚Äî -X- _ O
similar -X- _ O
as -X- _ O
the -X- _ O
improvements -X- _ O
of -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
approaches -X- _ O
‚Äî -X- _ O
is -X- _ O
not -X- _ O
statistically -X- _ O
signiÔ¨Åcant -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
small -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
500 -X- _ O
- -X- _ O
examples -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

paragraphs -X- _ O
long -X- _ O
‚Äî -X- _ O
similar -X- _ O
to -X- _ O
emails -X- _ O
( -X- _ O
e.g -X- _ O
for -X- _ O
legal -X- _ O
discovery -X- _ O
) -X- _ O
and -X- _ O
online -X- _ O
comments -X- _ O
( -X- _ O
e.g -X- _ O
for -X- _ O
community -X- _ O
management -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
is -X- _ O
similar -X- _ O
to -X- _ O
many -X- _ O
commercial -X- _ O
applications -X- _ O
, -X- _ O
e.g. -X- _ O
product -X- _ O
response -X- _ O
tracking -X- _ O
and -X- _ O
support -X- _ O
email -X- _ O
routing -X- _ O
. -X- _ O

imdb -X- _ B-DatasetName
in -X- _ O
particular -X- _ O
is -X- _ O
reÔ¨Çective -X- _ O
of -X- _ O
realworld -X- _ O
datasets -X- _ O
: -X- _ O
its -X- _ O
documents -X- _ O
are -X- _ O
generally -X- _ O
a -X- _ O
few334 -X- _ O
figure -X- _ O
3 -X- _ O
: -X- _ O
validation -X- _ O
error -X- _ B-MetricName
rates -X- _ I-MetricName
for -X- _ O
supervised -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
ulmfit -X- _ B-MethodName
vs. -X- _ O
training -X- _ O
from -X- _ B-MethodName
scratch -X- _ I-MethodName
with -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
training -X- _ O
examples -X- _ O
on -X- _ O
imdb -X- _ B-DatasetName
, -X- _ O
trec-6 -X- _ B-DatasetName
, -X- _ O
and -X- _ O
ag -X- _ B-DatasetName
( -X- _ O
from -X- _ O
left -X- _ O
to -X- _ O
right -X- _ O
) -X- _ O
. -X- _ O

we -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
approach -X- _ O
of -X- _ O
dai -X- _ O
and -X- _ O
le -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
only -X- _ O
achieves -X- _ O
an -X- _ O
error -X- _ B-MetricName
of -X- _ B-MetricValue
7.64 -X- _ I-MetricValue
vs. -X- _ O
4.6 -X- _ B-MetricValue
for -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
imdb -X- _ B-DatasetName
, -X- _ O
demonstrating -X- _ O
the -X- _ O
beneÔ¨Åt -X- _ O
of -X- _ O
transferring -X- _ O
knowledge -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
imagenet -X- _ O
- -X- _ O
like -X- _ O
corpus -X- _ O
using -X- _ O
our -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
techniques -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
and -X- _ O
sophisticated -X- _ O
embedding -X- _ O
schemes -X- _ O
( -X- _ O
johnson -X- _ O
and -X- _ O
zhang -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
our -X- _ O
method -X- _ O
employs -X- _ O
a -X- _ O
regular -X- _ O
lstm -X- _ O
with -X- _ O
dropout -X- _ O
. -X- _ O

2018 -X- _ O
) -X- _ O
, -X- _ O
multiple -X- _ O
forms -X- _ O
of -X- _ O
attention -X- _ O
( -X- _ O
mccann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

this -X- _ O
is -X- _ O
promising -X- _ O
as -X- _ O
the -X- _ O
existing -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
requires -X- _ O
complex -X- _ O
architectures -X- _ O
( -X- _ O
peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

on -X- _ O
imdb -X- _ B-DatasetName
, -X- _ O
we -X- _ O
reduce -X- _ O
the -X- _ O
error -X- _ B-MetricName
dramatically -X- _ O
by -X- _ O
43.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
22 -X- _ B-MetricValue
% -X- _ I-MetricValue
with -X- _ O
regard -X- _ O
to -X- _ O
cove -X- _ B-MethodName
and -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
respectively -X- _ O
. -X- _ O

our -X- _ O
method -X- _ O
outperforms -X- _ O
both -X- _ O
cove -X- _ B-MethodName
, -X- _ O
a -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
transfer -X- _ O
learning -X- _ O
method -X- _ O
based -X- _ O
on -X- _ O
hypercolumns -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O

we -X- _ O
show -X- _ O
the -X- _ O
test -X- _ O
error -X- _ B-MetricName
rates -X- _ I-MetricName
on -X- _ O
the -X- _ O
imdb -X- _ B-DatasetName
and -X- _ O
trec-6 -X- _ B-DatasetName
datasets -X- _ O
used -X- _ O
by -X- _ O
mccann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O

4.2 -X- _ O
results -X- _ O
for -X- _ O
consistency -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
all -X- _ O
results -X- _ O
as -X- _ O
error -X- _ B-MetricName
rates -X- _ I-MetricName
( -X- _ O
lower -X- _ O
is -X- _ O
better -X- _ O
) -X- _ O
. -X- _ O

for -X- _ O
the -X- _ O
ag -X- _ B-DatasetName
, -X- _ O
yelp -X- _ B-DatasetName
, -X- _ O
and -X- _ O
dbpedia -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
against -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
text -X- _ B-TaskName
categorization -X- _ I-TaskName
method -X- _ O
by -X- _ O
johnson -X- _ O
and -X- _ O
zhang -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
transfer -X- _ O
learning -X- _ O
method -X- _ O
for -X- _ O
nlp -X- _ O
. -X- _ O

for -X- _ O
the -X- _ O
imdb -X- _ B-DatasetName
and -X- _ O
trec-6 -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
against -X- _ O
cove -X- _ B-MethodName
( -X- _ O
mccann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

baselines -X- _ O
and -X- _ O
comparison -X- _ O
models -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
against -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
. -X- _ O

we -X- _ O
found -X- _ O
50epochs -X- _ B-HyperparameterValue
to -X- _ O
be -X- _ O
a -X- _ O
good -X- _ O
default -X- _ O
for -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
classiÔ¨Åer.used -X- _ O
in -X- _ O
( -X- _ O
merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
otherwise -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
practices -X- _ O
7on -X- _ O
small -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
trec-6 -X- _ B-DatasetName
, -X- _ O
we -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
the -X- _ O
lm -X- _ O
only -X- _ O
for -X- _ O
15epochs -X- _ B-HyperparameterValue
without -X- _ O
overÔ¨Åtting -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
can -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
longer -X- _ O
on -X- _ O
larger -X- _ O
datasets -X- _ O
. -X- _ O

we -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
, -X- _ O
a -X- _ O
base -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0:004 -X- _ B-HyperparameterValue
and0:01for -X- _ B-HyperparameterValue
Ô¨Ånetuning -X- _ O
the -X- _ O
lm -X- _ O
and -X- _ O
the -X- _ O
classiÔ¨Åer -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
tune -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
epochs -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
each -X- _ O
task7 -X- _ O
. -X- _ O

we -X- _ O
use -X- _ O
adam -X- _ B-HyperparameterName
with -X- _ O
1= -X- _ B-HyperparameterValue
0:7instead -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
default -X- _ O
1= -X- _ B-HyperparameterValue
0:9and -X- _ I-HyperparameterValue
2= -X- _ B-HyperparameterValue
0:99 -X- _ I-HyperparameterValue
, -X- _ O
similar -X- _ O
to -X- _ O
( -X- _ O
dozat -X- _ O
and -X- _ O
manning -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

we -X- _ O
apply -X- _ O
dropout -X- _ B-HyperparameterName
of -X- _ O
0:4to -X- _ B-HyperparameterValue
layers -X- _ O
, -X- _ B-HyperparameterValue
0:3to -X- _ I-HyperparameterValue
rnn -X- _ O
layers -X- _ O
, -X- _ O
0:4to -X- _ B-HyperparameterValue
input -X- _ O
embedding -X- _ O
layers -X- _ O
, -X- _ O
0:05to -X- _ B-HyperparameterValue
embedding -X- _ O
layers -X- _ O
, -X- _ O
and -X- _ O
weight -X- _ B-HyperparameterName
dropout -X- _ I-HyperparameterName
of -X- _ O
0:5to -X- _ B-HyperparameterValue
the -X- _ O
rnn -X- _ O
hidden -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
hidden -X- _ O
matrix -X- _ O
. -X- _ O

2017a -X- _ O
) -X- _ O
with -X- _ O
an -X- _ O
embedding -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
400,3layers -X- _ B-HyperparameterValue
, -X- _ O
1150 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
activations -X- _ I-HyperparameterName
per -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
a -X- _ O
bptt -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
70 -X- _ B-HyperparameterValue
. -X- _ O

we -X- _ O
use -X- _ O
the -X- _ O
awd -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
language -X- _ O
model -X- _ O
( -X- _ O
merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

to -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
if -X- _ O
not -X- _ O
mentioned -X- _ O
otherwise -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
hyperparameters -X- _ O
across -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
tune -X- _ O
on -X- _ O
the -X- _ O
imdb -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

hyperparameters -X- _ O
we -X- _ O
are -X- _ O
interested -X- _ O
in -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
performs -X- _ O
robustly -X- _ O
across -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O

in -X- _ O
addition -X- _ O
, -X- _ O
to -X- _ O
allow -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
capture -X- _ O
aspects -X- _ O
that -X- _ O
might -X- _ O
be -X- _ O
relevant -X- _ O
for -X- _ O
classiÔ¨Åcation -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
special -X- _ O
tokens -X- _ O
for -X- _ O
upper -X- _ O
- -X- _ O
case -X- _ O
words -X- _ O
, -X- _ O
elongation -X- _ O
, -X- _ O
and -X- _ O
repetition -X- _ O
. -X- _ O

pre -X- _ O
- -X- _ O
processing -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
as -X- _ O
in -X- _ O
earlier -X- _ O
work -X- _ O
( -X- _ O
johnson -X- _ O
and -X- _ O
zhang -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
mccann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

topic -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
for -X- _ O
topic -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
, -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
ag -X- _ B-DatasetName
news -X- _ O
and -X- _ O
dbpedia -X- _ B-DatasetName
ontology -X- _ O
datasets -X- _ O
created -X- _ O
by -X- _ O
zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O

2016 -X- _ O
) -X- _ O
5.9 -X- _ B-MethodName
lstm -X- _ I-MethodName
- -X- _ I-MethodName
cnn -X- _ I-MethodName
( -X- _ O
zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2017 -X- _ O
) -X- _ O
4.2 -X- _ O
oh -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ B-MethodName
( -X- _ O
johnson -X- _ O
and -X- _ O
zhang -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
5.9 -X- _ O
tbcnn -X- _ B-MethodName
( -X- _ O
mou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

question -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
we -X- _ O
use -X- _ O
the -X- _ O
six -X- _ O
- -X- _ O
class -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
small -X- _ O
trec -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
v -X- _ O
oorhees -X- _ O
and -X- _ O
tice -X- _ O
, -X- _ O
1999 -X- _ O
) -X- _ O
dataset -X- _ O
of -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
, -X- _ O
fact -X- _ O
- -X- _ O
based -X- _ O
questions -X- _ O
divided -X- _ O
into -X- _ O
broad -X- _ O
semantic -X- _ O
categories.333model -X- _ O
test -X- _ O
model -X- _ O
testimdbcove -X- _ O
( -X- _ O
mccann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2011 -X- _ O
) -X- _ O
and -X- _ O
on -X- _ O
the -X- _ O
binary -X- _ O
and -X- _ O
Ô¨Åve -X- _ O
- -X- _ O
class -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
yelp -X- _ B-DatasetName
review -X- _ O
dataset -X- _ O
compiled -X- _ O
by -X- _ O
zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O

sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
for -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
binary -X- _ O
movie -X- _ O
review -X- _ O
imdb -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
maas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
show -X- _ O
the -X- _ O
statistics -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
and -X- _ O
task -X- _ O
in -X- _ O
table -X- _ O
1 -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
as -X- _ O
instances -X- _ O
of -X- _ O
three -X- _ O
common -X- _ O
text -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
tasks -X- _ O
: -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
, -X- _ O
question -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
, -X- _ O
and -X- _ O
topic -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
. -X- _ O

4.1 -X- _ O
experimental -X- _ O
setup -X- _ O
datasets -X- _ O
and -X- _ O
tasks -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
six -X- _ O
widely -X- _ O
- -X- _ O
studied -X- _ O
datasets -X- _ O
, -X- _ O
with -X- _ O
varying -X- _ O
numbers -X- _ O
of -X- _ O
documents -X- _ O
and -X- _ O
varying -X- _ O
document -X- _ O
length -X- _ O
, -X- _ O
used -X- _ O
by -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
text -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
and -X- _ B-MethodName
transfer -X- _ I-MethodName
learning -X- _ I-MethodName
approaches -X- _ O
( -X- _ O
johnson -X- _ O
and -X- _ O
zhang -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
mccann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

4 -X- _ O
experiments -X- _ O
while -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
equally -X- _ O
applicable -X- _ O
to -X- _ O
sequence -X- _ O
labeling -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
text -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
tasks -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
important -X- _ O
realworld -X- _ O
applications -X- _ O
. -X- _ O

we -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
a -X- _ O
classiÔ¨Åer -X- _ O
for -X- _ O
each -X- _ O
lm -X- _ O
independently -X- _ O
using -X- _ O
bpt3c -X- _ O
and -X- _ O
average -X- _ O
the -X- _ O
classiÔ¨Åer -X- _ O
predictions -X- _ O
. -X- _ O

for -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
pretrain -X- _ B-MethodName
both -X- _ O
a -X- _ O
forward -X- _ O
and -X- _ O
a -X- _ O
backward -X- _ O
lm -X- _ O
. -X- _ O

2017 -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
not -X- _ O
limited -X- _ O
to -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
a -X- _ O
unidirectional -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

bidirectional -X- _ O
language -X- _ O
model -X- _ O
similar -X- _ O
to -X- _ O
existing -X- _ O
work -X- _ O
( -X- _ O
peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

in -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
variable -X- _ O
length -X- _ O
backpropagation -X- _ O
sequences -X- _ O
( -X- _ O
merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

bptt -X- _ O
for -X- _ O
text -X- _ O
classiÔ¨Åcation -X- _ O
( -X- _ O
bpt3c -X- _ O
) -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
backpropagation -X- _ O
through -X- _ O
time -X- _ O
( -X- _ O
bptt -X- _ O
) -X- _ O
to -X- _ O
enable -X- _ O
gradient -X- _ O
propagation -X- _ O
for -X- _ O
large -X- _ O
input -X- _ O
sequences -X- _ O
. -X- _ O

while -X- _ B-MethodName
discriminative -X- _ I-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
, -X- _ O
and -X- _ O
gradual -X- _ B-MethodName
unfreezing -X- _ I-MethodName
all -X- _ O
are -X- _ O
beneÔ¨Åcial -X- _ O
on -X- _ O
their -X- _ O
own -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
section -X- _ O
5 -X- _ O
that -X- _ O
they -X- _ O
complement -X- _ O
each -X- _ O
other -X- _ O
and -X- _ O
enable -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
perform -X- _ O
well -X- _ O
across -X- _ O
diverse -X- _ O
datasets -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
, -X- _ O
except -X- _ O
that -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
layer -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
to -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
‚Äò -X- _ O
thawed -X- _ O
‚Äô -X- _ O
layers -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
only -X- _ O
training -X- _ O
a -X- _ O
single -X- _ O
layer -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O

this -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
‚Äò -X- _ O
chain -X- _ O
- -X- _ O
thaw -X- _ O
‚Äô -X- _ O
( -X- _ O
felbo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
then -X- _ O
unfreeze -X- _ O
the -X- _ O
next -X- _ O
lower -X- _ O
frozen -X- _ O
layer -X- _ O
and -X- _ O
repeat -X- _ O
, -X- _ O
until -X- _ O
we -X- _ O
Ô¨Ånetune -X- _ B-MethodName
all -X- _ O
layers -X- _ O
until -X- _ O
convergence -X- _ O
at -X- _ O
the -X- _ O
last -X- _ O
iteration -X- _ O
. -X- _ O

2014 -X- _ O
): -X- _ O
we -X- _ O
Ô¨Årst -X- _ O
unfreeze -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
and -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
all -X- _ O
unfrozen -X- _ O
layers -X- _ O
for -X- _ O
one -X- _ O
epoch -X- _ O
. -X- _ O

gradual -X- _ B-MethodName
unfreezing -X- _ I-MethodName
rather -X- _ O
than -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
all -X- _ O
layers -X- _ O
at -X- _ O
once -X- _ O
, -X- _ O
which -X- _ O
risks -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
gradually -X- _ O
unfreeze -X- _ O
the -X- _ O
model -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
as -X- _ O
this -X- _ O
contains -X- _ O
the -X- _ O
least -X- _ O
general -X- _ O
knowledge -X- _ O
( -X- _ O
yosinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

besides -X- _ O
discriminative -X- _ B-MethodName
Ô¨Ånetuning -X- _ I-MethodName
and -X- _ O
triangular -X- _ B-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
, -X- _ O
we -X- _ O
propose -X- _ O
gradual -X- _ B-MethodName
unfreezing -X- _ I-MethodName
for -X- _ I-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
classiÔ¨Åer -X- _ O
. -X- _ O

overly -X- _ O
aggressive -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
will -X- _ O
cause -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
, -X- _ O
eliminating -X- _ O
the -X- _ O
beneÔ¨Åt -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
captured -X- _ O
through -X- _ O
language -X- _ O
modeling -X- _ O
; -X- _ O
too -X- _ O
cautious -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
will -X- _ O
lead -X- _ O
to -X- _ O
slow -X- _ O
convergence -X- _ O
( -X- _ O
and -X- _ O
resultant -X- _ O
overÔ¨Åtting -X- _ O
) -X- _ O
. -X- _ O

fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
target -X- _ O
classiÔ¨Åer -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
critical -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
transfer -X- _ B-MethodName
learning -X- _ I-MethodName
method -X- _ O
. -X- _ O

as -X- _ O
input -X- _ O
documents -X- _ O
can -X- _ O
consist -X- _ O
of -X- _ O
hundreds -X- _ O
of -X- _ O
words -X- _ O
, -X- _ O
information -X- _ O
may -X- _ O
get -X- _ O
lost -X- _ O
if -X- _ O
we -X- _ O
only -X- _ O
consider -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

6while -X- _ O
loshchilov -X- _ O
and -X- _ O
hutter -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
use -X- _ O
multiple -X- _ O
annealing -X- _ O
cycles -X- _ O
, -X- _ O
we -X- _ O
generally -X- _ O
found -X- _ O
one -X- _ O
cycle -X- _ O
to -X- _ O
work -X- _ O
best.332occur -X- _ O
anywhere -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
. -X- _ O

concat -X- _ O
pooling -X- _ O
the -X- _ O
signal -X- _ O
in -X- _ O
text -X- _ O
classiÔ¨Åcation -X- _ O
tasks -X- _ O
is -X- _ O
often -X- _ O
contained -X- _ O
in -X- _ O
a -X- _ O
few -X- _ O
words -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
5we -X- _ O
also -X- _ O
credit -X- _ O
personal -X- _ O
communication -X- _ O
with -X- _ O
the -X- _ O
author -X- _ O
. -X- _ O

the -X- _ O
Ô¨Årst -X- _ O
linear -X- _ O
layer -X- _ O
takes -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
the -X- _ O
pooled -X- _ O
last -X- _ O
hidden -X- _ O
layer -X- _ O
states -X- _ O
. -X- _ O

note -X- _ O
that -X- _ O
the -X- _ O
parameters -X- _ O
in -X- _ O
these -X- _ O
task -X- _ O
- -X- _ O
speciÔ¨Åc -X- _ O
classiÔ¨Åer -X- _ O
layers -X- _ O
are -X- _ O
the -X- _ O
only -X- _ O
ones -X- _ O
that -X- _ O
are -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

following -X- _ O
standard -X- _ O
practice -X- _ O
for -X- _ O
cv -X- _ O
classiÔ¨Åers -X- _ O
, -X- _ O
each -X- _ O
block -X- _ O
uses -X- _ O
batch -X- _ O
normalization -X- _ O
( -X- _ O
ioffe -X- _ O
and -X- _ O
szegedy -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
dropout -X- _ O
, -X- _ O
with -X- _ O
relu -X- _ O
activations -X- _ O
for -X- _ O
the -X- _ O
intermediate -X- _ O
layer -X- _ O
and -X- _ O
a -X- _ O
softmax -X- _ O
activation -X- _ O
that -X- _ O
outputs -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
target -X- _ O
classes -X- _ O
at -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
. -X- _ O

3.3 -X- _ O
target -X- _ O
task -X- _ O
classiÔ¨Åer -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
finally -X- _ O
, -X- _ O
for -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
classiÔ¨Åer -X- _ O
, -X- _ O
we -X- _ O
augment -X- _ O
the -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
two -X- _ O
additional -X- _ O
linear -X- _ O
blocks -X- _ O
. -X- _ O

stlr -X- _ B-MethodName
modiÔ¨Åes -X- _ O
triangular -X- _ O
learning -X- _ O
rates -X- _ O
( -X- _ O
smith -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
short -X- _ O
increase -X- _ O
and -X- _ O
a -X- _ O
long -X- _ O
decay -X- _ O
period -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
found -X- _ O
key -X- _ O
for -X- _ O
good -X- _ O
performance.5 -X- _ O
in -X- _ O
section -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
against -X- _ O
aggressive -X- _ O
cosine -X- _ O
annealing -X- _ O
, -X- _ O
a -X- _ O
similar -X- _ O
schedule -X- _ O
that -X- _ O
has -X- _ O
recently -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
in -X- _ O
cv -X- _ O
( -X- _ O
loshchilov -X- _ O
and -X- _ O
hutter -X- _ O
, -X- _ O
2017).6 -X- _ O
figure -X- _ O
2 -X- _ O
: -X- _ O
the -X- _ O
slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rate -X- _ I-MethodName
schedule -X- _ O
used -X- _ O
for -X- _ B-MethodName
ulmfit -X- _ I-MethodName
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
iterations -X- _ O
. -X- _ O

4in -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
times -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
updates -X- _ O
per -X- _ O
epoch.the -X- _ O
lr -X- _ O
, -X- _ O
cutis -X- _ O
the -X- _ O
iteration -X- _ O
when -X- _ O
we -X- _ O
switch -X- _ O
from -X- _ O
increasing -X- _ O
to -X- _ O
decreasing -X- _ O
the -X- _ O
lr -X- _ O
, -X- _ O
pis -X- _ O
the -X- _ O
fraction -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
iterations -X- _ O
we -X- _ O
have -X- _ O
increased -X- _ O
or -X- _ O
will -X- _ O
decrease -X- _ O
the -X- _ O
lr -X- _ O
respectively -X- _ O
, -X- _ O
ratio -X- _ O
speciÔ¨Åes -X- _ O
how -X- _ O
much -X- _ O
smaller -X- _ O
the -X- _ O
lowest -X- _ O
lr -X- _ O
is -X- _ O
from -X- _ O
the -X- _ O
maximum -X- _ O
lrmax -X- _ O
, -X- _ O
andtis -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
at -X- _ O
iteration -X- _ O
t. -X- _ O
we -X- _ O
generally -X- _ O
use -X- _ O
cutfrac -X- _ B-HyperparameterName
= -X- _ O
0:1,ratio -X- _ B-HyperparameterValue
= -X- _ O
32 -X- _ B-HyperparameterValue
and -X- _ O
max= -X- _ B-HyperparameterName
0:01 -X- _ B-HyperparameterValue
. -X- _ O

instead -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
( -X- _ O
stlr -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
Ô¨Årst -X- _ O
linearly -X- _ O
increases -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
and -X- _ O
then -X- _ O
linearly -X- _ O
decays -X- _ O
it -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
update -X- _ O
schedule -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
figure -X- _ O
2 -X- _ O
: -X- _ O
cut -X- _ O
= -X- _ O
btcutfracc -X- _ B-HyperparameterName
p= -X- _ O
( -X- _ O
t -X- _ O
= -X- _ O
cut -X- _ O
; -X- _ O
ift -X- _ O
< -X- _ O
cut -X- _ O
1 t cut -X- _ O
cut(ratio -X- _ O
 1);otherwise -X- _ O
t=max1 -X- _ O
+ -X- _ O
p(ratio 1 -X- _ B-HyperparameterName
) -X- _ B-HyperparameterName
ratio(3 -X- _ I-HyperparameterName
) -X- _ O
wheretis -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
iterations4 -X- _ B-HyperparameterName
, -X- _ I-HyperparameterName
cutfrac -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
fraction -X- _ O
of -X- _ O
iterations -X- _ O
we -X- _ O
increase -X- _ O
3an -X- _ O
unrelated -X- _ O
method -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
name -X- _ O
exists -X- _ O
for -X- _ O
deep -X- _ O
boltzmann -X- _ O
machines -X- _ O
( -X- _ O
salakhutdinov -X- _ O
and -X- _ O
hinton -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O

using -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ O
rate -X- _ O
( -X- _ O
lr -X- _ O
) -X- _ O
or -X- _ O
an -X- _ O
annealed -X- _ O
learning -X- _ O
rate -X- _ O
throughout -X- _ O
training -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
best -X- _ O
way -X- _ O
to -X- _ O
achieve -X- _ O
this -X- _ O
behaviour -X- _ O
. -X- _ O

slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
for -X- _ O
adapting -X- _ O
its -X- _ O
parameters -X- _ O
to -X- _ O
task -X- _ O
- -X- _ O
speciÔ¨Åc -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
quickly -X- _ O
converge -X- _ O
to -X- _ O
a -X- _ O
suitable -X- _ O
region -X- _ O
of -X- _ O
the -X- _ O
parameter -X- _ O
space -X- _ O
in -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
training -X- _ O
and -X- _ O
then -X- _ O
reÔ¨Åne -X- _ O
its -X- _ O
parameters -X- _ O
. -X- _ O

the -X- _ O
sgd -X- _ O
update -X- _ O
with -X- _ O
discriminative -X- _ B-MethodName
Ô¨Ånetuning -X- _ I-MethodName
is -X- _ O
then -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
l -X- _ O
t=l -X- _ O
t 1 lrlj( -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
empirically -X- _ O
found -X- _ O
it -X- _ O
to -X- _ O
work -X- _ O
well -X- _ O
to -X- _ O
Ô¨Årst -X- _ O
choose -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
lof -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
by -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
only -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
and -X- _ O
using -X- _ O
l 1= -X- _ O
l=2:6as -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
for -X- _ O
lower -X- _ O
layers -X- _ O
. -X- _ O

similarly -X- _ O
, -X- _ O
we -X- _ O
obtainf1;:::;lgwherelis -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
of -X- _ O
thel -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
. -X- _ O

for -X- _ O
discriminative -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
parametersintof1;:::;lgwherelcontains -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
at -X- _ O
the -X- _ O
l -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
and -X- _ O
lis -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

for -X- _ O
context -X- _ O
, -X- _ O
the -X- _ O
regular -X- _ O
stochastic -X- _ O
gradient -X- _ O
descent -X- _ O
( -X- _ O
sgd -X- _ O
) -X- _ O
update -X- _ O
of -X- _ O
a -X- _ O
model -X- _ O
‚Äôs -X- _ O
parameters -X- _ O
at -X- _ O
time -X- _ O
steptlooks -X- _ O
like -X- _ O
the -X- _ O
following -X- _ O
( -X- _ O
ruder -X- _ O
, -X- _ O
2016 -X- _ O
): -X- _ O
t=t 1 rj( -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
whereis -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
and -X- _ O
rj()is -X- _ O
the -X- _ O
gradient -X- _ O
with -X- _ O
regard -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
‚Äôs -X- _ O
objective -X- _ O
function -X- _ O
. -X- _ O

instead -X- _ O
of -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ O
rate -X- _ O
for -X- _ O
all -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
discriminative -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
allows -X- _ O
us -X- _ O
to -X- _ O
tune -X- _ O
each -X- _ O
layer -X- _ O
with -X- _ O
different -X- _ O
learning -X- _ O
rates -X- _ O
. -X- _ O

2014 -X- _ O
) -X- _ O
, -X- _ O
they -X- _ O
should -X- _ O
be -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
to -X- _ O
different -X- _ O
extents -X- _ O
. -X- _ O

discriminative -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
as -X- _ O
different -X- _ O
layers -X- _ O
capture -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
information -X- _ O
( -X- _ O
yosinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
propose -X- _ O
discriminative -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
andslanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
for -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
lm -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
introduce -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
. -X- _ O

given -X- _ O
a -X- _ O
pretrained -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
lm -X- _ O
, -X- _ O
this -X- _ O
stage -X- _ O
converges -X- _ O
faster -X- _ O
as -X- _ O
it -X- _ O
only -X- _ O
needs -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
idiosyncrasies -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
robust -X- _ O
lm -X- _ O
even -X- _ O
for -X- _ O
small -X- _ O
datasets -X- _ O
. -X- _ O

we -X- _ O
thus -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
the -X- _ O
lm -X- _ O
on -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

3.2 -X- _ O
target -X- _ O
task -X- _ O
lm -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
no -X- _ O
matter -X- _ O
how -X- _ O
diverse -X- _ O
the -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
used -X- _ O
for -X- _ O
pretraining -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
will -X- _ O
likely -X- _ O
come -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
distribution -X- _ O
. -X- _ O

while -X- _ O
this -X- _ O
stage -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
expensive -X- _ O
, -X- _ O
it -X- _ O
only -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
performed -X- _ O
once -X- _ O
and -X- _ O
improves -X- _ O
performance -X- _ O
and -X- _ O
convergence -X- _ O
of -X- _ O
downstream -X- _ O
models -X- _ O
. -X- _ O

we -X- _ O
leave -X- _ O
the -X- _ O
exploration -X- _ O
of -X- _ O
more -X- _ O
diverse -X- _ O
pretraining -X- _ O
corpora -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
but -X- _ O
expect -X- _ O
that -X- _ O
they -X- _ O
would -X- _ O
boost -X- _ O
performance -X- _ O
. -X- _ O

pretraining -X- _ B-MethodName
is -X- _ O
most -X- _ O
beneÔ¨Åcial -X- _ O
for -X- _ O
tasks -X- _ O
with -X- _ O
small -X- _ O
datasets -X- _ O
and -X- _ O
enables -X- _ O
generalization -X- _ O
even -X- _ O
with -X- _ O
100 -X- _ O
labeled -X- _ O
examples -X- _ O
. -X- _ O

2017b -X- _ O
) -X- _ O
consisting -X- _ O
of -X- _ O
28,595 -X- _ O
preprocessed -X- _ O
wikipedia -X- _ O
articles -X- _ O
and -X- _ O
103 -X- _ O
million -X- _ O
words -X- _ O
. -X- _ O

we -X- _ O
pretrain -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
wikitext-103 -X- _ B-DatasetName
( -X- _ O
merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
discuss -X- _ O
these -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
sections.3.1 -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
lm -X- _ O
pretraining -X- _ B-MethodName
an -X- _ O
imagenet -X- _ O
- -X- _ O
like -X- _ O
corpus -X- _ O
for -X- _ O
language -X- _ O
should -X- _ O
be -X- _ O
large -X- _ O
and -X- _ O
capture -X- _ O
general -X- _ O
properties -X- _ O
of -X- _ O
language -X- _ O
. -X- _ O

ulmfit -X- _ B-MethodName
consists -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
steps -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
figure -X- _ O
1 -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
lm -X- _ O
pretraining -X- _ B-MethodName
( -X- _ O
x3.1 -X- _ O
) -X- _ O
; -X- _ O
b -X- _ O
) -X- _ O
target -X- _ O
task -X- _ O
lm -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
x3.2 -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
c -X- _ O
) -X- _ O
target -X- _ O
task -X- _ O
classiÔ¨Åer -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
x3.3 -X- _ O
) -X- _ O
. -X- _ O

analogous -X- _ O
to -X- _ O
cv -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
that -X- _ O
downstream -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
by -X- _ O
using -X- _ O
higherperformance -X- _ O
language -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
. -X- _ O

2017a -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
regular -X- _ O
lstm -X- _ B-MethodName
( -X- _ O
with -X- _ O
no -X- _ O
attention -X- _ O
, -X- _ O
short -X- _ O
- -X- _ O
cut -X- _ O
connections -X- _ O
, -X- _ O
or -X- _ O
other -X- _ O
sophisticated -X- _ O
additions -X- _ O
) -X- _ O
with -X- _ O
various -X- _ O
tuned -X- _ O
dropout -X- _ O
hyperparameters -X- _ O
. -X- _ O

in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
language -X- _ O
model -X- _ O
awd -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
( -X- _ O
merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

the -X- _ O
method -X- _ O
is -X- _ O
universal -X- _ O
in -X- _ O
the -X- _ O
sense -X- _ O
that -X- _ O
it -X- _ O
meets -X- _ O
these -X- _ O
practical -X- _ O
criteria -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
it -X- _ O
works -X- _ O
across -X- _ O
tasks -X- _ O
varying -X- _ O
in -X- _ O
document -X- _ O
size -X- _ O
, -X- _ O
number -X- _ O
, -X- _ O
and -X- _ O
label -X- _ O
type -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
it -X- _ O
uses -X- _ O
a -X- _ O
single -X- _ O
architecture -X- _ O
and -X- _ O
training -X- _ O
process -X- _ O
; -X- _ O
3 -X- _ O
) -X- _ O
it -X- _ O
requires -X- _ O
no -X- _ O
custom -X- _ O
feature -X- _ O
engineering -X- _ O
or -X- _ O
preprocessing -X- _ O
; -X- _ O
and -X- _ O
4 -X- _ O
) -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
additional -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
documents -X- _ O
or -X- _ O
labels -X- _ O
. -X- _ O

we -X- _ O
propose -X- _ O
universal -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
finetuning -X- _ I-MethodName
( -X- _ O
ulmfit -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
pretrains -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
lm -X- _ O
) -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
corpus -X- _ O
and -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tunes -X- _ I-MethodName
it -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
using -X- _ O
novel -X- _ O
techniques -X- _ O
. -X- _ O

formally -X- _ O
, -X- _ O
language -X- _ O
modeling -X- _ O
induces -X- _ O
a -X- _ O
hypothesis -X- _ O
spacehthat -X- _ O
should -X- _ O
be -X- _ O
useful -X- _ O
for -X- _ O
many -X- _ O
other -X- _ O
nlp -X- _ O
tasks -X- _ O
( -X- _ O
vapnik -X- _ O
and -X- _ O
kotz -X- _ O
, -X- _ O
1982 -X- _ O
; -X- _ O
baxter -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
. -X- _ O

moreover -X- _ O
, -X- _ O
language -X- _ O
modeling -X- _ O
already -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
component -X- _ O
of -X- _ O
existing -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
mt -X- _ O
and -X- _ O
dialogue -X- _ O
modeling -X- _ O
. -X- _ O

task -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
show -X- _ O
signiÔ¨Åcantly -X- _ O
improves -X- _ O
performance -X- _ O
( -X- _ O
see -X- _ O
section -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

c -X- _ O
) -X- _ O
the -X- _ O
classiÔ¨Åer -X- _ O
is -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
using -X- _ O
gradual -X- _ B-MethodName
unfreezing -X- _ I-MethodName
, -X- _ O
‚Äò -X- _ O
discr -X- _ B-MethodName
‚Äô -X- _ O
, -X- _ O
and -X- _ O
stlr -X- _ B-MethodName
to -X- _ O
preserve -X- _ O
low -X- _ O
- -X- _ O
level -X- _ O
representations -X- _ O
and -X- _ O
adapt -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
ones -X- _ O
( -X- _ O
shaded -X- _ O
: -X- _ O
unfreezing -X- _ O
stages -X- _ O
; -X- _ O
black -X- _ O
: -X- _ O
frozen -X- _ O
) -X- _ O
. -X- _ O

b -X- _ O
) -X- _ O
the -X- _ O
full -X- _ O
lm -X- _ O
is -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
on -X- _ O
target -X- _ O
task -X- _ O
data -X- _ O
using -X- _ O
discriminative -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
‚Äò -X- _ O
discr -X- _ B-MethodName
‚Äô -X- _ O
) -X- _ O
and -X- _ O
slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
( -X- _ O
stlr -X- _ B-MethodName
) -X- _ O
to -X- _ O
learn -X- _ O
task -X- _ O
- -X- _ O
speciÔ¨Åc -X- _ O
features -X- _ O
. -X- _ O

