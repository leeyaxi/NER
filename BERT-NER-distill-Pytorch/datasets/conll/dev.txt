-DOCSTART- -X- O
2017 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
provides -X- _ O
data -X- _ O
in -X- _ O
near -X- _ O
- -X- _ O
unlimited -X- _ O
quantities -X- _ O
for -X- _ O
most -X- _ O
domains -X- _ O
and -X- _ O
languages -X- _ O
. -X- _ O

2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
sentiment -X- _ B-TaskName
( -X- _ O
radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

in -X- _ O
contrast -X- _ O
to -X- _ O
tasks -X- _ O
like -X- _ O
mt -X- _ O
( -X- _ O
mccann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2016 -X- _ O
) -X- _ O
, -X- _ O
hierarchical -X- _ O
relations -X- _ O
( -X- _ O
gulordava -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

language -X- _ O
modeling -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
the -X- _ O
ideal -X- _ O
source -X- _ O
task -X- _ O
and -X- _ O
a -X- _ O
counterpart -X- _ O
of -X- _ O
imagenet -X- _ O
for -X- _ O
nlp -X- _ O
: -X- _ O
it -X- _ O
captures -X- _ O
many -X- _ O
facets -X- _ O
of -X- _ O
language -X- _ O
relevant -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
long -X- _ O
- -X- _ O
term -X- _ O
dependencies -X- _ O
( -X- _ O
linzen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

3 -X- _ O
universal -X- _ O
language -X- _ O
model -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
we -X- _ O
are -X- _ O
interested -X- _ O
in -X- _ O
the -X- _ O
most -X- _ O
general -X- _ O
inductive -X- _ O
transfer -X- _ O
learning -X- _ O
setting -X- _ O
for -X- _ O
nlp -X- _ O
( -X- _ O
pan -X- _ O
and -X- _ O
yang -X- _ O
, -X- _ O
2010 -X- _ O
): -X- _ O
given -X- _ O
a -X- _ O
static -X- _ O
source -X- _ O
task -X- _ O
tsandanytarget -X- _ O
taskttwithts6 -X- _ O
= -X- _ O
tt -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
on -X- _ O
tt -X- _ O
. -X- _ O

in -X- _ O
contrast -X- _ O
, -X- _ O
ulmfit -X- _ B-MethodName
leverages -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
pretraining -X- _ O
and -X- _ O
novel -X- _ O
Ô¨Ånetuning -X- _ O
techniques -X- _ O
to -X- _ O
prevent -X- _ O
overÔ¨Åtting -X- _ O
even -X- _ O
with -X- _ O
only100labeled -X- _ O
examples -X- _ O
and -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
also -X- _ O
on -X- _ O
small -X- _ O
datasets -X- _ O
. -X- _ O

dai -X- _ O
and -X- _ O
le -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
also -X- _ O
Ô¨Åne -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
a -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
but -X- _ O
overÔ¨Åt -X- _ O
with -X- _ O
10k -X- _ O
labeled -X- _ O
examples -X- _ O
and -X- _ O
require -X- _ O
millions -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
documents -X- _ O
for -X- _ O
good -X- _ O
performance -X- _ O
. -X- _ O

2015 -X- _ O
) -X- _ O
but -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
fail -X- _ O
between -X- _ O
unrelated -X- _ O
ones -X- _ O
( -X- _ O
mou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2017 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
distantly -X- _ O
supervised -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
( -X- _ O
severyn -X- _ O
and -X- _ O
moschitti -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
mt -X- _ O
domains -X- _ O
( -X- _ O
sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
has -X- _ O
been -X- _ O
used -X- _ O
successfully -X- _ O
to -X- _ O
transfer -X- _ O
between -X- _ O
similar -X- _ O
tasks -X- _ O
, -X- _ O
e.g. -X- _ O
in -X- _ O
qa -X- _ B-TaskName
( -X- _ O
min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

mtl -X- _ O
requires -X- _ O
the -X- _ O
tasks -X- _ O
to -X- _ O
be -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
every -X- _ O
time -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
inefÔ¨Åcient -X- _ O
and -X- _ O
often -X- _ O
requires -X- _ O
careful -X- _ O
weighting -X- _ O
of -X- _ O
the -X- _ O
taskspeciÔ¨Åc -X- _ O
objective -X- _ O
functions -X- _ O
( -X- _ O
chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2018 -X- _ O
) -X- _ O
who -X- _ O
add -X- _ O
a -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
trained -X- _ O
jointly -X- _ O
with -X- _ O
the -X- _ O
main -X- _ O
task -X- _ O
model -X- _ O
. -X- _ O

this -X- _ O
is -X- _ O
the -X- _ O
approach -X- _ O
taken -X- _ O
by -X- _ O
rei -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O

multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
a -X- _ O
related -X- _ O
direction -X- _ O
is -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
( -X- _ O
mtl -X- _ O
) -X- _ O
( -X- _ O
caruana -X- _ O
, -X- _ O
1993 -X- _ O
) -X- _ O
. -X- _ O

in -X- _ O
cv -X- _ O
, -X- _ O
hypercolumns -X- _ O
have -X- _ O
been -X- _ O
nearly -X- _ O
entirely -X- _ O
superseded -X- _ O
by -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
( -X- _ O
long -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2018 -X- _ O
) -X- _ O
require -X- _ O
engineered -X- _ O
custom -X- _ O
architectures -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
show -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
basic -X- _ O
architecture -X- _ O
across -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
who -X- _ O
use -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
paraphrasing -X- _ O
, -X- _ O
entailment -X- _ O
, -X- _ O
and -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
mt -X- _ O
) -X- _ O
respectively -X- _ O
for -X- _ O
pretraining -X- _ O
. -X- _ O

in -X- _ O
analogy -X- _ O
, -X- _ O
a -X- _ O
hypercolumn -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
or -X- _ O
sentence -X- _ O
in -X- _ O
nlp -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
embeddings -X- _ O
at -X- _ O
different -X- _ O
layers -X- _ O
in -X- _ O
a -X- _ O
pretrained -X- _ O
model.et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O

2018 -X- _ O
) -X- _ O
, -X- _ O
wieting -X- _ O
and -X- _ O
gimpel -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
conneau -X- _ O
2a -X- _ O
hypercolumn -X- _ O
at -X- _ O
a -X- _ O
pixel -X- _ O
in -X- _ O
cv -X- _ O
is -X- _ O
the -X- _ O
vector -X- _ O
of -X- _ O
activations -X- _ O
of -X- _ O
all -X- _ O
cnn -X- _ B-MethodName
units -X- _ O
above -X- _ O
that -X- _ O
pixel -X- _ O
. -X- _ O

2 -X- _ O
) -X- _ O
we -X- _ O
propose -X- _ O
discriminative -X- _ B-MethodName
Ô¨Åne -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
slanted -X- _ B-MethodName
triangular -X- _ I-MethodName
learning -X- _ I-MethodName
rates -X- _ I-MethodName
, -X- _ O
and -X- _ O
gradual -X- _ B-MethodName
unfreezing -X- _ I-MethodName
, -X- _ O
novel -X- _ O
techniques -X- _ O
to -X- _ O
retain -X- _ O
previous -X- _ O
knowledge -X- _ O
and -X- _ O
avoid -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
during -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

this -X- _ O
method -X- _ O
is -X- _ O
known -X- _ O
as -X- _ O
hypercolumns -X- _ O
( -X- _ O
hariharan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

embeddings -X- _ O
at -X- _ O
different -X- _ O
levels -X- _ O
are -X- _ O
then -X- _ O
used -X- _ O
as -X- _ O
features -X- _ O
, -X- _ O
concatenated -X- _ O
either -X- _ O
with -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
or -X- _ O
with -X- _ O
the -X- _ O
inputs -X- _ O
at -X- _ O
intermediate -X- _ O
layers -X- _ O
. -X- _ O

the -X- _ O
prevailing -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
pretrain -X- _ O
embeddings -X- _ O
that -X- _ O
capture -X- _ O
additional -X- _ O
context -X- _ O
via -X- _ O
other -X- _ O
tasks -X- _ O
. -X- _ O

hypercolumns -X- _ O
in -X- _ O
nlp -X- _ O
, -X- _ O
only -X- _ O
recently -X- _ O
have -X- _ O
methods -X- _ O
been -X- _ O
proposed -X- _ O
that -X- _ O
go -X- _ O
beyond -X- _ O
transferring -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

2014 -X- _ O
) -X- _ O
or -X- _ O
several -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
layers -X- _ O
of -X- _ O
a -X- _ O
pretrained -X- _ O
model -X- _ O
and -X- _ O
leaving -X- _ O
the -X- _ O
remaining -X- _ O
layers -X- _ O
frozen -X- _ O
( -X- _ O
long -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

in -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
this -X- _ O
approach -X- _ O
has -X- _ O
been -X- _ O
superseded -X- _ O
by -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
either -X- _ O
the -X- _ O
last -X- _ O
( -X- _ O
donahue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2014 -X- _ O
) -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
results -X- _ O
using -X- _ O
features -X- _ O
of -X- _ O
an -X- _ O
imagenet -X- _ O
model -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
a -X- _ O
simple -X- _ O
classiÔ¨Åer -X- _ O
. -X- _ O

for -X- _ O
this -X- _ O
reason -X- _ O
, -X- _ O
most -X- _ O
work -X- _ O
in -X- _ O
cv -X- _ O
focuses -X- _ O
on -X- _ O
transferring -X- _ O
the -X- _ O
last -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
long -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2 -X- _ O
related -X- _ O
work -X- _ O
transfer -X- _ O
learning -X- _ O
in -X- _ O
cv -X- _ O
features -X- _ O
in -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
in -X- _ O
cv -X- _ O
have -X- _ O
been -X- _ O
observed -X- _ O
to -X- _ O
transition -X- _ O
from -X- _ O
task- -X- _ O
speciÔ¨Åc -X- _ O
togeneral -X- _ O
from -X- _ O
the -X- _ O
Ô¨Årst -X- _ O
to -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
( -X- _ O
yosinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

5 -X- _ O
) -X- _ O
we -X- _ O
make -X- _ O
the -X- _ O
pretrained -X- _ O
models -X- _ O
and -X- _ O
our -X- _ O
code -X- _ O
available -X- _ O
to -X- _ O
enable -X- _ O
wider -X- _ O
adoption -X- _ O
. -X- _ O

4 -X- _ O
) -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
enables -X- _ O
extremely -X- _ O
sample -X- _ O
- -X- _ O
efÔ¨Åcient -X- _ O
transfer -X- _ O
learning -X- _ O
and -X- _ O
perform -X- _ O
an -X- _ O
extensive -X- _ O
ablation -X- _ O
analysis -X- _ O
. -X- _ O

3 -X- _ O
) -X- _ O
we -X- _ O
signiÔ¨Åcantly -X- _ O
outperform -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
six -X- _ O
representative -X- _ O
text -X- _ O
classiÔ¨Åcation -X- _ O
datasets -X- _ O
, -X- _ O
with -X- _ O
an -X- _ B-MetricName
error -X- _ I-MetricName
reduction -X- _ O
of -X- _ O
18 -X- _ B-MetricValue
- -X- _ I-MetricValue
24 -X- _ I-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
datasets -X- _ O
. -X- _ O

contributions -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
we -X- _ O
propose -X- _ O
universal -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
ulmfit -X- _ B-MethodName
) -X- _ O
, -X- _ O
a -X- _ O
method -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
achieve -X- _ O
cv -X- _ O
- -X- _ O
like -X- _ O
transfer -X- _ O
learning -X- _ O
for -X- _ O
any -X- _ O
task -X- _ O
for -X- _ O
nlp -X- _ O
. -X- _ O

on -X- _ O
imdb -X- _ B-DatasetName
, -X- _ O
with -X- _ O
100labeled -X- _ O
examples -X- _ O
, -X- _ O
ulmfit -X- _ B-MethodName
matches -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
training -X- _ O
from -X- _ O
scratch -X- _ O
with -X- _ O
10and -X- _ O
‚Äî -X- _ O
given -X- _ O
50k -X- _ O
unlabeled -X- _ O
examples -X- _ O
‚Äî -X- _ O
with -X- _ O
100more -X- _ O
data -X- _ O
. -X- _ O

we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
method -X- _ O
, -X- _ O
universal -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
ulmfit -X- _ B-MethodName
) -X- _ O
that -X- _ O
addresses -X- _ O
these -X- _ O
issues -X- _ O
and -X- _ O
enables -X- _ O
robust -X- _ O
inductive -X- _ O
transfer -X- _ O
learning -X- _ O
for -X- _ O
any -X- _ O
nlp -X- _ O
task -X- _ O
, -X- _ O
akin -X- _ O
to -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
imagenet -X- _ O
models -X- _ O
: -X- _ O
the -X- _ O
same -X- _ O
3 -X- _ O
- -X- _ O
layer -X- _ O
lstm -X- _ B-MethodName
architecture -X- _ O
‚Äî -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
and -X- _ O
no -X- _ O
additions -X- _ O
other -X- _ O
than -X- _ O
tuned -X- _ O
dropout -X- _ O
hyperparameters -X- _ O
‚Äî -X- _ O
outperforms -X- _ O
highly -X- _ O
engineered -X- _ O
models -X- _ O
and -X- _ O
trans-329fer -X- _ O
learning -X- _ O
approaches -X- _ O
on -X- _ O
six -X- _ O
widely -X- _ O
studied -X- _ O
text -X- _ O
classiÔ¨Åcation -X- _ O
tasks -X- _ O
. -X- _ O

compared -X- _ O
to -X- _ O
cv -X- _ O
, -X- _ O
nlp -X- _ O
models -X- _ O
are -X- _ O
typically -X- _ O
more -X- _ O
shallow -X- _ O
and -X- _ O
thus -X- _ O
require -X- _ O
different -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
methods -X- _ O
. -X- _ O

lms -X- _ O
overÔ¨Åt -X- _ O
to -X- _ O
small -X- _ O
datasets -X- _ O
and -X- _ O
suffered -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
when -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
a -X- _ O
classiÔ¨Åer -X- _ O
. -X- _ O

we -X- _ O
show -X- _ O
that -X- _ O
not -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
lm -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
but -X- _ O
our -X- _ O
lack -X- _ O
of -X- _ O
knowledge -X- _ O
of -X- _ O
how -X- _ O
to -X- _ O
train -X- _ O
them -X- _ O
effectively -X- _ O
has -X- _ O
been -X- _ O
hindering -X- _ O
wider -X- _ O
adoption -X- _ O
. -X- _ O

dai -X- _ O
and -X- _ O
le -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
Ô¨Årst -X- _ O
proposed -X- _ O
Ô¨Ånetuning -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
lm -X- _ O
) -X- _ O
but -X- _ O
require -X- _ O
millions -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
documents -X- _ O
to -X- _ O
achieve -X- _ O
good -X- _ O
performance -X- _ O
, -X- _ O
which -X- _ O
severely -X- _ O
limits -X- _ O
its -X- _ O
applicability -X- _ O
. -X- _ O

however -X- _ O
, -X- _ O
inductive -X- _ O
transfer -X- _ O
via -X- _ O
Ô¨Ånetuning -X- _ O
has -X- _ O
been -X- _ O
unsuccessful -X- _ O
for -X- _ O
nlp -X- _ O
( -X- _ O
mou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2010 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
should -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
do -X- _ O
better -X- _ O
than -X- _ O
randomly -X- _ O
initializing -X- _ O
the -X- _ O
remaining -X- _ O
parameters -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O

in -X- _ O
light -X- _ O
of -X- _ O
the -X- _ O
beneÔ¨Åts -X- _ O
of -X- _ O
pretraining -X- _ O
( -X- _ O
erhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2018 -X- _ O
) -X- _ O
still -X- _ O
train -X- _ O
the -X- _ O
main -X- _ O
task -X- _ O
model -X- _ O
from -X- _ O
scratch -X- _ O
and -X- _ O
treat -X- _ O
pretrained -X- _ O
embeddings -X- _ O
as -X- _ O
Ô¨Åxed -X- _ O
parameters -X- _ O
, -X- _ O
limiting -X- _ O
their -X- _ O
usefulness -X- _ O
. -X- _ O

recent -X- _ O
approaches -X- _ O
that -X- _ O
concatenate -X- _ O
embeddings -X- _ O
derived -X- _ O
from -X- _ O
other -X- _ O
tasks -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
at -X- _ O
different -X- _ O
layers -X- _ O
( -X- _ O
peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2013 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
transfer -X- _ O
technique -X- _ O
that -X- _ O
only -X- _ O
targets -X- _ O
a -X- _ O
model -X- _ O
‚Äôs -X- _ O
Ô¨Årst -X- _ O
layer -X- _ O
, -X- _ O
has -X- _ O
had -X- _ O
a -X- _ O
large -X- _ O
impact -X- _ O
in -X- _ O
practice -X- _ O
and -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
most -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O

for -X- _ O
inductive -X- _ O
transfer -X- _ O
, -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
pretrained -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

research -X- _ O
in -X- _ O
nlp -X- _ O
focused -X- _ O
mostly -X- _ O
on -X- _ O
transductive -X- _ O
transfer -X- _ O
( -X- _ O
blitzer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

while -X- _ O
deep -X- _ O
learning -X- _ O
models -X- _ O
have -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
many -X- _ O
nlp -X- _ O
tasks -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
requiring -X- _ O
large -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
days -X- _ O
to -X- _ O
converge -X- _ O
. -X- _ O

jeremy -X- _ O
focused -X- _ O
on -X- _ O
the -X- _ O
algorithm -X- _ O
development -X- _ O
and -X- _ O
implementation -X- _ O
, -X- _ O
sebastian -X- _ O
focused -X- _ O
on -X- _ O
the -X- _ O
experiments -X- _ O
and -X- _ O
writing -X- _ O
. -X- _ O

2011 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
commercial -X- _ O
document -X- _ O
classiÔ¨Åcation -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
for -X- _ O
legal -X- _ O
discovery -X- _ O
( -X- _ O
roitblat -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2012 -X- _ O
) -X- _ O
, -X- _ O
emergency -X- _ O
response -X- _ O
( -X- _ O
caragea -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

text -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
is -X- _ O
a -X- _ O
category -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
nlp -X- _ O
) -X- _ O
tasks -X- _ O
with -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
applications -X- _ O
such -X- _ O
as -X- _ O
spam -X- _ O
, -X- _ O
fraud -X- _ O
, -X- _ O
and -X- _ O
bot -X- _ O
detection -X- _ O
( -X- _ O
jindal -X- _ O
and -X- _ O
liu -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
ngai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

applied -X- _ O
cv -X- _ O
models -X- _ O
( -X- _ O
including -X- _ O
object -X- _ O
detection -X- _ O
, -X- _ O
classiÔ¨Åcation -X- _ O
, -X- _ O
and -X- _ O
segmentation -X- _ O
) -X- _ O
are -X- _ O
rarely -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
but -X- _ O
instead -X- _ O
are -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuned -X- _ O
from -X- _ O
models -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
pretrained -X- _ O
on -X- _ O
imagenet -X- _ O
, -X- _ O
ms -X- _ O
- -X- _ O
coco -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
datasets -X- _ O
( -X- _ O
sharif -X- _ O
razavian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

1 -X- _ O
introduction -X- _ O
inductive -X- _ O
transfer -X- _ O
learning -X- _ O
has -X- _ O
had -X- _ O
a -X- _ O
large -X- _ O
impact -X- _ O
on -X- _ O
computer -X- _ O
vision -X- _ O
( -X- _ O
cv -X- _ O
) -X- _ O
. -X- _ O

furthermore -X- _ O
, -X- _ O
with -X- _ O
only -X- _ O
100labeled -X- _ O
examples -X- _ O
, -X- _ O
it -X- _ O
matches -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
training -X- _ O
from -X- _ O
scratch -X- _ O
on -X- _ O
100more -X- _ O
data -X- _ O
. -X- _ O

our -X- _ O
method -X- _ O
signiÔ¨Åcantly -X- _ O
outperforms -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
six -X- _ O
text -X- _ O
classiÔ¨Åcation -X- _ O
tasks -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
error -X- _ B-MetricName
by -X- _ O
1824 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
datasets -X- _ O
. -X- _ O

we -X- _ O
propose -X- _ O
universal -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
ulmfit -X- _ B-MethodName
) -X- _ O
, -X- _ O
an -X- _ O
effective -X- _ O
transfer -X- _ O
learning -X- _ O
method -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
task -X- _ O
in -X- _ O
nlp -X- _ O
, -X- _ O
and -X- _ O
introduce -X- _ O
techniques -X- _ O
that -X- _ O
are -X- _ O
key -X- _ O
for -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tuning -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

in -X- _ O
contrast -X- _ O
, -X- _ O
a -X- _ O
clear -X- _ O
dichotomy -X- _ O
between -X- _ O
the -X- _ O
recommender -X- _ O
system -X- _ O
perceived -X- _ O
as -X- _ O
useful -X- _ O
or -X- _ O
useless -X- _ O
existed -X- _ O
; -X- _ O
the -X- _ O
system -X- _ O
had -X- _ O
features -X- _ O
to -X- _ O
prompt -X- _ O
new -X- _ O
common -X- _ O
words -X- _ O
or -X- _ O
old -X- _ O
poorly -X- _ O
- -X- _ O
scored -X- _ O
words -X- _ O
. -X- _ O

the -X- _ O
feedback -X- _ O
system -X- _ O
with -X- _ O
features -X- _ O
for -X- _ O
pronunciation -X- _ O
scoring -X- _ O
, -X- _ O
speech -X- _ O
replay -X- _ O
, -X- _ O
and -X- _ O
giving -X- _ O
a -X- _ O
pronunciation -X- _ O
example -X- _ O
was -X- _ O
deemed -X- _ O
essential -X- _ O
by -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
respondents -X- _ O
. -X- _ O

13 -X- _ O
of -X- _ O
them -X- _ O
said -X- _ O
they -X- _ O
need -X- _ O
to -X- _ O
improve -X- _ O
their -X- _ O
pronunciation -X- _ O
skills -X- _ O
in -X- _ O
english -X- _ O
because -X- _ O
of -X- _ O
their -X- _ O
foreign -X- _ O
accent -X- _ O
. -X- _ O

16 -X- _ O
international -X- _ O
students -X- _ O
who -X- _ O
spoke -X- _ O
non -X- _ O
- -X- _ O
native -X- _ O
english -X- _ O
and -X- _ O
lived -X- _ O
in -X- _ O
australia -X- _ O
participated -X- _ O
. -X- _ O

an -X- _ O
artiÔ¨Åcial -X- _ O
intelligence -X- _ O
system -X- _ O
can -X- _ O
take -X- _ O
a -X- _ O
role -X- _ O
in -X- _ O
these -X- _ O
guided -X- _ O
learning -X- _ O
approaches -X- _ O
as -X- _ O
an -X- _ O
enabler -X- _ O
of -X- _ O
an -X- _ O
application -X- _ O
for -X- _ O
pronunciation -X- _ O
learning -X- _ O
with -X- _ O
a -X- _ O
recommender -X- _ O
system -X- _ O
to -X- _ O
guide -X- _ O
language -X- _ O
learners -X- _ O
through -X- _ O
exercises -X- _ O
and -X- _ O
feedback -X- _ O
system -X- _ O
to -X- _ O
correct -X- _ O
their -X- _ O
pronunciation -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
proposes -X- _ O
a -X- _ O
contextualized -X- _ B-MethodName
character -X- _ I-MethodName
representation -X- _ I-MethodName
for -X- _ I-MethodName
cged -X- _ I-MethodName
and -X- _ O
related -X- _ O
solutions -X- _ O
for -X- _ O
the -X- _ O
error -X- _ O
sparse -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
improved -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
approach -X- _ O
. -X- _ O

8 -X- _ O
conclusion -X- _ O
as -X- _ O
more -X- _ O
and -X- _ O
more -X- _ O
people -X- _ O
learn -X- _ O
chinese -X- _ O
, -X- _ O
the -X- _ O
automatic -X- _ B-TaskName
diagnosis -X- _ I-TaskName
of -X- _ I-TaskName
chinese -X- _ I-TaskName
grammatical -X- _ I-TaskName
error -X- _ I-TaskName
becomes -X- _ O
more -X- _ O
and -X- _ O
more -X- _ O
important -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
added -X- _ O
more -X- _ O
linguistic -X- _ O
information -X- _ O
on -X- _ B-MethodName
lstm+crf -X- _ I-MethodName
model -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
pos -X- _ B-MethodName
, -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
, -X- _ O
pmi -X- _ O
score -X- _ O
and -X- _ O
dependency -X- _ O
features -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
used -X- _ O
the -X- _ O
lstm+crf -X- _ B-MethodName
model -X- _ O
to -X- _ O
detect -X- _ O
dependencies -X- _ O
between -X- _ O
outputs -X- _ O
to -X- _ O
better -X- _ O
detect -X- _ O
error -X- _ O
messages -X- _ O
. -X- _ O
( -X- _ O

2017 -X- _ O
) -X- _ O
combined -X- _ O
machine -X- _ O
learning -X- _ O
with -X- _ O
traditional -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
methods -X- _ O
, -X- _ O
using -X- _ O
bi -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
to -X- _ O
detect -X- _ O
the -X- _ O
location -X- _ O
of -X- _ O
errors -X- _ O
and -X- _ O
adding -X- _ O
additional -X- _ O
linguistic -X- _ O
information -X- _ O
, -X- _ O
pos -X- _ B-MethodName
, -X- _ O
ngram -X- _ O
. -X- _ O
( -X- _ O

huang -X- _ O
and -X- _ O
wang -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
used -X- _ O
bi -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
to -X- _ O
annotate -X- _ O
the -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
( -X- _ O

grammatical -X- _ B-TaskName
error -X- _ I-TaskName
detection -X- _ I-TaskName
is -X- _ O
usually -X- _ O
considered -X- _ O
as -X- _ O
the -X- _ O
sequence -X- _ O
labeling -X- _ O
task -X- _ O
( -X- _ O
zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

in -X- _ O
the -X- _ O
past -X- _ O
few -X- _ O
years -X- _ O
, -X- _ O
the -X- _ O
diagnosis -X- _ B-TaskName
of -X- _ I-TaskName
chinese -X- _ I-TaskName
grammatical -X- _ I-TaskName
errors -X- _ I-TaskName
has -X- _ O
also -X- _ O
been -X- _ O
developing -X- _ O
in -X- _ O
machine -X- _ O
learning -X- _ O
. -X- _ O

due -X- _ O
to -X- _ O
the -X- _ O
continuous -X- _ O
rise -X- _ O
of -X- _ O
machine -X- _ O
learning -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
the -X- _ O
Ô¨Åeld -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
is -X- _ O
increasingly -X- _ O
turning -X- _ O
to -X- _ O
machine -X- _ O
learning -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
used -X- _ O
the -X- _ O
kmp -X- _ O
algorithm -X- _ O
to -X- _ O
speed -X- _ O
up -X- _ O
the -X- _ O
search -X- _ O
for -X- _ O
correct -X- _ O
candidates -X- _ O
. -X- _ O

lin -X- _ O
and -X- _ O
chu -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
used -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
to -X- _ O
establish -X- _ O
a -X- _ O
scoring -X- _ O
system -X- _ O
to -X- _ O
better -X- _ O
give -X- _ O
correction -X- _ O
options -X- _ O
. -X- _ O
( -X- _ O

2013 -X- _ O
) -X- _ O
still -X- _ O
used -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
as -X- _ O
the -X- _ O
main -X- _ O
method -X- _ O
, -X- _ O
and -X- _ O
added -X- _ O
web -X- _ O
resources -X- _ O
to -X- _ O
improve -X- _ O
detection -X- _ O
results -X- _ O
. -X- _ O
( -X- _ O

7 -X- _ O
related -X- _ O
work -X- _ B-TaskName
chinese -X- _ I-TaskName
grammatical -X- _ I-TaskName
error -X- _ I-TaskName
diagnosis -X- _ I-TaskName
task -X- _ O
has -X- _ O
been -X- _ O
developed -X- _ O
for -X- _ O
a -X- _ O
long -X- _ O
time -X- _ O
. -X- _ O

since -X- _ O
our -X- _ O
model -X- _ O
only -X- _ O
proposes -X- _ O
one -X- _ O
candidate -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
correction -X- _ O
and -X- _ O
top3 -X- _ O
correction -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O

table -X- _ O
14 -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
cged2018 -X- _ B-DatasetName
in -X- _ O
correction -X- _ O
part -X- _ O
. -X- _ O

table -X- _ O
10 -X- _ O
, -X- _ O
11 -X- _ O
, -X- _ O
12 -X- _ O
, -X- _ O
13 -X- _ O
shows -X- _ O
the -X- _ O
experiment -X- _ O
results -X- _ O
we -X- _ O
submitted -X- _ O
in -X- _ O
cged2018 -X- _ B-DatasetName
in -X- _ O
detection -X- _ O
part -X- _ O
. -X- _ O

for -X- _ O
errors -X- _ O
, -X- _ O
pos -X- _ B-MethodName
may -X- _ O
provide -X- _ O
some -X- _ O
information -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
detect -X- _ O
better -X- _ O
. -X- _ O

it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
pos -X- _ B-MethodName
is -X- _ O
useful -X- _ O
in -X- _ O
chinese -X- _ B-TaskName
error -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O

since -X- _ O
we -X- _ O
are -X- _ O
dealing -X- _ O
with -X- _ O
characters -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
use -X- _ O
pos -X- _ B-MethodName
for -X- _ O
the -X- _ O
character -X- _ O
‚Äôs -X- _ O
corresponding -X- _ O
word -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
‚Äôs -X- _ O
pos -X- _ B-MethodName
. -X- _ O

we -X- _ O
also -X- _ O
tried -X- _ O
to -X- _ O
add -X- _ O
artiÔ¨Åcial -X- _ O
information -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
added -X- _ O
pos -X- _ B-MethodName
( -X- _ O
part -X- _ B-MethodName
of -X- _ I-MethodName
speech -X- _ I-MethodName
) -X- _ O
information -X- _ O
. -X- _ O

the -X- _ O
model -X- _ O
can -X- _ O
also -X- _ O
detect -X- _ O
error -X- _ O
information -X- _ O
very -X- _ O
well -X- _ O
without -X- _ O
artiÔ¨Åcial -X- _ O
features -X- _ O
. -X- _ O

the -X- _ O
results -X- _ O
from -X- _ O
f1 -X- _ B-MetricName
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
is -X- _ O
improved -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
. -X- _ O

perimental -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
with -X- _ O
new -X- _ O
save -X- _ O
function -X- _ O
and -X- _ O
reconstructive -X- _ O
loss -X- _ O
. -X- _ O

at -X- _ O
0.05 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
f1 -X- _ B-MetricName
values -X- _ O
of -X- _ O
all -X- _ O
levels -X- _ O
are -X- _ O
too -X- _ O
low -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
use -X- _ O
0.1 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
weight -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
following -X- _ O
experiments -X- _ O
. -X- _ O

when -X- _ O
the -X- _ O
weight -X- _ B-HyperparameterName
is -X- _ O
too -X- _ O
large -X- _ O
, -X- _ O
false -X- _ B-MetricName
positive -X- _ I-MetricName
rate -X- _ I-MetricName
is -X- _ O
too -X- _ O
large -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
error -X- _ O
is -X- _ O
not -X- _ O
detected -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
objectives -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O

when -X- _ O
is -X- _ O
0.2 -X- _ B-HyperparameterValue
or -X- _ O
0.1 -X- _ B-HyperparameterValue
is -X- _ O
more -X- _ O
suitable -X- _ O
for -X- _ O
our -X- _ O
task -X- _ O
. -X- _ O

it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
weight -X- _ B-HyperparameterName
decreases -X- _ O
, -X- _ O
the -X- _ O
false -X- _ B-MetricName
positive -X- _ I-MetricName
rate -X- _ I-MetricName
decreases -X- _ O
signiÔ¨Åcantly -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
captures -X- _ O
more -X- _ O
correct -X- _ O
information -X- _ O
. -X- _ O

so -X- _ O
after -X- _ O
that -X- _ O
we -X- _ O
modify -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
weight -X- _ B-HyperparameterName
in -X- _ O
eq -X- _ O
. -X- _ O

the -X- _ O
second -X- _ O
part -X- _ O
of -X- _ O
table -X- _ O
6 -X- _ O
, -X- _ O
7 -X- _ O
, -X- _ O
8 -X- _ O
, -X- _ O
9 -X- _ O
shows -X- _ O
the -X- _ O
different -X- _ O
models -X- _ O
with -X- _ O
new -X- _ O
function -X- _ O
to -X- _ O
save -X- _ O
model -X- _ O
and -X- _ O
reconstructive -X- _ O
loss -X- _ O
for -X- _ O
modifying -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
in -X- _ O
eq -X- _ O
. -X- _ O

there -X- _ O
is -X- _ O
an -X- _ O
improvement -X- _ O
in -X- _ O
error -X- _ O
detection -X- _ O
, -X- _ O
but -X- _ O
too -X- _ O
many -X- _ O
errors -X- _ O
are -X- _ O
detected -X- _ O
and -X- _ O
the -X- _ O
correct -X- _ O
information -X- _ O
is -X- _ O
ignored -X- _ O
. -X- _ O

the -X- _ O
results -X- _ O
of -X- _ O
mixing -X- _ O
the -X- _ O
above -X- _ O
methods -X- _ O
are -X- _ O
also -X- _ O
given -X- _ O
. -X- _ O

it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
from -X- _ O
the -X- _ O
experiment -X- _ O
that -X- _ O
modifying -X- _ O
the -X- _ O
save -X- _ O
function -X- _ O
and -X- _ O
rebuilding -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
all -X- _ O
have -X- _ O
a -X- _ O
good -X- _ O
improvement -X- _ O
on -X- _ O
the -X- _ O
error -X- _ O
detection -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

the -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
reconstructive -X- _ O
loss -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O

the -X- _ O
Ô¨Årst -X- _ O
part -X- _ O
of -X- _ O
table -X- _ O
6 -X- _ O
, -X- _ O
7 -X- _ O
, -X- _ O
8 -X- _ O
, -X- _ O
9 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
comparison -X- _ O
between -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
new -X- _ O
function -X- _ O
to -X- _ O
save -X- _ O
model -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
reconstruction -X- _ O
loss -X- _ O
function -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
model -X- _ O
. -X- _ O

since -X- _ O
the -X- _ O
experiment -X- _ O
results -X- _ O
are -X- _ O
similar -X- _ O
on -X- _ O
cged2017 -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
given -X- _ O
. -X- _ O

6 -X- _ O
result -X- _ O
in -X- _ O
this -X- _ O
part -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
our -X- _ O
experiment -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
cged2016 -X- _ B-DatasetName
test -X- _ O
set -X- _ O
. -X- _ O

the -X- _ O
following -X- _ O
metrics -X- _ O
are -X- _ O
measured -X- _ O
at -X- _ O
detection -X- _ O
, -X- _ O
identiÔ¨Åcation -X- _ O
, -X- _ O
position -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O

the -X- _ O
model -X- _ O
can -X- _ O
recommend -X- _ O
at -X- _ O
most -X- _ O
3 -X- _ O
correction -X- _ O
at -X- _ O
each -X- _ O
error -X- _ O
. -X- _ O

correction -X- _ O
level -X- _ O
: -X- _ O
characters -X- _ O
marked -X- _ O
as -X- _ O
s -X- _ O
and -X- _ O
m -X- _ O
need -X- _ O
to -X- _ O
give -X- _ O
correct -X- _ O
candidates -X- _ O
. -X- _ O

position -X- _ O
level -X- _ O
: -X- _ O
the -X- _ O
system -X- _ O
results -X- _ O
should -X- _ O
be -X- _ O
perfectly -X- _ O
identical -X- _ O
with -X- _ O
the -X- _ O
quadruples -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
standard -X- _ O
. -X- _ O

identiÔ¨Åcation -X- _ O
level -X- _ O
: -X- _ O
the -X- _ O
correct -X- _ O
situation -X- _ O
should -X- _ O
be -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
gold -X- _ O
standard -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
type -X- _ O
of -X- _ O
error -X- _ O
. -X- _ O

in -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
sentences -X- _ O
are -X- _ O
classiÔ¨Åed -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
. -X- _ O

if -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
error -X- _ O
, -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
incorrect -X- _ O
. -X- _ O

detection -X- _ O
level -X- _ O
: -X- _ O
determines -X- _ O
whether -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
correct -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O

2016 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
evaluation -X- _ O
method -X- _ O
includes -X- _ O
three -X- _ O
levels -X- _ O
, -X- _ O
detection -X- _ O
level -X- _ O
, -X- _ O
identiÔ¨Åcation -X- _ O
level -X- _ O
, -X- _ O
position -X- _ O
level -X- _ O
. -X- _ O

5.3 -X- _ O
evaluation -X- _ O
method -X- _ O
according -X- _ O
to -X- _ O
( -X- _ O
lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

vide -X- _ O
part -X- _ O
of -X- _ O
data -X- _ O
from -X- _ O
nlptea2016 -X- _ B-DatasetName
to -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O

we -X- _ O
use -X- _ O
adam -X- _ O
optimizer -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
0.001 -X- _ B-HyperparameterValue
. -X- _ O

the -X- _ O
character -X- _ O
embedding -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
400 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
bilstm -X- _ I-HyperparameterName
is -X- _ O
256 -X- _ B-HyperparameterValue
. -X- _ O

we -X- _ O
also -X- _ O
use -X- _ O
wiki -X- _ O
corpus -X- _ O
to -X- _ O
build -X- _ O
our -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
dictionaries -X- _ O
. -X- _ O

5.2 -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
and -X- _ O
data -X- _ O
we -X- _ O
use -X- _ O
word2vec3to -X- _ O
pretrain -X- _ O
our -X- _ O
character -X- _ O
embeddings -X- _ O
by -X- _ O
wiki -X- _ O
corpus4 -X- _ O
. -X- _ O

unlike -X- _ O
traditional -X- _ O
sequence -X- _ O
labeling -X- _ O
, -X- _ O
chinese -X- _ B-TaskName
grammatical -X- _ I-TaskName
error -X- _ I-TaskName
diagnosis -X- _ I-TaskName
may -X- _ O
result -X- _ O
in -X- _ O
inaccurate -X- _ O
word -X- _ O
segmentation -X- _ O
due -X- _ O
to -X- _ O
existing -X- _ O
errors -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
use -X- _ O
character -X- _ O
embeddings -X- _ O
to -X- _ O
replace -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

5 -X- _ O
evaluation -X- _ O
5.1 -X- _ O
baseline -X- _ O
in -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
the -X- _ O
bi -X- _ B-MethodName
- -X- _ I-MethodName
lstm -X- _ I-MethodName
model -X- _ O
for -X- _ O
sequence -X- _ O
labelling -X- _ O
as -X- _ O
our -X- _ O
baseline -X- _ O
model -X- _ O
. -X- _ O

we -X- _ O
regard -X- _ O
that -X- _ O
the -X- _ O
candidate -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
is -X- _ O
the -X- _ O
correct -X- _ O
candidate -X- _ O
. -X- _ O

we -X- _ O
Ô¨Årst -X- _ O
search -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
word -X- _ O
dictionary -X- _ O
which -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
character -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
labeled -X- _ O
m. -X- _ O
then -X- _ O
, -X- _ O
calculate -X- _ O
the -X- _ O
candidates -X- _ O
‚Äô -X- _ O
score -X- _ O
. -X- _ O

for -X- _ O
the -X- _ O
error -X- _ O
typed -X- _ O
with -X- _ O
m -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
slto -X- _ O
calculate -X- _ O
the -X- _ O
score -X- _ O
using -X- _ O
2 -X- _ O
- -X- _ O
gram -X- _ O
and -X- _ O
3 -X- _ O
- -X- _ O
gram -X- _ O
. -X- _ O

the -X- _ O
character -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
correct -X- _ O
. -X- _ O

the -X- _ O
candidate -X- _ O
dictionary -X- _ O
is -X- _ O
directly -X- _ O
used -X- _ O
to -X- _ O
replace -X- _ O
the -X- _ O
character -X- _ O
and -X- _ O
the -X- _ O
score -X- _ O
is -X- _ O
calculated -X- _ O
. -X- _ O

for -X- _ O
the -X- _ O
error -X- _ O
which -X- _ O
is -X- _ O
typed -X- _ O
with -X- _ O
s -X- _ O
is -X- _ O
a -X- _ O
character -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
slscore -X- _ O
for -X- _ O
the -X- _ O
character -X- _ O
. -X- _ O

we -X- _ O
select -X- _ O
the -X- _ O
candidate -X- _ O
word -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
as -X- _ O
the -X- _ O
correct -X- _ O
one -X- _ O
. -X- _ O

we -X- _ O
replace -X- _ O
each -X- _ O
characters -X- _ O
in -X- _ O
the -X- _ O
words -X- _ O
and -X- _ O
calculate -X- _ O
the -X- _ O
score -X- _ O
separately -X- _ O
. -X- _ O

when -X- _ O
we -X- _ O
choose -X- _ O
the -X- _ O
word -X- _ O
to -X- _ O
replace -X- _ O
, -X- _ O
we -X- _ O
prefer -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
word -X- _ O
that -X- _ O
have -X- _ O
only -X- _ O
one -X- _ O
character -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
word -X- _ O
. -X- _ O

we -X- _ O
merged -X- _ O
the -X- _ O
two -X- _ O
dictionaries -X- _ O
to -X- _ O
one -X- _ O
dictionary -X- _ O
of -X- _ O
candidates -X- _ O
for -X- _ O
characters -X- _ O
. -X- _ O

we -X- _ O
use -X- _ O
the -X- _ O
dictionaries -X- _ O
of -X- _ O
characters -X- _ O
with -X- _ O
similar -X- _ O
pronunciation -X- _ O
and -X- _ O
similar -X- _ O
shape -X- _ O
in -X- _ O
( -X- _ O
wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
use -X- _ O
this -X- _ O
score -X- _ O
for -X- _ O
errors -X- _ O
typed -X- _ O
s. -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
calculation -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
keep -X- _ O
the -X- _ O
calculation -X- _ O
of -X- _ O
2 -X- _ O
- -X- _ O
gram -X- _ O
and -X- _ O
3 -X- _ O
- -X- _ O
gram -X- _ O
, -X- _ O
the -X- _ O
example -X- _ O
of -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
of -X- _ O
words -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
table -X- _ O
4.175for -X- _ O
the -X- _ O
error -X- _ O
which -X- _ O
is -X- _ O
typed -X- _ O
with -X- _ O
s -X- _ O
is -X- _ O
a -X- _ O
word -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
calculate -X- _ O
the -X- _ O
slscore -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
. -X- _ O

2016 -X- _ O
) -X- _ O
adds -X- _ O
weights -X- _ O
to -X- _ O
the -X- _ O
different -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
by -X- _ O
their -X- _ O
length -X- _ O
to -X- _ O
favor -X- _ O
higher -X- _ O
gram -X- _ O
. -X- _ O

to -X- _ O
increase -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
correction -X- _ O
, -X- _ O
( -X- _ O
chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

the -X- _ O
candidate -X- _ O
word -X- _ O
with -X- _ O
highest -X- _ O
scoring -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
correction -X- _ O
. -X- _ O

if -X- _ O
the -X- _ O
candidate -X- _ O
word -X- _ O
has -X- _ O
a -X- _ O
higher -X- _ O
score -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
word -X- _ O
, -X- _ O
the -X- _ O
original -X- _ O
word -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
wrong -X- _ O
. -X- _ O

if -X- _ O
the -X- _ O
original -X- _ O
word -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
, -X- _ O
the -X- _ O
original -X- _ O
word -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
correct -X- _ O
. -X- _ O

2016 -X- _ O
) -X- _ O
uses -X- _ O
the -X- _ O
method -X- _ O
of -X- _ O
calculating -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
score -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
judge -X- _ O
whether -X- _ O
the -X- _ O
word -X- _ O
is -X- _ O
correct -X- _ O
or -X- _ O
not -X- _ O
and -X- _ O
put -X- _ O
forward -X- _ O
correct -X- _ O
candidates -X- _ O
. -X- _ O

2016 -X- _ O
) -X- _ O
and -X- _ O
only -X- _ O
put -X- _ O
forward -X- _ O
one -X- _ O
candidate -X- _ O
correction -X- _ O
. -X- _ O
( -X- _ O

since -X- _ O
we -X- _ O
mainly -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
detection -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
simpliÔ¨Åed -X- _ O
the -X- _ O
method -X- _ O
in -X- _ O
( -X- _ O
chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

4 -X- _ O
correction -X- _ O
system -X- _ O
correct -X- _ O
system -X- _ O
we -X- _ O
use -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
the -X- _ O
method -X- _ O
proposed -X- _ O
in -X- _ O
( -X- _ O
chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

to -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
loss -X- _ O
function -X- _ O
eq -X- _ O
. -X- _ O

therefore -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
may -X- _ O
have -X- _ O
some -X- _ O
problem -X- _ O
. -X- _ O

loss -X- _ O
1= 1 -X- _ O
nx -X- _ O
x[ylna+ -X- _ O
( -X- _ O
1 y -X- _ O
) -X- _ O
ln(1 a)](7 -X- _ O
) -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
problem -X- _ O
that -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
correct -X- _ O
characters -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
is -X- _ O
much -X- _ O
larger -X- _ O
than -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
incorrect -X- _ O
characters -X- _ O
still -X- _ O
exists -X- _ O
. -X- _ O

in -X- _ O
the -X- _ O
traditional -X- _ O
lstm -X- _ B-MethodName
model -X- _ O
of -X- _ O
sequence -X- _ O
labelling -X- _ O
, -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
function -X- _ O
, -X- _ O
eq -X- _ O
. -X- _ O

from -X- _ O
the -X- _ O
table -X- _ O
6 -X- _ O
, -X- _ O
7 -X- _ O
, -X- _ O
8 -X- _ O
, -X- _ O
9 -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
although -X- _ O
the -X- _ O
results -X- _ O
have -X- _ O
improved -X- _ O
but -X- _ O
the -X- _ O
increase -X- _ O
is -X- _ O
limited -X- _ O
. -X- _ O

3.3 -X- _ O
loss -X- _ O
function -X- _ O
although -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
detect -X- _ O
more -X- _ O
error -X- _ O
information -X- _ O
but -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
enough -X- _ O
, -X- _ O
when -X- _ O
we -X- _ O
use -X- _ O
eq -X- _ O
. -X- _ O

the -X- _ O
model -X- _ O
can -X- _ O
capture -X- _ O
more -X- _ O
error -X- _ O
information -X- _ O
when -X- _ O
there -X- _ O
are -X- _ O
fewer -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O

4 -X- _ O
is -X- _ O
that -X- _ O
when -X- _ O
we -X- _ O
save -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
detect -X- _ O
more -X- _ O
wrong -X- _ O
information -X- _ O
and -X- _ O
ignore -X- _ O
some -X- _ O
correct -X- _ O
information -X- _ O
. -X- _ O

therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
save -X- _ O
the -X- _ O
model -X- _ O
no -X- _ O
longer -X- _ O
when -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
achieves -X- _ O
the -X- _ O
max -X- _ O
accuracy -X- _ B-MetricName
, -X- _ O
but -X- _ O
when -X- _ O
eq -X- _ O
. -X- _ O

the -X- _ O
model -X- _ O
discriminates -X- _ O
most -X- _ O
of -X- _ O
test -X- _ O
sentences -X- _ O
to -X- _ O
be -X- _ O
correct -X- _ O
. -X- _ O

analyzing -X- _ O
the -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
the -X- _ O
correct -X- _ O
part -X- _ O
more -X- _ O
, -X- _ O
and -X- _ O
learns -X- _ O
the -X- _ O
error -X- _ O
information -X- _ O
less -X- _ O
. -X- _ O

however -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
has -X- _ O
reached -X- _ O
the -X- _ O
greatest -X- _ O
accuracy -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
not -X- _ O
good -X- _ O
. -X- _ O

3.2 -X- _ O
function -X- _ O
of -X- _ O
save -X- _ O
model -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
traditional -X- _ O
training -X- _ O
method -X- _ O
, -X- _ O
accuracy -X- _ O
, -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

after -X- _ O
dividing -X- _ O
the -X- _ O
errors -X- _ O
into -X- _ O
four -X- _ O
categories -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
errors -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
conducive -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

in -X- _ O
table -X- _ O
2 -X- _ O
and -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
give -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
errors -X- _ O
in -X- _ O
cged2018 -X- _ B-DatasetName
. -X- _ O

the -X- _ O
task -X- _ O
of -X- _ O
cged20181is -X- _ B-DatasetName
to -X- _ O
automatically -X- _ O
diagnose -X- _ O
grammatical -X- _ O
errors -X- _ O
in -X- _ O
chinese -X- _ O
sentences -X- _ O
written -X- _ O
by -X- _ O
second -X- _ O
language -X- _ O
learners -X- _ O
. -X- _ O

although -X- _ O
one -X- _ O
sentence -X- _ O
may -X- _ O
contain -X- _ O
multiple -X- _ O
errors -X- _ O
but -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
errors -X- _ O
is -X- _ O
insufÔ¨Åcient -X- _ O
. -X- _ O

we -X- _ O
use -X- _ O
the -X- _ O
mask -X- _ B-MethodName
to -X- _ O
get -X- _ O
the -X- _ O
contextualized -X- _ O
character -X- _ O
representation -X- _ O
which -X- _ O
can -X- _ O
better -X- _ O
represent -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
characters -X- _ O
and -X- _ O
better -X- _ O
obtain -X- _ O
the -X- _ O
information -X- _ O
we -X- _ O
need -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O

mask -X- _ B-MethodName
= -X- _ O
(wmt+bm -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
xt -X- _ O
xt -X- _ O
mask -X- _ B-MethodName
( -X- _ O
3 -X- _ O
) -X- _ O
whereis -X- _ O
the -X- _ O
sigmoid -X- _ O
activation -X- _ O
function -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
output -X- _ O
between -X- _ O
0 -X- _ O
to -X- _ O
1 -X- _ O
. -X- _ O

then -X- _ O
we -X- _ O
use -X- _ O
tto -X- _ O
calculate -X- _ O
the -X- _ O
contextualized -X- _ O
character -X- _ O
vectors -X- _ O
as -X- _ O
input -X- _ O
of -X- _ O
traditional -X- _ O
sequence -X- _ O
labeling -X- _ O
model -X- _ O
of -X- _ O
lstm -X- _ B-MethodName
instead -X- _ O
of -X- _ O
the -X- _ O
traditional -X- _ O
character -X- _ O
vectors -X- _ O
. -X- _ O

nn -X- _ O
: -X- _ O
rce!rteis -X- _ O
a -X- _ O
feedforward -X- _ O
neural -X- _ O
network -X- _ O
parametrized -X- _ O
by -X- _ O
.ceis -X- _ B-HyperparameterName
the -X- _ O
character -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ B-HyperparameterName
teis -X- _ I-HyperparameterName
the -X- _ O
text -X- _ B-HyperparameterName
representation -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
. -X- _ O

t=1 -X- _ O
mmx -X- _ O
t=1nn(xt -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
xtin -X- _ O
our -X- _ O
work -X- _ O
represents -X- _ O
the -X- _ O
character -X- _ O
representation -X- _ O
in -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
. -X- _ O

we -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
this -X- _ O
method -X- _ O
proposed -X- _ O
in -X- _ O
( -X- _ O
choi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

that -X- _ O
is -X- _ O
to -X- _ O
say -X- _ O
, -X- _ O
under -X- _ O
the -X- _ O
different -X- _ O
context -X- _ O
conditions -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
mask -X- _ O
out -X- _ O
some -X- _ O
dimensions -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
vectors -X- _ O
. -X- _ O

but -X- _ O
in -X- _ O
different -X- _ O
texts -X- _ O
, -X- _ O
the -X- _ O
semantic -X- _ O
information -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
use -X- _ O
is -X- _ O
different -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
ignore -X- _ O
the -X- _ O
unneeded -X- _ O
semantic -X- _ O
information -X- _ O
. -X- _ O

2016 -X- _ O
) -X- _ O
puts -X- _ O
forward -X- _ O
that -X- _ O
each -X- _ O
dimension -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
vector -X- _ O
may -X- _ O
represent -X- _ O
some -X- _ O
semantic -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
. -X- _ O

2.2 -X- _ O
building -X- _ O
contextualized -X- _ O
character -X- _ O
representation -X- _ O
( -X- _ O
choi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

to -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
contextualized -X- _ B-MethodName
character -X- _ I-MethodName
representation -X- _ I-MethodName
for -X- _ I-MethodName
cged -X- _ I-MethodName
to -X- _ O
solve -X- _ O
the -X- _ O
ambiguity -X- _ O
problem -X- _ O
. -X- _ O

therefore -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
character -X- _ O
vector -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
same -X- _ O
character -X- _ O
in -X- _ O
different -X- _ O
contexts -X- _ O
is -X- _ O
inaccurate -X- _ O
, -X- _ O
and -X- _ O
sometimes -X- _ O
there -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
big -X- _ O
semantic -X- _ O
deviation -X- _ O
. -X- _ O

for -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
character -X- _ O
‚Äù -X- _ O
s -X- _ O
‚Äù -X- _ O
in -X- _ O
word -X- _ O
‚Äù -X- _ O
 s -X- _ O
‚Äù -X- _ O
( -X- _ O
a -X- _ O
dozen -X- _ O
) -X- _ O
means -X- _ O
dozen -X- _ O
, -X- _ O
in -X- _ O
word -X- _ O
‚Äù -X- _ O
s -X- _ O
‚Äù -X- _ O
( -X- _ O
play -X- _ O
the173drum -X- _ O
) -X- _ O
means -X- _ O
play -X- _ O
. -X- _ O

the -X- _ O
experiment -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
have -X- _ O
better -X- _ O
result -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
without -X- _ O
artiÔ¨Åcial -X- _ O
features -X- _ O
. -X- _ O

this -X- _ O
model -X- _ O
have -X- _ O
better -X- _ O
considered -X- _ O
the -X- _ O
different -X- _ O
semantics -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
chinese -X- _ O
texts -X- _ O
. -X- _ O

for -X- _ O
error -X- _ O
typed -X- _ O
s -X- _ O
and -X- _ O
m -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
give -X- _ O
at -X- _ O
most -X- _ O
three -X- _ O
correct -X- _ O
candidates -X- _ O
. -X- _ O

the -X- _ O
cged -X- _ B-TaskName
system -X- _ O
needs -X- _ O
to -X- _ O
detect -X- _ O
the -X- _ O
location -X- _ O
of -X- _ O
errors -X- _ O
and -X- _ O
gives -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
each -X- _ O
error -X- _ O
. -X- _ O

the -X- _ O
errors -X- _ O
include -X- _ O
four -X- _ O
types -X- _ O
, -X- _ O
redundant -X- _ O
words -X- _ O
( -X- _ O
denoted -X- _ O
as -X- _ O
a -X- _ O
capital -X- _ O
‚Äù -X- _ O
r -X- _ O
‚Äù -X- _ O
) -X- _ O
, -X- _ O
missing -X- _ O
words -X- _ O
( -X- _ O
‚Äù -X- _ O
m -X- _ O
‚Äù -X- _ O
) -X- _ O
, -X- _ O
word -X- _ O
selection -X- _ O
errors -X- _ O
( -X- _ O
‚Äù -X- _ O
s -X- _ O
‚Äù -X- _ O
) -X- _ O
and -X- _ O
word -X- _ O
ordering -X- _ O
errors -X- _ O
( -X- _ O
‚Äù -X- _ O
w -X- _ O
‚Äù -X- _ O
) -X- _ O
. -X- _ O

traditional -X- _ O
chinese -X- _ O
learning -X- _ O
methods -X- _ O
cost -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
labor -X- _ O
and -X- _ O
time -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
very -X- _ O
important -X- _ O
to -X- _ O
establish -X- _ O
an -X- _ O
automatic -X- _ B-TaskName
diagnosis -X- _ I-TaskName
system -X- _ I-TaskName
for -X- _ I-TaskName
chinese -X- _ I-TaskName
grammatical -X- _ I-TaskName
error -X- _ I-TaskName
. -X- _ O

however -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
some -X- _ O
differences -X- _ O
between -X- _ O
chinese -X- _ O
and -X- _ O
english -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
no -X- _ O
changes -X- _ O
in -X- _ O
tense -X- _ O
in -X- _ O
chinese -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
difÔ¨Åcult -X- _ O
for -X- _ O
many -X- _ O
chinese -X- _ O
learners -X- _ O
to -X- _ O
Ô¨Ånd -X- _ O
their -X- _ O
own -X- _ O
mistakes -X- _ O
in -X- _ O
writing -X- _ O
. -X- _ O

1 -X- _ O
introduction -X- _ O
with -X- _ O
the -X- _ O
rapid -X- _ O
development -X- _ O
of -X- _ O
china -X- _ O
, -X- _ O
more -X- _ O
and -X- _ O
more -X- _ O
non -X- _ O
- -X- _ O
native -X- _ O
chinese -X- _ O
speakers -X- _ O
begin -X- _ O
to -X- _ O
learn -X- _ O
chinese -X- _ O
. -X- _ O

compared -X- _ O
to -X- _ O
the -X- _ O
traditional -X- _ O
model -X- _ O
using -X- _ O
lstm -X- _ B-MethodName
( -X- _ O
long -X- _ B-MethodName
- -X- _ I-MethodName
short -X- _ I-MethodName
term -X- _ I-MethodName
memory -X- _ I-MethodName
) -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
have -X- _ O
better -X- _ O
performance -X- _ O
and -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
need -X- _ O
to -X- _ O
add -X- _ O
too -X- _ O
many -X- _ O
artiÔ¨Åcial -X- _ O
features -X- _ O
. -X- _ O

in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
chinese -X- _ B-TaskName
grammatical -X- _ I-TaskName
error -X- _ I-TaskName
diagnosis -X- _ I-TaskName
( -X- _ O
cged -X- _ B-TaskName
) -X- _ O
model -X- _ B-MethodName
with -X- _ I-MethodName
contextualized -X- _ I-MethodName
character -X- _ I-MethodName
representation -X- _ I-MethodName
. -X- _ O

establishing -X- _ O
an -X- _ O
automatic -X- _ B-TaskName
diagnosis -X- _ I-TaskName
system -X- _ I-TaskName
for -X- _ I-TaskName
chinese -X- _ I-TaskName
grammatical -X- _ I-TaskName
error -X- _ I-TaskName
has -X- _ O
become -X- _ O
an -X- _ O
important -X- _ O
challenge -X- _ O
. -X- _ O

recent -X- _ O
machine -X- _ O
learning -X- _ O
techniques -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
convolutional -X- _ O
neural -X- _ O
networks -X- _ O
( -X- _ O
cnn -X- _ O
) -X- _ O
( -X- _ O
collobertet -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

readability -X- _ B-TaskName
assessment -X- _ I-TaskName
has -X- _ O
a -X- _ O
long -X- _ O
research -X- _ O
history -X- _ O
, -X- _ O
and -X- _ O
many -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
couple -X- _ O
of -X- _ O
decades -X- _ O
( -X- _ O
dale -X- _ O
and -X- _ O
chall -X- _ O
, -X- _ O
1948 -X- _ O
; -X- _ O
mc -X- _ O
laughlin -X- _ O
, -X- _ O
1969 -X- _ O
; -X- _ O
kincaid -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

the -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
using -X- _ O
frequency -X- _ B-MethodName
class -X- _ I-MethodName
metric -X- _ O
can -X- _ O
represent -X- _ O
frequency -X- _ O
information -X- _ O
better -X- _ O
than -X- _ O
using -X- _ O
other -X- _ O
common -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
raw -X- _ O
counts -X- _ O
or -X- _ O
ranking -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
model -X- _ O
that -X- _ O
integrates -X- _ O
the -X- _ O
frequency -X- _ B-MethodName
embeddings -X- _ I-MethodName
directly -X- _ O
to -X- _ O
the -X- _ O
fullyconnected -X- _ O
layer -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
applying -X- _ O
Ô¨Ålters -X- _ O
on -X- _ O
the -X- _ O
concatenated -X- _ O
word -X- _ B-MethodName
frequency -X- _ I-MethodName
embeddings -X- _ I-MethodName
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
both -X- _ O
proposed -X- _ O
models -X- _ O
outperform -X- _ O
the -X- _ O
baseline -X- _ O
( -X- _ O
the -X- _ O
traditional -X- _ O
ndc -X- _ B-MethodName
method -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
cnn -X- _ B-MethodName
models -X- _ O
without -X- _ O
using -X- _ O
frequency -X- _ O
information -X- _ O
in -X- _ O
both -X- _ O
english -X- _ O
and -X- _ O
chinese -X- _ O
datasets.107references -X- _ O
jeanne -X- _ O
s -X- _ O
chall -X- _ O
and -X- _ O
edgar -X- _ O
dale -X- _ O
. -X- _ O

5 -X- _ O
conclusion -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
proposed -X- _ O
two -X- _ O
models -X- _ O
that -X- _ O
employ -X- _ O
both -X- _ O
word -X- _ B-MethodName
and -X- _ I-MethodName
frequency -X- _ I-MethodName
embeddings -X- _ I-MethodName
for -X- _ O
the -X- _ O
readability -X- _ B-TaskName
assessment -X- _ I-TaskName
task -X- _ I-TaskName
. -X- _ O

this -X- _ O
method -X- _ O
is -X- _ O
extensible -X- _ O
and -X- _ O
can -X- _ O
easily -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
different -X- _ O
languages -X- _ O
without -X- _ O
prior -X- _ O
knowledge -X- _ O
about -X- _ O
these -X- _ O
languages -X- _ O
. -X- _ O

it -X- _ O
proves -X- _ O
our -X- _ O
hypothesis -X- _ O
that -X- _ O
frequency -X- _ O
information -X- _ O
is -X- _ O
useful -X- _ O
in -X- _ O
judging -X- _ B-TaskName
the -X- _ I-TaskName
difÔ¨Åculty -X- _ I-TaskName
level -X- _ I-TaskName
of -X- _ O
a -X- _ O
document -X- _ O
. -X- _ O

finally -X- _ O
, -X- _ O
it -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
frequency -X- _ B-MethodName
embeddings -X- _ I-MethodName
help -X- _ O
improving -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
both -X- _ O
english -X- _ O
( -X- _ O
to -X- _ O
93 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
and -X- _ O
chinese -X- _ O
( -X- _ O
to -X- _ O
49 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
when -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
frequency -X- _ B-MethodName
embeddings -X- _ I-MethodName
and -X- _ O
word -X- _ B-MethodName
embeddings -X- _ I-MethodName
, -X- _ O
using -X- _ O
the -X- _ O
frequency -X- _ B-MethodName
class -X- _ I-MethodName
information -X- _ O
. -X- _ O

it -X- _ O
means -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
necessary -X- _ O
to -X- _ O
apply -X- _ O
Ô¨Ålters -X- _ O
and -X- _ O
max -X- _ O
poolings -X- _ O
on -X- _ O
the -X- _ O
frequency -X- _ B-MethodName
embeddings -X- _ I-MethodName
and -X- _ O
the -X- _ B-MethodName
frequency -X- _ I-MethodName
and -X- _ I-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
can -X- _ O
be -X- _ O
learned -X- _ O
separated -X- _ O
and -X- _ O
Ô¨Ånally -X- _ O
concatenate -X- _ O
before -X- _ O
going -X- _ O
to -X- _ O
the -X- _ O
fully -X- _ O
connected -X- _ O
layer -X- _ O
. -X- _ O

the -X- _ O
result -X- _ O
suggests -X- _ O
that -X- _ O
model -X- _ O
wfe -X- _ B-MethodName
- -X- _ I-MethodName
sep -X- _ I-MethodName
works -X- _ O
better -X- _ O
than -X- _ O
wfe -X- _ B-MethodName
- -X- _ I-MethodName
com -X- _ I-MethodName
. -X- _ O

since -X- _ O
frequency -X- _ B-MethodName
class -X- _ I-MethodName
information -X- _ O
is -X- _ O
more -X- _ O
representative -X- _ O
than -X- _ O
word -X- _ O
counts -X- _ O
and -X- _ O
word -X- _ O
ranks -X- _ O
, -X- _ O
it -X- _ O
perhaps -X- _ O
helps -X- _ O
the -X- _ O
model -X- _ O
learn -X- _ O
to -X- _ O
classify -X- _ B-TaskName
the -X- _ I-TaskName
difÔ¨Åculty -X- _ I-TaskName
levels -X- _ I-TaskName
better -X- _ O
in -X- _ O
more -X- _ O
general -X- _ O
cases -X- _ O
. -X- _ O

this -X- _ O
model -X- _ O
is -X- _ O
however -X- _ O
worse -X- _ O
than -X- _ O
when -X- _ O
using -X- _ O
only -X- _ O
frequency -X- _ B-MethodName
class -X- _ I-MethodName
information -X- _ O
. -X- _ O

when -X- _ O
using -X- _ O
all -X- _ O
frequency -X- _ O
levels -X- _ O
, -X- _ O
word -X- _ O
ranks -X- _ O
and -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
together -X- _ O
for -X- _ O
frequency -X- _ B-MethodName
embedding -X- _ I-MethodName
, -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O

however -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
work -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
when -X- _ O
keeping -X- _ O
the -X- _ O
embedding -X- _ O
vectors -X- _ O
static -X- _ B-MethodName
for -X- _ O
both -X- _ O
english -X- _ O
and -X- _ O
chinese -X- _ O
. -X- _ O

non -X- _ B-MethodName
- -X- _ I-MethodName
static -X- _ I-MethodName
model -X- _ O
is -X- _ O
supposed -X- _ O
to -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
tune -X- _ O
to -X- _ O
the -X- _ O
speciÔ¨Åc -X- _ O
given -X- _ O
task -X- _ O
. -X- _ O

among -X- _ O
three -X- _ O
we -X- _ B-MethodName
methods -X- _ O
( -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ B-MethodName
embeddings -X- _ I-MethodName
) -X- _ O
, -X- _ O
the -X- _ O
static -X- _ B-MethodName
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
. -X- _ O

it -X- _ O
shows -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
embeddings -X- _ O
play -X- _ O
an -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
determining -X- _ B-TaskName
the -X- _ I-TaskName
difÔ¨Åculty -X- _ I-TaskName
levels -X- _ I-TaskName
. -X- _ O

the -X- _ O
random -X- _ B-MethodName
- -X- _ I-MethodName
we -X- _ I-MethodName
method -X- _ O
works -X- _ O
better -X- _ O
for -X- _ O
english -X- _ O
and -X- _ O
much -X- _ O
better -X- _ O
for -X- _ O
chinese -X- _ O
in -X- _ O
comparedto -X- _ O
the -X- _ O
ndc -X- _ B-MethodName
, -X- _ O
but -X- _ O
lower -X- _ O
than -X- _ O
when -X- _ O
using -X- _ O
pretrained -X- _ O
frequency -X- _ B-MethodName
and -X- _ I-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
. -X- _ O

their -X- _ O
results -X- _ O
are -X- _ O
still -X- _ O
much -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
cnn -X- _ B-MethodName
methods -X- _ O
using -X- _ O
pretrained -X- _ O
frequency -X- _ B-MethodName
and -X- _ I-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
. -X- _ O

4.3 -X- _ O
result -X- _ O
and -X- _ O
discussion -X- _ O
the -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
traditional -X- _ O
method -X- _ O
ndc -X- _ B-MethodName
works -X- _ O
much -X- _ O
better -X- _ O
for -X- _ O
english -X- _ O
dataset -X- _ O
( -X- _ O
50 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
than -X- _ O
for -X- _ O
chinese -X- _ O
( -X- _ O
17 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
probably -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
formulae -X- _ O
was -X- _ O
originally -X- _ O
designed -X- _ O
for -X- _ O
english -X- _ O
language -X- _ O
. -X- _ O

in -X- _ O
both -X- _ O
settings -X- _ O
, -X- _ O
the -X- _ O
frequency -X- _ B-MethodName
embeddings -X- _ I-MethodName
are -X- _ O
kept -X- _ B-MethodName
static -X- _ I-MethodName
during -X- _ O
training -X- _ O
. -X- _ O

in -X- _ O
the -X- _ O
wfe -X- _ B-MethodName
setting -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
three -X- _ O
frequency -X- _ O
metrics -X- _ O
: -X- _ O
raw -X- _ O
counts -X- _ O
, -X- _ O
ranking -X- _ O
and -X- _ O
frequency -X- _ O
class -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
the -X- _ O
wfe -X- _ B-MethodName
- -X- _ I-MethodName
class -X- _ I-MethodName
setting -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
only -X- _ O
the -X- _ O
frequency -X- _ O
class -X- _ O
metric -X- _ O
. -X- _ O

for -X- _ O
chinese -X- _ O
, -X- _ O
we -X- _ O
collected -X- _ O
a -X- _ O
dataset -X- _ O
consisting -X- _ O
of -X- _ O
news -X- _ O
( -X- _ O
320 -X- _ O
k -X- _ O
documents -X- _ O
) -X- _ O
and -X- _ O
wikipedia -X- _ O
, -X- _ O
tokenised -X- _ O
and -X- _ O
trained -X- _ O
the -X- _ O
word -X- _ B-MethodName
embeddings -X- _ I-MethodName
on -X- _ O
it -X- _ O
. -X- _ O

we -X- _ O
concatenate -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ B-MethodName
embeddings -X- _ I-MethodName
and -X- _ O
the -X- _ O
frequency -X- _ B-MethodName
embeddings -X- _ I-MethodName
as -X- _ O
explained -X- _ O
in -X- _ O
section -X- _ O
3 -X- _ O
. -X- _ O

only -X- _ O
frequency -X- _ B-MethodName
embeddings -X- _ I-MethodName
are -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
setting -X- _ O
( -X- _ O
without -X- _ O
word -X- _ B-MethodName
embeddings -X- _ I-MethodName
) -X- _ O
. -X- _ O

each -X- _ O
static -X- _ B-MethodName
and -X- _ O
non -X- _ B-MethodName
- -X- _ I-MethodName
static -X- _ I-MethodName
we -X- _ O
is -X- _ O
treated -X- _ O
as -X- _ O
one -X- _ O
channel -X- _ O
while -X- _ O
gradients -X- _ O
are -X- _ O
backpropagated -X- _ O
only -X- _ O
through -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
channels -X- _ O
. -X- _ O

these -X- _ O
two -X- _ O
settings -X- _ O
followed -X- _ O
the -X- _ O
method -X- _ O
in -X- _ O
( -X- _ O
kim -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
all -X- _ O
words -X- _ O
are -X- _ O
kept -X- _ O
either -X- _ O
static -X- _ B-MethodName
( -X- _ O
in -X- _ O
static -X- _ B-MethodName
setting -X- _ O
) -X- _ O
or -X- _ O
updated -X- _ O
( -X- _ O
in -X- _ O
non -X- _ B-MethodName
- -X- _ I-MethodName
static -X- _ I-MethodName
setting -X- _ O
) -X- _ O
including -X- _ O
the -X- _ O
unknown -X- _ O
ones -X- _ O
while -X- _ O
others -X- _ O
parameters -X- _ O
are -X- _ O
learned -X- _ O
. -X- _ O

we -X- _ O
used -X- _ O
rectiÔ¨Åed -X- _ O
linear -X- _ O
units -X- _ O
as -X- _ O
activation -X- _ O
functions -X- _ O
for -X- _ O
the -X- _ O
convolutional -X- _ O
layers -X- _ O
, -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.5 -X- _ B-HyperparameterValue
and -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
50 -X- _ B-HyperparameterValue
. -X- _ O

the -X- _ O
Ô¨Ålter -X- _ B-HyperparameterName
windows -X- _ I-HyperparameterName
‚Äô -X- _ I-HyperparameterName
sizes -X- _ I-HyperparameterName
are -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ O
5 -X- _ B-HyperparameterValue
with -X- _ O
100 -X- _ O
feature -X- _ O
maps -X- _ O
each -X- _ O
. -X- _ O

for -X- _ O
english -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word2vec -X- _ B-MethodName
by -X- _ O
( -X- _ O
mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

finally -X- _ O
, -X- _ O
if -X- _ O
pdwis -X- _ O
above -X- _ O
5 -X- _ O
% -X- _ O
, -X- _ O
then -X- _ O
add -X- _ O
3.6365 -X- _ O
to -X- _ O
the -X- _ O
raw -X- _ O
score -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
adjusted -X- _ O
score -X- _ O
. -X- _ O

raw -X- _ O
score -X- _ O
is -X- _ O
calculated -X- _ O
as: -X- _ O
= -X- _ O
0 -X- _ O
: -X- _ O
1579pdw+ -X- _ O
0:0496nw -X- _ O
nswhere -X- _ O
nwis -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
and -X- _ O
nsis -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
whole -X- _ O
corpus -X- _ O
, -X- _ O
hencenw -X- _ O
nsrepresents -X- _ O
the -X- _ O
average -X- _ O
sentence -X- _ O
length -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
. -X- _ O

pdwis -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
difÔ¨Åcult -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
document -X- _ O
, -X- _ O
calculated -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
difÔ¨Åcult -X- _ O
words -X- _ O
divided -X- _ O
by -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
. -X- _ O

the -X- _ O
new -X- _ B-MethodName
dale -X- _ I-MethodName
- -X- _ I-MethodName
chall -X- _ I-MethodName
readability -X- _ O
level -X- _ O
( -X- _ O
chall -X- _ O
and -X- _ O
dale -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
traditional -X- _ O
readability -X- _ O
test -X- _ O
. -X- _ O

we -X- _ O
split -X- _ O
randomly -X- _ O
the -X- _ O
dataset -X- _ O
70 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
for -X- _ O
training -X- _ O
, -X- _ O
27 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
for -X- _ O
testing -X- _ O
and -X- _ O
3 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
for -X- _ O
a -X- _ O
development -X- _ O
set.4.2 -X- _ O
experiment -X- _ O
setup -X- _ O
ndc -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
. -X- _ O

in -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
difÔ¨Åculty -X- _ O
levels -X- _ O
were -X- _ O
assigned -X- _ O
by -X- _ O
human -X- _ O
experts -X- _ O
. -X- _ O

in -X- _ O
total -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
279 -X- _ O
documents -X- _ O
with -X- _ O
4671 -X- _ O
sentences -X- _ O
in -X- _ O
enct -X- _ B-DatasetName
and -X- _ O
637 -X- _ O
documents -X- _ O
with -X- _ O
16145 -X- _ O
sentences -X- _ O
in -X- _ O
cpt -X- _ B-DatasetName
. -X- _ O

the -X- _ O
second -X- _ O
dataset -X- _ O
, -X- _ O
cpt -X- _ B-DatasetName
, -X- _ O
was -X- _ O
collected -X- _ O
from -X- _ O
chinese -X- _ O
primary -X- _ O
textbook -X- _ O
and -X- _ O
contains -X- _ O
six -X- _ O
difÔ¨Åculty -X- _ O
levels -X- _ O
. -X- _ O

the -X- _ O
Ô¨Årst -X- _ O
dataset -X- _ O
, -X- _ O
enct -X- _ B-DatasetName
, -X- _ O
was -X- _ O
built -X- _ O
with -X- _ O
four -X- _ O
reading -X- _ O
levels -X- _ O
from -X- _ O
english -X- _ O
new -X- _ O
concept -X- _ O
textbook -X- _ O
. -X- _ O

4 -X- _ O
evaluation -X- _ O
4.1 -X- _ O
dataset -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
methods -X- _ O
for -X- _ O
english -X- _ O
and -X- _ O
chinese -X- _ O
readability -X- _ B-TaskName
assessment -X- _ I-TaskName
on -X- _ O
two -X- _ O
datasets -X- _ O
collected -X- _ O
by -X- _ O
( -X- _ O
jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

the -X- _ O
feature -X- _ O
map -X- _ O
extracted -X- _ O
from -X- _ O
applying -X- _ O
the -X- _ O
Ô¨Ålters -X- _ O
on -X- _ O
word -X- _ O
embeddings -X- _ O
is -X- _ O
then -X- _ O
computed -X- _ O
as -X- _ O
: -X- _ O
ci -X- _ O
= -X- _ O
f(wxw -X- _ O
i -X- _ O
: -X- _ O
i+h 1+b -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
finally -X- _ O
this -X- _ O
feature -X- _ O
map -X- _ O
is -X- _ O
concatenated -X- _ O
with -X- _ O
the -X- _ O
frequency -X- _ O
embeddings -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
dropout -X- _ O
for -X- _ O
regularisation -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
described -X- _ O
in -X- _ O
( -X- _ O
kim -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
( -X- _ O
see -X- _ O
section -X- _ O
4.2 -X- _ O
) -X- _ O
. -X- _ O

convolutional -X- _ O
layers -X- _ O
and -X- _ O
max -X- _ O
poolings -X- _ O
are -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
as -X- _ O
these -X- _ O
layers -X- _ O
help -X- _ O
Ô¨Ånding -X- _ O
and -X- _ O
representing -X- _ O
features -X- _ O
of -X- _ O
interests -X- _ O
, -X- _ O
while -X- _ O
these -X- _ O
layers -X- _ O
are -X- _ O
omitted -X- _ O
for -X- _ O
frequency -X- _ O
embeddings -X- _ O
. -X- _ O

4 -X- _ O
is -X- _ O
applied -X- _ O
on -X- _ O
the -X- _ O
window -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
hfrom -X- _ O
xitoxi+h 1 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
weights -X- _ O
w2rhkewhere -X- _ O
ke -X- _ O
= -X- _ O
kw+kfandbis -X- _ O
the -X- _ O
bias.105 -X- _ O
figure -X- _ O
1 -X- _ O
: -X- _ B-MethodName
convolutional -X- _ B-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
architecture -X- _ O
with -X- _ B-MethodName
word -X- _ I-MethodName
frequency -X- _ I-MethodName
embedding -X- _ I-MethodName
we -X- _ O
then -X- _ O
apply -X- _ O
max -X- _ O
- -X- _ O
over -X- _ O
- -X- _ O
time -X- _ O
pooling -X- _ O
operations -X- _ O
in -X- _ O
the -X- _ O
feature -X- _ O
map -X- _ O
. -X- _ O

in -X- _ O
this -X- _ O
model -X- _ O
, -X- _ O
word -X- _ O
embeddings -X- _ O
and -X- _ O
frequency -X- _ O
embeddings -X- _ O
are -X- _ O
learned -X- _ O
separately -X- _ O
before -X- _ O
being -X- _ O
fetched -X- _ O
into -X- _ O
a -X- _ O
fully -X- _ O
connected -X- _ O
layer -X- _ O
. -X- _ O

2 -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
feature -X- _ O
ciis -X- _ O
obtained -X- _ O
using -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
activation -X- _ O
function -X- _ O
f -X- _ O
: -X- _ O
ci -X- _ O
= -X- _ O
f(wxe -X- _ O
i -X- _ O
: -X- _ O
i+h 1+b -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
where -X- _ O
xi -X- _ O
: -X- _ O
i+h 1represents -X- _ O
the -X- _ O
matrix -X- _ O
which -X- _ O
composes -X- _ O
of -X- _ O
vectors -X- _ O
from -X- _ O
xitoxi+h 1 -X- _ O
. -X- _ O

a -X- _ O
feature -X- _ O
map -X- _ O
is -X- _ O
generated -X- _ O
using -X- _ O
Ô¨Ålters -X- _ O
of -X- _ O
window -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
hto -X- _ O
the -X- _ O
sentence -X- _ O
matrix -X- _ O
in -X- _ O
eq -X- _ O
. -X- _ O

the -X- _ O
sentence -X- _ O
with -X- _ O
length -X- _ O
nis -X- _ O
then -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
matrix -X- _ O
: -X- _ O
[ -X- _ O
xw -X- _ O
1xf -X- _ O
1 -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
xw -X- _ O
ixf -X- _ O
i -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
xw -X- _ O
nxf -X- _ O
n -X- _ O
] -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
andxe -X- _ O
i -X- _ O
= -X- _ O
xw -X- _ O
ixf -X- _ O
irepresents -X- _ O
the -X- _ O
Ô¨Ånal -X- _ O
embedding -X- _ O
of -X- _ O
word -X- _ O
xi -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
word -X- _ O
and -X- _ O
frequency -X- _ O
embeddings -X- _ O
. -X- _ O

note -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
frequency -X- _ O
embeddings -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
randomly -X- _ O
assigning -X- _ O
values -X- _ O
to -X- _ O
unknown -X- _ O
words -X- _ O
as -X- _ O
in -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
them -X- _ O
to -X- _ O
the -X- _ O
highest -X- _ O
frequency -X- _ O
class -X- _ O
adopted -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
corpus -X- _ O
. -X- _ O

xw -X- _ O
irepresents -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
word -X- _ O
wiwhile -X- _ O
xf -X- _ O
irepresents -X- _ O
its -X- _ O
frequency -X- _ O
embeddings -X- _ O
. -X- _ O

letxw -X- _ O
i2rkwandxf -X- _ O
i2rkf -X- _ O
, -X- _ O
where -X- _ O
xiis -X- _ O
a -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
of -X- _ O
length -X- _ O
n -X- _ O
, -X- _ O
kwis -X- _ O
the -X- _ O
word -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
and -X- _ O
kfis -X- _ O
the -X- _ O
frequency -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
. -X- _ O

the -X- _ O
network -X- _ O
learns -X- _ O
these -X- _ O
Ô¨Ålters -X- _ O
‚Äô -X- _ O
weights -X- _ O
that -X- _ O
activate -X- _ O
features -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
these -X- _ O
embeddings -X- _ O
. -X- _ O

in -X- _ O
this -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
Ô¨Ålters -X- _ O
are -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
concatenated -X- _ O
embeddings -X- _ O
of -X- _ O
word -X- _ O
and -X- _ O
frequency -X- _ O
. -X- _ O

in -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
two -X- _ O
models -X- _ O
( -X- _ O
figure -X- _ O
1 -X- _ O
) -X- _ O
wfe -X- _ B-MethodName
- -X- _ I-MethodName
com -X- _ I-MethodName
( -X- _ O
left -X- _ O
) -X- _ O
and -X- _ O
wfe -X- _ B-MethodName
- -X- _ I-MethodName
sep -X- _ I-MethodName
( -X- _ O
right -X- _ O
) -X- _ O
. -X- _ O

in -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
frequency -X- _ O
class -X- _ O
fc -X- _ O
( -X- _ O
w)of -X- _ O
a -X- _ O
word -X- _ O
wdescribes -X- _ O
the -X- _ O
frequency -X- _ O
freq -X- _ O
( -X- _ O
w)of -X- _ O
the -X- _ O
word -X- _ O
in -X- _ O
relation -X- _ O
to -X- _ O
the -X- _ O
frequency -X- _ O
freq -X- _ O
max -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
word -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
with -X- _ O
ranking -X- _ O
0 -X- _ O
( -X- _ O
sabine -X- _ O
fiedler -X- _ O
and -X- _ O
quasthoff -X- _ O
, -X- _ O
2012 -X- _ O
): -X- _ O
fc(w -X- _ O
) -X- _ O
= -X- _ O
log2freqmax -X- _ O
freqw(1 -X- _ O
) -X- _ O
our -X- _ O
architecture -X- _ O
is -X- _ O
slightly -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
cnn -X- _ O
architecture -X- _ O
presented -X- _ O
in -X- _ O
( -X- _ O
kim -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

among -X- _ O
these -X- _ O
metrics -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
frequency -X- _ O
class -X- _ O
information -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
generalised -X- _ O
one -X- _ O
. -X- _ O

we -X- _ O
take -X- _ O
these -X- _ O
metrics -X- _ O
directly -X- _ O
as -X- _ O
an -X- _ O
embedding -X- _ O
vector -X- _ O
represents -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
. -X- _ O

1we -X- _ O
have -X- _ O
not -X- _ O
taken -X- _ O
into -X- _ O
account -X- _ O
rare -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
easy -X- _ O
to -X- _ O
understand -X- _ O
, -X- _ O
for -X- _ O
examples -X- _ O
names -X- _ O
, -X- _ O
locationsthe -X- _ O
three -X- _ O
common -X- _ O
metrics -X- _ O
representing -X- _ O
word -X- _ O
frequency -X- _ O
information -X- _ O
are -X- _ O
raw -X- _ O
counts -X- _ O
( -X- _ O
number -X- _ O
of -X- _ O
times -X- _ O
a -X- _ O
word -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
whole -X- _ O
corpus -X- _ O
) -X- _ O
, -X- _ O
ranking -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
rank -X- _ O
0 -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
common -X- _ O
word -X- _ O
) -X- _ O
and -X- _ O
frequency -X- _ O
classes -X- _ O
. -X- _ O

in -X- _ O
addition -X- _ O
, -X- _ O
frequency -X- _ O
information -X- _ O
plays -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
pointing -X- _ O
out -X- _ O
which -X- _ O
words -X- _ O
are -X- _ O
more -X- _ O
difÔ¨Åcult -X- _ O
to -X- _ O
understand1 -X- _ O
. -X- _ O

word -X- _ O
embeddings -X- _ O
help -X- _ O
associating -X- _ O
the -X- _ O
topics -X- _ O
of -X- _ O
documents -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
important -X- _ O
to -X- _ O
assess -X- _ B-TaskName
the -X- _ I-TaskName
readability -X- _ I-TaskName
levels -X- _ I-TaskName
( -X- _ O
e.g. -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
topics -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
difÔ¨Åcult -X- _ O
to -X- _ O
understand -X- _ O
than -X- _ O
others -X- _ O
from -X- _ O
their -X- _ O
natures -X- _ O
) -X- _ O
. -X- _ O

our -X- _ O
hypothesis -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
learn -X- _ O
better -X- _ O
from -X- _ O
knowing -X- _ O
words -X- _ O
‚Äô -X- _ O
difÔ¨Åculty -X- _ O
levels -X- _ O
besides -X- _ O
their -X- _ O
meanings -X- _ O
. -X- _ O

from -X- _ O
this -X- _ O
observation -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
takes -X- _ O
into -X- _ O
account -X- _ O
also -X- _ O
word -X- _ O
frequency -X- _ O
information -X- _ O
besides -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

in -X- _ O
the -X- _ O
readability -X- _ B-TaskName
assessment -X- _ I-TaskName
scenario -X- _ O
, -X- _ O
frequency -X- _ O
information -X- _ O
is -X- _ O
important -X- _ O
in -X- _ O
deciding -X- _ O
whether -X- _ O
a -X- _ O
document -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
read -X- _ O
or -X- _ O
not -X- _ O
( -X- _ O
jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

although -X- _ O
they -X- _ O
can -X- _ O
reÔ¨Çect -X- _ O
word -X- _ O
meaning -X- _ O
and -X- _ O
topics -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
take -X- _ O
directly -X- _ O
frequency -X- _ O
information -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
into -X- _ O
account -X- _ O
. -X- _ O

they -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
context -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
word -X- _ O
appears -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
words -X- _ O
. -X- _ O

word -X- _ O
embeddings -X- _ O
are -X- _ O
used -X- _ O
transferrably -X- _ O
in -X- _ O
many -X- _ O
general -X- _ O
nlp -X- _ O
tasks -X- _ O
. -X- _ O

motivated -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
success -X- _ O
of -X- _ O
convolutional -X- _ B-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ O
cnn -X- _ B-MethodName
) -X- _ O
models -X- _ O
in -X- _ O
many -X- _ O
text -X- _ O
classiÔ¨Åcation -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
models -X- _ O
for -X- _ O
learning -X- _ O
and -X- _ O
classifying -X- _ O
a -X- _ O
given -X- _ O
text -X- _ O
to -X- _ O
its -X- _ O
difÔ¨Åculty -X- _ O
level -X- _ O
. -X- _ O

these -X- _ O
methods -X- _ O
are -X- _ O
not -X- _ O
easily -X- _ O
transferred -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
especially -X- _ O
asian -X- _ O
. -X- _ O

3 -X- _ O
our -X- _ O
method -X- _ O
while -X- _ O
traditional -X- _ O
methods -X- _ O
are -X- _ O
simple -X- _ O
to -X- _ O
implement -X- _ O
, -X- _ O
they -X- _ O
focus -X- _ O
mostly -X- _ O
on -X- _ O
latin -X- _ O
languages -X- _ O
such -X- _ O
as -X- _ O
english -X- _ O
. -X- _ O

most -X- _ O
of -X- _ O
these -X- _ O
studies -X- _ O
however -X- _ O
require -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
, -X- _ O
language -X- _ O
- -X- _ O
dependent -X- _ O
features -X- _ O
, -X- _ O
and -X- _ O
not -X- _ O
readily -X- _ O
applicable -X- _ O
to -X- _ O
multilingual -X- _ O
setting -X- _ O
. -X- _ O

2007 -X- _ O
) -X- _ O
, -X- _ O
grammatical -X- _ O
templates -X- _ O
( -X- _ O
wang -X- _ O
and -X- _ O
andersen -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
word -X- _ O
frequency -X- _ O
smoothed -X- _ O
by -X- _ O
correlation -X- _ O
information -X- _ O
( -X- _ O
jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

in -X- _ O
these -X- _ O
studies -X- _ O
, -X- _ O
documents -X- _ O
are -X- _ O
represented -X- _ O
by -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
features -X- _ O
such -X- _ O
as -X- _ O
bag -X- _ O
of -X- _ O
words -X- _ O
, -X- _ O
lexical -X- _ O
and -X- _ O
grammatical -X- _ O
features -X- _ O
extracted -X- _ O
from -X- _ O
parse -X- _ O
trees -X- _ O
( -X- _ O
heilman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

the -X- _ O
data -X- _ O
driven -X- _ O
approach -X- _ O
treats -X- _ O
readability -X- _ B-TaskName
assessment -X- _ I-TaskName
as -X- _ O
a -X- _ O
machine -X- _ O
learning -X- _ O
problem -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
to -X- _ O
automatically -X- _ O
learn -X- _ O
the -X- _ O
mapping -X- _ O
from -X- _ O
documents -X- _ O
to -X- _ O
difÔ¨Åculty -X- _ O
levels -X- _ O
based -X- _ O
on -X- _ O
training -X- _ O
examples -X- _ O
( -X- _ O
si -X- _ O
and -X- _ O
callan -X- _ O
, -X- _ O
2001 -X- _ O
; -X- _ O
heilman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

though -X- _ O
considered -X- _ O
quick -X- _ O
and -X- _ O
easy -X- _ O
to -X- _ O
compute -X- _ O
, -X- _ O
these -X- _ O
tra-104ditional -X- _ O
metrics -X- _ O
/ -X- _ O
formulae -X- _ O
are -X- _ O
designed -X- _ O
with -X- _ O
some -X- _ O
speciÔ¨Åc -X- _ O
language -X- _ O
in -X- _ O
mind -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
work -X- _ O
well -X- _ O
when -X- _ O
applying -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O

these -X- _ O
early -X- _ O
studies -X- _ O
evaluated -X- _ O
text -X- _ O
difÔ¨Åculty -X- _ O
based -X- _ O
on -X- _ O
shallow -X- _ O
features -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
difÔ¨Åculty -X- _ O
levels -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
sentence -X- _ O
length -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
syllables -X- _ O
. -X- _ O

1975 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
chall -X- _ O
and -X- _ O
dale -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
. -X- _ O

the -X- _ O
traditional -X- _ O
approach -X- _ O
include -X- _ O
( -X- _ O
dale -X- _ O
and -X- _ O
chall -X- _ O
, -X- _ O
1948 -X- _ O
) -X- _ O
, -X- _ O
fog -X- _ O
index -X- _ O
( -X- _ O
gunning -X- _ O
, -X- _ O
1952 -X- _ O
) -X- _ O
, -X- _ O
smog -X- _ O
( -X- _ O
mc -X- _ O
laughlin -X- _ O
, -X- _ O
1969 -X- _ O
) -X- _ O
and -X- _ O
flesch -X- _ O
- -X- _ O
kincaid -X- _ O
index -X- _ O
( -X- _ O
kincaid -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2 -X- _ O
related -X- _ O
work -X- _ O
readability -X- _ B-TaskName
assessment -X- _ I-TaskName
methods -X- _ O
can -X- _ O
be -X- _ O
classiÔ¨Åed -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
, -X- _ O
the -X- _ O
traditional -X- _ O
approach -X- _ O
and -X- _ O
data -X- _ O
driven -X- _ O
approach -X- _ O
. -X- _ O

since -X- _ O
this -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
features -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
adapted -X- _ O
to -X- _ O
multiple -X- _ O
languages -X- _ O
. -X- _ O

these -X- _ O
two -X- _ O
embedding -X- _ O
layers -X- _ O
are -X- _ O
employed -X- _ O
in -X- _ O
a -X- _ O
cnn -X- _ B-MethodName
architecture -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
readability -X- _ O
level -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
document -X- _ O
. -X- _ O

we -X- _ O
therefore -X- _ O
propose -X- _ O
two -X- _ O
models -X- _ O
that -X- _ O
jointly -X- _ O
represent -X- _ O
words -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
meanings -X- _ O
with -X- _ O
traditional -X- _ O
word -X- _ O
embeddings -X- _ O
and -X- _ O
their -X- _ O
frequency -X- _ O
levels -X- _ O
with -X- _ O
the -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
frequency -X- _ B-MethodName
embeddings -X- _ I-MethodName
. -X- _ O

it -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
more -X- _ O
frequent -X- _ O
words -X- _ O
are -X- _ O
supposed -X- _ O
to -X- _ O
be -X- _ O
easier -X- _ O
to -X- _ O
understand -X- _ O
. -X- _ O

in -X- _ O
our -X- _ O
scenario -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
desirable -X- _ O
that -X- _ O
the -X- _ O
system -X- _ O
can -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
frequency -X- _ O
level -X- _ O
of -X- _ O
words -X- _ O
rather -X- _ O
purely -X- _ O
focusing -X- _ O
on -X- _ O
their -X- _ O
meanings -X- _ O
. -X- _ O

though -X- _ O
they -X- _ O
are -X- _ O
useful -X- _ O
since -X- _ O
topics -X- _ O
are -X- _ O
good -X- _ O
indications -X- _ O
of -X- _ O
whether -X- _ O
a -X- _ O
document -X- _ O
is -X- _ O
difÔ¨Åcult -X- _ O
to -X- _ O
comprehend -X- _ O
, -X- _ O
word -X- _ O
embeddings -X- _ O
do -X- _ O
not -X- _ O
directly -X- _ O
reÔ¨Çect -X- _ O
the -X- _ O
frequency -X- _ O
levels -X- _ O
of -X- _ O
words -X- _ O
. -X- _ O

the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
generally -X- _ O
designed -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
they -X- _ O
can -X- _ O
capture -X- _ O
word -X- _ O
meaning -X- _ O
and -X- _ O
topics -X- _ O
. -X- _ O

these -X- _ O
models -X- _ O
often -X- _ O
use -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
nlp -X- _ O
tasks -X- _ O
and -X- _ O
have -X- _ O
been -X- _ O
proven -X- _ O
to -X- _ O
achieve -X- _ O
good -X- _ O
results -X- _ O
on -X- _ O
multiple -X- _ O
benchmarks -X- _ O
( -X- _ O
mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2011 -X- _ O
) -X- _ O
typically -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
to -X- _ O
be -X- _ O
supplied -X- _ O
with -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
features -X- _ O
. -X- _ O

our -X- _ O
aim -X- _ O
is -X- _ O
to -X- _ O
develop -X- _ O
a -X- _ O
universal -X- _ O
method -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
a -X- _ O
multilingual -X- _ O
setting -X- _ O
, -X- _ O
which -X- _ O
involve -X- _ O
little -X- _ O
effort -X- _ O
when -X- _ O
extending -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O

these -X- _ O
approaches -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
rely -X- _ O
on -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
features -X- _ O
that -X- _ O
depend -X- _ O
heavily -X- _ O
on -X- _ O
the -X- _ O
languages -X- _ O
and -X- _ O
require -X- _ O
adjustment -X- _ O
when -X- _ O
applying -X- _ O
to -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
. -X- _ O

1975 -X- _ O
; -X- _ O
chall -X- _ O
and -X- _ O
dale -X- _ O
, -X- _ O
1995 -X- _ O
; -X- _ O
si -X- _ O
and -X- _ O
callan -X- _ O
, -X- _ O
2001 -X- _ O
; -X- _ O
heilman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

it -X- _ O
is -X- _ O
useful -X- _ O
in -X- _ O
many -X- _ O
applications -X- _ O
such -X- _ O
as -X- _ O
selecting -X- _ O
learning -X- _ O
material -X- _ O
for -X- _ O
children -X- _ O
of -X- _ O
different -X- _ O
grade -X- _ O
levels -X- _ O
, -X- _ O
for -X- _ O
language -X- _ O
learners -X- _ O
, -X- _ O
for -X- _ O
comprehension -X- _ O
tests -X- _ O
, -X- _ O
skills -X- _ O
training -X- _ O
, -X- _ O
text -X- _ O
summarisation -X- _ O
, -X- _ O
simpliÔ¨Åcation -X- _ O
systems -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
. -X- _ O

1 -X- _ O
introduction -X- _ O
readability -X- _ B-TaskName
assessment -X- _ I-TaskName
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
determining -X- _ O
how -X- _ O
difÔ¨Åcult -X- _ O
a -X- _ O
given -X- _ O
document -X- _ O
is -X- _ O
to -X- _ O
understand -X- _ O
. -X- _ O

the -X- _ O
experimental -X- _ O
results -X- _ O
testing -X- _ O
on -X- _ O
both -X- _ O
english -X- _ O
and -X- _ O
chinese -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
models -X- _ O
improve -X- _ O
the -X- _ O
results -X- _ O
notably -X- _ O
when -X- _ O
comparing -X- _ O
to -X- _ O
those -X- _ O
using -X- _ O
only -X- _ O
traditional -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

the -X- _ O
proposed -X- _ O
models -X- _ O
show -X- _ O
how -X- _ O
frequency -X- _ O
information -X- _ O
can -X- _ O
be -X- _ O
integrated -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
readability -X- _ B-TaskName
assessment -X- _ I-TaskName
. -X- _ O

the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
difÔ¨Åculty -X- _ O
level -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
document -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
how -X- _ O
hard -X- _ O
it -X- _ O
is -X- _ O
for -X- _ O
a -X- _ O
reader -X- _ O
to -X- _ O
fully -X- _ O
comprehend -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O

acknowledgments -X- _ O
this -X- _ O
study -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
dfg -X- _ O
grant -X- _ O
oceanic -X- _ O
exchanges -X- _ O
( -X- _ O
ko -X- _ O
5362/2 -X- _ O
- -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
creta -X- _ O
center -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
german -X- _ O
ministry -X- _ O
for -X- _ O
education -X- _ O
and -X- _ O
research -X- _ O
( -X- _ O
bmbf -X- _ O
) -X- _ O
. -X- _ O

in -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
extend -X- _ O
the -X- _ O
bilstm -X- _ B-MethodName
to -X- _ O
other -X- _ O
languages -X- _ O
using -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
embeddings -X- _ O
( -X- _ O
ruder -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

in -X- _ O
sum -X- _ O
, -X- _ O
modern -X- _ O
rnns -X- _ B-MethodName
consistently -X- _ O
yield -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
. -X- _ O

even -X- _ O
though -X- _ O
rnns -X- _ B-MethodName
struggle -X- _ O
with -X- _ O
small -X- _ O
datasets -X- _ O
, -X- _ O
transfer -X- _ O
learning -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
and -X- _ O
effective -X- _ O
remedy -X- _ O
to -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
even -X- _ O
for -X- _ O
such -X- _ O
datasets -X- _ O
. -X- _ O

we -X- _ O
found -X- _ O
that -X- _ O
combining -X- _ O
bilstm -X- _ B-MethodName
with -X- _ O
a -X- _ O
crf -X- _ B-MethodName
as -X- _ O
top -X- _ O
layer -X- _ O
, -X- _ O
outperform -X- _ O
crfs -X- _ B-MethodName
with -X- _ O
hand -X- _ O
- -X- _ O
coded -X- _ O
features -X- _ O
consistently -X- _ O
when -X- _ O
enough -X- _ O
data -X- _ O
is -X- _ O
available -X- _ O
. -X- _ O

we -X- _ O
have -X- _ O
investigated -X- _ O
the -X- _ O
relative -X- _ O
performance -X- _ O
of -X- _ O
an -X- _ O
bilstm -X- _ B-MethodName
method -X- _ O
and -X- _ O
traditional -X- _ B-MethodName
crfs -X- _ I-MethodName
on -X- _ O
german -X- _ O
ner -X- _ B-TaskName
in -X- _ O
big- -X- _ O
and -X- _ O
small -X- _ O
- -X- _ O
data -X- _ O
situations -X- _ O
, -X- _ O
asking -X- _ O
whether -X- _ O
it -X- _ O
makes -X- _ O
sense -X- _ O
to -X- _ O
consider -X- _ O
different -X- _ O
model -X- _ O
types -X- _ O
for -X- _ O
different -X- _ O
setups -X- _ O
. -X- _ O

9 -X- _ O
conclusion -X- _ O
our -X- _ O
study -X- _ O
Ô¨Ålls -X- _ O
an -X- _ O
empirical -X- _ O
gap -X- _ O
by -X- _ O
considering -X- _ O
historical -X- _ O
datasets -X- _ O
and -X- _ O
performing -X- _ O
careful -X- _ O
comparisons -X- _ O
of -X- _ O
multiple -X- _ O
models -X- _ O
under -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
conditions -X- _ O
. -X- _ O

most -X- _ O
related -X- _ O
to -X- _ O
our -X- _ O
paper -X- _ O
is -X- _ O
the -X- _ O
work -X- _ O
by -X- _ O
ghaddar -X- _ O
and -X- _ O
langlais -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
which -X- _ O
demonstrates -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
of -X- _ O
the -X- _ O
english -X- _ O
conll -X- _ B-DatasetName
2003 -X- _ I-DatasetName
dataset -X- _ O
with -X- _ O
wikipedia -X- _ O
annotations -X- _ O
. -X- _ O

2017 -X- _ O
) -X- _ O
yield -X- _ O
improvements -X- _ O
up -X- _ O
to -X- _ O
0.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
ner -X- _ B-TaskName
in -X- _ O
the -X- _ O
medical -X- _ O
domain -X- _ O
. -X- _ O

with -X- _ O
different -X- _ O
labels -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
only -X- _ O
60 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
achieve -X- _ O
good -X- _ O
results -X- _ O
. -X- _ O

sutton -X- _ O
and -X- _ O
mccallum -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
showed -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
crfs -X- _ B-MethodName
for -X- _ O
transfer -X- _ O
learning -X- _ O
by -X- _ O
joint -X- _ O
decoding -X- _ O
two -X- _ O
separately -X- _ O
trained -X- _ O
sequence -X- _ O
models -X- _ O
. -X- _ O

2016 -X- _ O
; -X- _ O
reimers -X- _ O
and -X- _ O
gurevych -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ B-DatasetName
germeval -X- _ I-DatasetName
( -X- _ O
reimers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

however -X- _ O
, -X- _ O
only -X- _ O
few -X- _ O
systems -X- _ O
reported -X- _ O
results -X- _ O
for -X- _ O
german -X- _ O
ner -X- _ B-TaskName
, -X- _ O
and -X- _ O
restrict -X- _ O
themselves -X- _ O
to -X- _ O
the -X- _ O
‚Äú -X- _ O
big -X- _ O
- -X- _ O
data -X- _ O
‚Äù -X- _ O
scenarios -X- _ O
of -X- _ O
the -X- _ O
conll -X- _ B-DatasetName
2003 -X- _ I-DatasetName
( -X- _ O
lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2016 -X- _ O
; -X- _ O
reimers -X- _ O
and -X- _ O
gurevych -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

8 -X- _ O
related -X- _ O
work -X- _ B-MethodName
bilstms -X- _ I-MethodName
that -X- _ O
combine -X- _ O
neural -X- _ O
network -X- _ O
architectures -X- _ O
with -X- _ O
crf -X- _ B-MethodName
- -X- _ O
based -X- _ O
superstructures -X- _ O
yield -X- _ O
the -X- _ O
highest -X- _ O
results -X- _ O
on -X- _ O
english -X- _ O
ner -X- _ B-TaskName
datasets -X- _ O
in -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
studies -X- _ O
( -X- _ O
ma -X- _ O
and -X- _ O
hovy -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

czechoslovakian -X- _ O
press -X- _ O
) -X- _ O
is -X- _ O
detected -X- _ O
as -X- _ O
organization -X- _ O
by -X- _ O
all -X- _ O
classiÔ¨Åers -X- _ O
but -X- _ O
is -X- _ O
not -X- _ O
manually -X- _ O
annotated -X- _ O
. -X- _ O

for -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
typo -X- _ O
‚Äú -X- _ O
sterreichischen -X- _ O
au√üenministerlum -X- _ O
‚Äù -X- _ O
( -X- _ O
should -X- _ O
be -X- _ O
‚Äú -X- _ O
au√üenministerium -X- _ O
‚Äù -X- _ O
, -X- _ O
austrian -X- _ O
foreign -X- _ O
ministry -X- _ O
) -X- _ O
is -X- _ O
manually -X- _ O
annotated -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
but -X- _ O
not -X- _ O
detected -X- _ O
by -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O

often -X- _ O
, -X- _ O
the -X- _ O
annotations -X- _ O
for -X- _ O
the -X- _ O
organization -X- _ O
category -X- _ O
are -X- _ O
not -X- _ O
entirely -X- _ O
clear -X- _ O
. -X- _ O

evaluating -X- _ O
on -X- _ O
the -X- _ O
onb -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
an -X- _ O
f1 -X- _ B-MetricName
score -X- _ O
for -X- _ O
that -X- _ O
label -X- _ O
of -X- _ O
50.22 -X- _ B-MetricValue
using -X- _ O
germaner -X- _ B-MethodName
, -X- _ O
48.63 -X- _ B-MetricValue
for -X- _ O
the -X- _ O
bilstm -X- _ B-MethodName
using -X- _ O
europeana -X- _ B-MethodName
embeddings -X- _ I-MethodName
and -X- _ O
61.48 -X- _ B-MetricValue
using -X- _ O
transfer -X- _ O
learning -X- _ O
. -X- _ O

the -X- _ O
lowest -X- _ O
f1 -X- _ B-MetricName
scores -X- _ O
are -X- _ O
achieved -X- _ O
for -X- _ O
the -X- _ O
label -X- _ O
organization -X- _ O
. -X- _ O

7 -X- _ O
data -X- _ O
analysis -X- _ O
besides -X- _ O
ocr -X- _ B-MetricName
errors -X- _ O
, -X- _ O
the -X- _ O
lower -X- _ B-MetricName
f1 -X- _ I-MetricName
scores -X- _ O
for -X- _ O
the -X- _ O
historic -X- _ O
data -X- _ O
are -X- _ O
largely -X- _ O
due -X- _ O
to -X- _ O
hyphens -X- _ O
used -X- _ O
to -X- _ O
divide -X- _ O
words -X- _ O
for -X- _ O
line -X- _ O
breaks -X- _ O
. -X- _ O

we -X- _ O
applied -X- _ O
the -X- _ O
same -X- _ O
procedure -X- _ O
to -X- _ O
the -X- _ O
crfs -X- _ B-MethodName
, -X- _ O
but -X- _ O
did -X- _ O
not -X- _ O
obtain -X- _ O
improvements -X- _ O
for -X- _ O
the -X- _ O
‚Äú -X- _ O
target -X- _ O
‚Äù -X- _ O
data -X- _ O
. -X- _ O

we -X- _ O
conclude -X- _ O
that -X- _ O
transfer -X- _ O
learning -X- _ O
is -X- _ O
beneÔ¨Åcial -X- _ O
for -X- _ O
bilstms -X- _ B-MethodName
, -X- _ O
especially -X- _ O
when -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
is -X- _ O
scarce -X- _ O
. -X- _ O

the -X- _ O
germeval -X- _ B-DatasetName
corpus -X- _ O
is -X- _ O
more -X- _ O
appropriate -X- _ O
as -X- _ O
a -X- _ O
source -X- _ O
corpus -X- _ O
, -X- _ O
presumably -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
both -X- _ O
larger -X- _ O
and -X- _ O
drawn -X- _ O
from -X- _ O
encyclopaedic -X- _ O
text -X- _ O
, -X- _ O
more -X- _ O
varied -X- _ O
than -X- _ O
newswire -X- _ O
. -X- _ O

theresults -X- _ O
in -X- _ O
table -X- _ O
5 -X- _ O
show -X- _ O
signiÔ¨Åcant -X- _ O
improvements -X- _ O
for -X- _ O
the -X- _ O
conll -X- _ B-DatasetName
dataset -X- _ O
but -X- _ O
performance -X- _ O
drops -X- _ O
for -X- _ O
germeval -X- _ B-DatasetName
. -X- _ O

performance -X- _ O
on -X- _ B-DatasetName
lft -X- _ I-DatasetName
increases -X- _ O
from -X- _ O
69.62 -X- _ B-MetricValue
to -X- _ O
74.33 -X- _ B-MetricValue
and -X- _ O
on -X- _ O
onb -X- _ B-DatasetName
from -X- _ O
73.31 -X- _ B-MetricValue
to -X- _ O
78.56 -X- _ B-MetricValue
. -X- _ O

combining -X- _ O
contemporary -X- _ O
sources -X- _ O
with -X- _ O
historic -X- _ O
target -X- _ O
corpora -X- _ O
yields -X- _ O
to -X- _ O
consistent -X- _ O
beneÔ¨Åts -X- _ O
. -X- _ O

in -X- _ O
our -X- _ O
scenario -X- _ O
, -X- _ O
we -X- _ O
start -X- _ O
by -X- _ O
training -X- _ O
on -X- _ O
large -X- _ O
contemporary -X- _ O
‚Äú -X- _ O
source -X- _ O
‚Äù -X- _ O
corpora -X- _ O
until -X- _ O
convergence -X- _ O
and -X- _ O
then -X- _ O
train -X- _ O
additional -X- _ O
15 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
‚Äú -X- _ O
target -X- _ O
‚Äù -X- _ O
corpus -X- _ O
from -X- _ O
the -X- _ O
domain -X- _ O
on -X- _ O
which -X- _ O
we -X- _ O
evaluate -X- _ O
. -X- _ O

2017 -X- _ O
): -X- _ O
we -X- _ O
simply -X- _ O
start -X- _ O
training -X- _ O
on -X- _ O
one -X- _ O
corpus -X- _ O
and -X- _ O
at -X- _ O
some -X- _ O
point -X- _ O
switch -X- _ O
to -X- _ O
another -X- _ O
corpus -X- _ O
. -X- _ O

a -X- _ O
simple -X- _ O
way -X- _ O
of -X- _ O
doing -X- _ O
this -X- _ O
is -X- _ O
transfer -X- _ O
learning -X- _ O
( -X- _ O
lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

6 -X- _ O
experiment -X- _ O
3 -X- _ O
: -X- _ O
transfer -X- _ O
learning -X- _ O
if -X- _ O
the -X- _ O
problems -X- _ O
of -X- _ O
bilstm -X- _ B-MethodName
from -X- _ O
the -X- _ O
last -X- _ O
section -X- _ O
are -X- _ O
in -X- _ O
fact -X- _ O
due -X- _ O
to -X- _ O
lack -X- _ O
of -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
might -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
obtain -X- _ O
an -X- _ O
improvement -X- _ O
by -X- _ O
combining -X- _ O
them -X- _ O
. -X- _ O

in -X- _ O
sum -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
bilstm -X- _ B-MethodName
models -X- _ O
run -X- _ O
into -X- _ O
trouble -X- _ O
when -X- _ O
faced -X- _ O
with -X- _ O
very -X- _ O
small -X- _ O
training -X- _ O
datasets -X- _ O
, -X- _ O
while -X- _ O
crf -X- _ B-MethodName
- -X- _ O
based -X- _ O
methods -X- _ O
are -X- _ O
more -X- _ O
robust -X- _ O
( -X- _ O
cotterell -X- _ O
and -X- _ O
duh -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

the -X- _ O
type -X- _ O
of -X- _ O
embeddings -X- _ O
used -X- _ O
by -X- _ O
bilstm -X- _ B-MethodName
plays -X- _ O
a -X- _ O
minor -X- _ O
role -X- _ O
for -X- _ O
the -X- _ O
historical -X- _ O
corpora -X- _ O
( -X- _ O
for -X- _ O
contemporary -X- _ O
corpora -X- _ O
, -X- _ O
wikipedia -X- _ O
is -X- _ O
clearly -X- _ O
better -X- _ O
) -X- _ O
. -X- _ O

interestingly -X- _ O
, -X- _ O
these -X- _ O
beneÔ¨Åts -X- _ O
also -X- _ O
extend -X- _ O
to -X- _ O
the -X- _ O
historical -X- _ O
datasets -X- _ O
for -X- _ O
which -X- _ O
the -X- _ O
crf -X- _ B-MethodName
features -X- _ O
were -X- _ O
presumably -X- _ O
not -X- _ O
optimized -X- _ O
: -X- _ O
overall -X- _ O
f1 -X- _ B-MetricName
- -X- _ O
scores -X- _ O
are -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
points -X- _ O
lower -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
contemporary -X- _ O
corpora -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
crfs -X- _ B-MethodName
signiÔ¨Åcantly -X- _ O
outperform -X- _ O
the -X- _ O
bilstm -X- _ B-MethodName
models -X- _ O
on -X- _ O
onb -X- _ B-DatasetName
and -X- _ O
performs -X- _ O
comparable -X- _ O
on -X- _ O
the -X- _ O
larger -X- _ O
lft -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

germaner -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
stanfordner -X- _ B-MethodName
again -X- _ O
, -X- _ O
highlighting -X- _ O
the -X- _ O
beneÔ¨Åts -X- _ O
of -X- _ O
knowledge -X- _ O
engineering -X- _ O
when -X- _ O
using -X- _ O
crfs -X- _ B-MethodName
. -X- _ O

unsurprisingly -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
are -X- _ O
gained -X- _ O
when -X- _ O
testing -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
dataset -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
has -X- _ O
been -X- _ O
performed -X- _ O
. -X- _ O

experiment -X- _ O
2 -X- _ O
evaluates -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
models -X- _ O
do -X- _ O
when -X- _ O
trained -X- _ O
on -X- _ O
one -X- _ O
corpus -X- _ O
and -X- _ O
tested -X- _ O
on -X- _ O
another -X- _ O
one -X- _ O
, -X- _ O
including -X- _ O
historical -X- _ O
corpora -X- _ O
. -X- _ O

5 -X- _ O
experiment -X- _ O
2 -X- _ O
: -X- _ O
cross -X- _ O
- -X- _ O
corpus -X- _ O
performance -X- _ O
a -X- _ O
potential -X- _ O
downside -X- _ O
of -X- _ O
bilstms -X- _ B-MethodName
is -X- _ O
that -X- _ O
learned -X- _ O
models -X- _ O
may -X- _ O
be -X- _ O
more -X- _ O
text -X- _ O
type -X- _ O
speciÔ¨Åc -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
high -X- _ O
capacity -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O

in -X- _ O
sum -X- _ O
, -X- _ O
we -X- _ O
Ô¨Ånd -X- _ O
that -X- _ O
bilstm -X- _ B-MethodName
models -X- _ O
can -X- _ O
outperform -X- _ O
crf -X- _ B-MethodName
models -X- _ O
when -X- _ O
there -X- _ O
is -X- _ O
sufÔ¨Åcient -X- _ O
training -X- _ O
data -X- _ O
to -X- _ O
proÔ¨Åt -X- _ O
from -X- _ O
distributed -X- _ O
representations -X- _ O
. -X- _ O

again -X- _ O
, -X- _ O
lower -X- _ O
f1 -X- _ B-MetricName
scores -X- _ O
are -X- _ O
achieved -X- _ O
using -X- _ O
the -X- _ O
europeana -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O

the -X- _ O
bilstm -X- _ B-MethodName
again -X- _ O
yields -X- _ O
the -X- _ O
signiÔ¨Åcantly -X- _ O
best -X- _ O
performance -X- _ O
, -X- _ O
matching -X- _ O
its -X- _ O
high -X- _ O
precision -X- _ B-MetricName
while -X- _ O
substantially -X- _ O
improving -X- _ O
recall -X- _ B-MetricName
. -X- _ O

on -X- _ O
the -X- _ B-DatasetName
conll -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
see -X- _ O
table -X- _ O
3 -X- _ O
) -X- _ O
germaner -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
currently -X- _ O
best -X- _ O
- -X- _ O
performing -X- _ O
rnnbased -X- _ B-MethodName
system -X- _ O
( -X- _ O
lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

using -X- _ O
europeana -X- _ B-MethodName
embeddings -X- _ I-MethodName
, -X- _ O
the -X- _ O
performance -X- _ O
drops -X- _ O
to -X- _ O
an -X- _ O
f1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
73.03 -X- _ B-MetricValue
‚Äì -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
vocabulary -X- _ O
. -X- _ O

our -X- _ O
bilstm -X- _ B-MethodName
with -X- _ O
wikipedia -X- _ B-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
, -X- _ O
scores -X- _ O
highest -X- _ O
( -X- _ O
79.99 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
outperforms -X- _ O
the -X- _ O
shared -X- _ O
7we -X- _ O
cleaned -X- _ O
the -X- _ O
corpora -X- _ O
by -X- _ O
correcting -X- _ O
named -X- _ O
entity -X- _ O
labels -X- _ O
and -X- _ O
tokenization -X- _ O
. -X- _ O

germaner -X- _ B-MethodName
achieves -X- _ O
high -X- _ O
precision -X- _ B-MetricName
, -X- _ O
but -X- _ O
can -X- _ O
not -X- _ O
compete -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
recall -X- _ B-MetricName
. -X- _ O

2015 -X- _ O
) -X- _ O
ensemble -X- _ O
classiÔ¨Åer -X- _ O
achieved -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
with -X- _ O
an -X- _ O
f1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
76.38 -X- _ B-MetricValue
, -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
rnn -X- _ B-MethodName
- -X- _ O
based -X- _ O
method -X- _ O
from -X- _ O
ukp -X- _ B-MethodName
( -X- _ O
reimers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

first -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
embeddings -X- _ O
computed -X- _ O
on -X- _ O
wikipedia -X- _ O
with -X- _ O
300 -X- _ O
dimensions -X- _ O
and -X- _ O
standard -X- _ O
parameters -X- _ O
( -X- _ O
wikiemb)8 -X- _ B-MethodName
, -X- _ O
which -X- _ O
are -X- _ O
presumably -X- _ O
more -X- _ O
appropriate -X- _ O
for -X- _ O
contemporary -X- _ O
texts -X- _ O
. -X- _ O

second -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
embeddings -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
parameters -X- _ O
from -X- _ O
1.5 -X- _ O
billion -X- _ O
tokens -X- _ O
of -X- _ O
historic -X- _ O
german -X- _ O
texts -X- _ O
from -X- _ O
europeana -X- _ B-MethodName
( -X- _ O
euroemb -X- _ B-MethodName
) -X- _ O
. -X- _ O

for -X- _ O
bilstm -X- _ B-MethodName
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
two -X- _ O
options -X- _ O
for -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

4 -X- _ O
experiment -X- _ O
1 -X- _ O
: -X- _ O
contemporary -X- _ O
german -X- _ O
in -X- _ O
our -X- _ O
Ô¨Årst -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
ner -X- _ B-TaskName
performances -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
contemporary -X- _ O
, -X- _ O
large -X- _ O
datasets -X- _ O
. -X- _ O

these -X- _ O
corpora -X- _ O
give -X- _ O
rise -X- _ O
to -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
challenges -X- _ O
: -X- _ O
they -X- _ O
are -X- _ O
considerably -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
contemporary -X- _ O
corpora -X- _ O
from -X- _ O
above -X- _ O
, -X- _ O
contain -X- _ O
a -X- _ O
different -X- _ O
language -X- _ O
variety -X- _ O
( -X- _ O
19th -X- _ O
century -X- _ O
austrian -X- _ O
german -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
include -X- _ O
a -X- _ O
high -X- _ O
rate -X- _ O
of -X- _ O
ocr -X- _ O
errors -X- _ O
since -X- _ O
they -X- _ O
were -X- _ O
originally -X- _ O
printed -X- _ O
in -X- _ O
gothic -X- _ O
typeface.7we -X- _ O
use -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
data -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
each -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
for -X- _ O
development -X- _ O
and -X- _ O
testing -X- _ O
. -X- _ O

our -X- _ O
second -X- _ O
corpus -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
austrian -X- _ B-DatasetName
newspaper -X- _ I-DatasetName
texts -X- _ I-DatasetName
from -X- _ I-DatasetName
the -X- _ I-DatasetName
austrian -X- _ I-DatasetName
national -X- _ I-DatasetName
library -X- _ I-DatasetName
( -X- _ O
onb -X- _ B-DatasetName
) -X- _ O
, -X- _ O
covering -X- _ O
some -X- _ O
35k -X- _ O
tokens -X- _ O
between -X- _ O
1710 -X- _ O
and -X- _ O
1873 -X- _ O
. -X- _ O

we -X- _ O
further -X- _ O
consider -X- _ O
two -X- _ O
datasets -X- _ O
based -X- _ O
on -X- _ O
historical -X- _ O
texts -X- _ O
( -X- _ O
neudecker -X- _ O
, -X- _ O
2016)5 -X- _ O
, -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
europeana -X- _ O
collection -X- _ O
of -X- _ O
historical -X- _ O
newspapers6 -X- _ O
, -X- _ O
a -X- _ O
standard -X- _ O
resource -X- _ O
for -X- _ O
historical -X- _ O
digital -X- _ O
humanities -X- _ O
. -X- _ O

to -X- _ O
be -X- _ O
more -X- _ O
conform -X- _ O
with -X- _ O
the -X- _ O
tagsets -X- _ O
of -X- _ O
the -X- _ O
conll -X- _ B-DatasetName
task -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
outer -X- _ O
spans -X- _ O
and -X- _ O
remove -X- _ O
the -X- _ O
Ô¨Åne -X- _ O
- -X- _ O
grained -X- _ O
tags -X- _ O
in -X- _ O
the -X- _ O
follow -X- _ O
- -X- _ O
up -X- _ O
experiments -X- _ O
( -X- _ O
see -X- _ O
section -X- _ O
5 -X- _ O
and -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O

as -X- _ O
there -X- _ O
are -X- _ O
only -X- _ O
few -X- _ O
inner -X- _ O
span -X- _ O
annotations -X- _ O
, -X- _ O
we -X- _ O
additionally -X- _ O
report -X- _ O
results -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
outer -X- _ O
spans -X- _ O
. -X- _ O

to -X- _ O
compare -X- _ O
to -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
ofÔ¨Åcial -X- _ O
metric -X- _ O
( -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
outer -X- _ O
and -X- _ O
inner -X- _ O
spans -X- _ O
) -X- _ O
in -X- _ O
section -X- _ O
4 -X- _ O
. -X- _ O

in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
standard -X- _ O
tagsets -X- _ O
also -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
conll -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
Ô¨Åne -X- _ O
grained -X- _ O
versions -X- _ O
of -X- _ O
these -X- _ O
entities -X- _ O
are -X- _ O
marked -X- _ O
with -X- _ O
sufÔ¨Åxes -X- _ O
: -X- _ O
-deriv -X- _ O
marks -X- _ O
derivations -X- _ O
of -X- _ O
the -X- _ O
named -X- _ O
entities -X- _ O
( -X- _ O
e.g. -X- _ O
german -X- _ O
actor -X- _ O
‚Äì -X- _ O
german -X- _ O
is -X- _ O
a -X- _ O
derived -X- _ O
location -X- _ O
) -X- _ O
and -X- _ O
-part -X- _ O
marks -X- _ O
compounds -X- _ O
including -X- _ O
a -X- _ O
named -X- _ O
entity -X- _ O
( -X- _ O
e.g. -X- _ O
in -X- _ O
the -X- _ O
word -X- _ O
rhineshore -X- _ O
the -X- _ O
compound -X- _ O
rhine -X- _ O
is -X- _ O
location -X- _ O
) -X- _ O
. -X- _ O

the -X- _ O
nested -X- _ O
term -X- _ O
chicago -X- _ O
is -X- _ O
annotated -X- _ O
as -X- _ O
location -X- _ O
in -X- _ O
the -X- _ O
inner -X- _ O
span -X- _ O
annotation -X- _ O
. -X- _ O

for -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
term -X- _ O
chicago -X- _ O
bulls -X- _ O
is -X- _ O
tagged -X- _ O
as -X- _ O
organization -X- _ O
in -X- _ O
the -X- _ O
outer -X- _ O
span -X- _ O
annotation -X- _ O
. -X- _ O

2014 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
consisting -X- _ O
of -X- _ O
some -X- _ O
450k -X- _ O
tokens -X- _ O
( -X- _ O
for -X- _ O
training -X- _ O
) -X- _ O
of -X- _ O
wikipedia -X- _ O
articles.4this -X- _ O
dataset -X- _ O
has -X- _ O
two -X- _ O
levels -X- _ O
of -X- _ O
annotations -X- _ O
: -X- _ O
outer -X- _ O
and -X- _ O
inner -X- _ O
span -X- _ O
named -X- _ O
entities -X- _ O
. -X- _ O

the -X- _ O
second -X- _ O
dataset -X- _ O
is -X- _ O
the -X- _ O
germeval -X- _ B-DatasetName
2014 -X- _ I-DatasetName
shared -X- _ O
task -X- _ O
dataset -X- _ O
( -X- _ O
germeval -X- _ O
, -X- _ O
benikova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O

the -X- _ O
tagset -X- _ O
handles -X- _ O
locations -X- _ O
( -X- _ O
loc -X- _ O
) -X- _ O
, -X- _ O
organizations -X- _ O
( -X- _ O
org -X- _ O
) -X- _ O
, -X- _ O
persons -X- _ O
( -X- _ O
per -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
remaining -X- _ O
entities -X- _ O
as -X- _ O
miscellaneous -X- _ O
( -X- _ O
misc -X- _ O
) -X- _ O
. -X- _ O

it -X- _ O
consists -X- _ O
of -X- _ O
about -X- _ O
220k -X- _ O
tokens -X- _ O
( -X- _ O
for -X- _ O
training -X- _ O
) -X- _ O
of -X- _ O
annotated -X- _ O
newspaper -X- _ O
documents -X- _ O
. -X- _ O

the -X- _ O
Ô¨Årst -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
german -X- _ O
ner -X- _ B-TaskName
dataset -X- _ O
was -X- _ O
published -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
conll -X- _ B-DatasetName
2003 -X- _ I-DatasetName
shared -X- _ O
task -X- _ O
( -X- _ O
conll -X- _ O
, -X- _ O
tjong -X- _ O
kim -X- _ O
sang -X- _ O
and -X- _ O
de -X- _ O
meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O

to -X- _ O
alleviate -X- _ O
issues -X- _ O
with -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
vocabulary -X- _ O
( -X- _ O
oov -X- _ O
) -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
both -X- _ O
character- -X- _ O
and -X- _ O
subwordbased -X- _ O
word -X- _ O
embeddings -X- _ O
computed -X- _ O
with -X- _ O
fasttext -X- _ O
( -X- _ O
bojanowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

we -X- _ O
train -X- _ O
the -X- _ O
character -X- _ O
embeddings -X- _ O
while -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
but -X- _ O
use -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
implementation -X- _ O
that -X- _ O
solely -X- _ O
uses -X- _ O
word -X- _ O
and -X- _ O
character -X- _ O
embeddings -X- _ O
. -X- _ O

among -X- _ O
the -X- _ O
various -X- _ O
deep -X- _ O
learning -X- _ O
architectures -X- _ O
applied -X- _ O
for -X- _ O
ner -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
have -X- _ O
been -X- _ O
achieved -X- _ O
with -X- _ O
bidirectional -X- _ B-MethodName
lstm -X- _ I-MethodName
methods -X- _ O
combined -X- _ O
with -X- _ O
a -X- _ O
top -X- _ O
- -X- _ O
level -X- _ O
crf -X- _ B-MethodName
model -X- _ O
( -X- _ O
ma -X- _ O
and -X- _ O
hovy -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

it -X- _ O
was -X- _ O
optimized -X- _ O
for -X- _ O
the -X- _ O
germeval -X- _ B-DatasetName
2014 -X- _ I-DatasetName
ner -X- _ B-TaskName
challenge -X- _ O
and -X- _ O
also -X- _ O
uses -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
standard -X- _ O
features -X- _ O
( -X- _ O
word -X- _ O
and -X- _ O
character -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
, -X- _ O
pos -X- _ O
) -X- _ O
supplemented -X- _ O
by -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
speciÔ¨Åc -X- _ O
information -X- _ O
sources -X- _ O
( -X- _ O
unsupervised -X- _ O
parts -X- _ O
of -X- _ O
speech -X- _ O
( -X- _ O
biemann -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
distributional -X- _ O
semantics -X- _ O
and -X- _ O
topic -X- _ O
cluster -X- _ O
information -X- _ O
, -X- _ O
gazetteer -X- _ O
lists -X- _ O
) -X- _ O
. -X- _ O

2015 -X- _ O
) -X- _ O
developed -X- _ O
germa -X- _ B-MethodName
ner2 -X- _ I-MethodName
, -X- _ O
another -X- _ O
crf -X- _ B-MethodName
- -X- _ O
based -X- _ O
ner -X- _ B-TaskName
system -X- _ O
. -X- _ O

the -X- _ O
ready -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
run -X- _ O
model -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
german -X- _ B-DatasetName
conll -X- _ I-DatasetName
2003 -X- _ I-DatasetName
data -X- _ O
( -X- _ O
tjong -X- _ O
kim -X- _ O
sang -X- _ O
and -X- _ O
de -X- _ O
meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O

for -X- _ O
german -X- _ O
, -X- _ O
these -X- _ O
features -X- _ O
are -X- _ O
complemented -X- _ O
by -X- _ O
distributional -X- _ O
clusters -X- _ O
computed -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
german -X- _ O
web -X- _ O
corpus -X- _ O
( -X- _ O
faruqui -X- _ O
and -X- _ O
pad -X- _ O
¬¥ -X- _ O
o -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O

it -X- _ O
uses -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
language -X- _ O
- -X- _ O
independent -X- _ O
features -X- _ O
, -X- _ O
including -X- _ O
word -X- _ O
and -X- _ O
character -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
, -X- _ O
word -X- _ O
shapes -X- _ O
, -X- _ O
surrounding -X- _ O
pos -X- _ O
and -X- _ O
lemmas -X- _ O
. -X- _ O

they -X- _ O
form -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
two -X- _ O
widely -X- _ O
used -X- _ O
named -X- _ O
entity -X- _ O
recognizers -X- _ O
. -X- _ O

linear -X- _ O
- -X- _ O
chain -X- _ O
crfs -X- _ B-MethodName
form -X- _ O
a -X- _ O
family -X- _ O
of -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
well -X- _ O
established -X- _ O
in -X- _ O
sequence -X- _ O
classiÔ¨Åcation -X- _ O
. -X- _ O

our -X- _ O
study -X- _ O
focuses -X- _ O
on -X- _ O
crfs -X- _ B-MethodName
and -X- _ O
bilstms -X- _ B-MethodName
, -X- _ O
the -X- _ O
two -X- _ O
most -X- _ O
widely -X- _ O
used -X- _ O
choices -X- _ O
. -X- _ O

the -X- _ O
Ô¨Ånal -X- _ O
bilstm -X- _ B-MethodName
models -X- _ O
form -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
german -X- _ O
ner -X- _ B-TaskName
and -X- _ O
are -X- _ O
freely -X- _ O
available.1212 -X- _ O
model -X- _ O
families -X- _ O
for -X- _ O
ner -X- _ B-TaskName
as -X- _ O
mentioned -X- _ O
above -X- _ O
, -X- _ O
contemporary -X- _ O
research -X- _ O
on -X- _ O
ner -X- _ B-TaskName
almost -X- _ O
exclusively -X- _ O
uses -X- _ O
sequence -X- _ O
classiÔ¨Åcation -X- _ O
models -X- _ O
. -X- _ O

due -X- _ O
to -X- _ O
these -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
the -X- _ O
following -X- _ O
results -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
bilstm -X- _ B-MethodName
system -X- _ O
indeed -X- _ O
performs -X- _ O
best -X- _ O
on -X- _ O
contemporary -X- _ O
corpora -X- _ O
, -X- _ O
both -X- _ O
within -X- _ O
and -X- _ O
across -X- _ O
domains -X- _ O
; -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
bilstm -X- _ O
system -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
crf -X- _ B-MethodName
systems -X- _ O
for -X- _ O
the -X- _ O
smallest -X- _ O
historical -X- _ O
corpus -X- _ O
due -X- _ O
to -X- _ O
lack -X- _ O
of -X- _ O
data -X- _ O
; -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
by -X- _ O
applying -X- _ O
transfer -X- _ O
learning -X- _ O
to -X- _ O
adduce -X- _ O
more -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
rnn -X- _ B-MethodName
outperform -X- _ O
crfs -X- _ B-MethodName
substantially -X- _ O
for -X- _ O
all -X- _ O
corpora -X- _ O
. -X- _ O

we -X- _ O
pit -X- _ O
linear -X- _ O
- -X- _ O
chain -X- _ O
crf- -X- _ B-MethodName
and -X- _ O
bilstm -X- _ B-MethodName
- -X- _ O
based -X- _ O
systems -X- _ O
against -X- _ O
each -X- _ O
other -X- _ O
and -X- _ O
compare -X- _ O
to -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
, -X- _ O
performing -X- _ O
three -X- _ O
experiments -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
investigates -X- _ O
this -X- _ O
question -X- _ O
empirically -X- _ O
on -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
german -X- _ O
corpora -X- _ O
including -X- _ O
two -X- _ O
large -X- _ O
, -X- _ O
contemporary -X- _ O
corpora -X- _ O
and -X- _ O
two -X- _ O
small -X- _ O
historical -X- _ O
corpora -X- _ O
. -X- _ O

thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
an -X- _ O
open -X- _ O
question -X- _ O
, -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
generally -X- _ O
a -X- _ O
better -X- _ O
idea -X- _ O
to -X- _ O
choose -X- _ O
different -X- _ O
model -X- _ O
families -X- _ O
for -X- _ O
different -X- _ O
settings -X- _ O
, -X- _ O
or -X- _ O
whether -X- _ O
one -X- _ O
model -X- _ O
family -X- _ O
can -X- _ O
be -X- _ O
optimized -X- _ O
to -X- _ O
perform -X- _ O
well -X- _ O
across -X- _ O
settings -X- _ O
. -X- _ O

this -X- _ O
consideration -X- _ O
becomes -X- _ O
particularly -X- _ O
pressing -X- _ O
when -X- _ O
moving -X- _ O
to -X- _ O
‚Äú -X- _ O
small -X- _ O
- -X- _ O
data -X- _ O
‚Äù -X- _ O
settings -X- _ O
such -X- _ O
as -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
, -X- _ O
speciÔ¨Åc -X- _ O
domains -X- _ O
, -X- _ O
or -X- _ O
historical -X- _ O
corpora -X- _ O
. -X- _ O

to -X- _ O
perform -X- _ O
representation -X- _ O
learning -X- _ O
, -X- _ O
bilstms -X- _ B-MethodName
require -X- _ O
considerably -X- _ O
annotated -X- _ O
data -X- _ O
to -X- _ O
learn -X- _ O
proper -X- _ O
representations -X- _ O
( -X- _ O
see -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
training -X- _ O
size -X- _ O
by -X- _ O
dernoncourt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

another -X- _ O
one -X- _ O
is -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
: -X- _ O
linearchain -X- _ O
crfs -X- _ B-MethodName
require -X- _ O
only -X- _ O
moderate -X- _ O
amounts -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
compared -X- _ O
to -X- _ O
bilstm -X- _ B-MethodName
. -X- _ O

when -X- _ O
developing -X- _ O
ner -X- _ B-TaskName
tools -X- _ O
for -X- _ O
new -X- _ O
types -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
one -X- _ O
requirement -X- _ O
is -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
different -X- _ O
resources -X- _ O
to -X- _ O
inform -X- _ O
features -X- _ O
and/or -X- _ O
embeddings -X- _ O
. -X- _ O

there -X- _ O
are -X- _ O
two -X- _ O
families -X- _ O
of -X- _ O
sequence -X- _ O
models -X- _ O
that -X- _ O
constitute -X- _ O
promising -X- _ O
candidates -X- _ O
. -X- _ O

the -X- _ O
two -X- _ O
best -X- _ O
- -X- _ O
performing -X- _ O
model -X- _ O
families -X- _ O
are -X- _ O
pitted -X- _ O
against -X- _ O
each -X- _ O
other -X- _ O
( -X- _ O
linear -X- _ O
- -X- _ O
chain -X- _ O
crfs -X- _ B-MethodName
and -X- _ O
bilstm -X- _ B-MethodName
) -X- _ O
to -X- _ O
observe -X- _ O
the -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
expressiveness -X- _ O
and -X- _ O
data -X- _ O
requirements -X- _ O
. -X- _ O

bilstms -X- _ B-MethodName
proÔ¨Åt -X- _ O
substantially -X- _ O
from -X- _ O
transfer -X- _ O
learning -X- _ O
, -X- _ O
which -X- _ O
enables -X- _ O
them -X- _ O
to -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
multiple -X- _ O
corpora -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
model -X- _ O
for -X- _ O
german -X- _ O
ner -X- _ B-TaskName
on -X- _ O
two -X- _ O
contemporary -X- _ O
german -X- _ O
corpora -X- _ O
( -X- _ O
conll -X- _ B-DatasetName
2003 -X- _ I-DatasetName
and -X- _ O
germeval -X- _ B-DatasetName
2014 -X- _ I-DatasetName
) -X- _ O
and -X- _ O
two -X- _ O
historic -X- _ O
corpora -X- _ O
. -X- _ O

on -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
linearchain -X- _ O
crfs -X- _ B-MethodName
, -X- _ O
which -X- _ O
form -X- _ O
the -X- _ O
basis -X- _ O
for -X- _ O
many -X- _ O
widely -X- _ O
used -X- _ O
systems -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
finkel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
bidirectional -X- _ B-MethodName
lstmss -X- _ B-MethodName
( -X- _ O
bilstms -X- _ B-MethodName
, -X- _ O
e.g. -X- _ O
, -X- _ O
reimers -X- _ O
and -X- _ O
gurevych -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
identifyinformative -X- _ O
features -X- _ O
directly -X- _ O
from -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
presented -X- _ O
as -X- _ O
word -X- _ O
and/or -X- _ O
character -X- _ O
embeddings -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

2015 -X- _ O
) -X- _ O
, -X- _ O
proÔ¨Åt -X- _ O
from -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
features -X- _ O
and -X- _ O
can -X- _ O
easily -X- _ O
incorporate -X- _ O
language- -X- _ O
and -X- _ O
domainspeciÔ¨Åc -X- _ O
knowledge -X- _ O
from -X- _ O
dictionaries -X- _ O
or -X- _ O
gazetteers -X- _ O
. -X- _ O

since -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
ner -X- _ B-TaskName
is -X- _ O
to -X- _ O
recognize -X- _ O
instances -X- _ O
of -X- _ O
named -X- _ O
entities -X- _ O
in -X- _ O
running -X- _ O
text -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
established -X- _ O
practice -X- _ O
to -X- _ O
treat -X- _ O
ner -X- _ B-TaskName
as -X- _ O
a -X- _ O
‚Äú -X- _ O
word -X- _ O
- -X- _ O
by -X- _ O
- -X- _ O
word -X- _ O
sequence -X- _ O
labeling -X- _ O
task -X- _ O
‚Äù -X- _ O
( -X- _ O
jurafsky -X- _ O
and -X- _ O
martin -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O

high -X- _ O
- -X- _ O
quality -X- _ O
ner -X- _ B-TaskName
is -X- _ O
crucial -X- _ O
for -X- _ O
applications -X- _ O
like -X- _ O
information -X- _ O
extraction -X- _ O
, -X- _ O
question -X- _ O
answering -X- _ O
, -X- _ O
or -X- _ O
entity -X- _ O
linking -X- _ O
. -X- _ O

1 -X- _ O
introduction -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
and -X- _ B-TaskName
classiÔ¨Åcation -X- _ I-TaskName
( -X- _ O
ner -X- _ B-TaskName
) -X- _ O
is -X- _ O
a -X- _ O
central -X- _ O
component -X- _ O
in -X- _ O
many -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
pipelines -X- _ O
. -X- _ O

bilstm -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
crf -X- _ B-MethodName
when -X- _ O
large -X- _ O
datasets -X- _ O
are -X- _ O
available -X- _ O
and -X- _ O
performs -X- _ O
inferior -X- _ O
for -X- _ O
the -X- _ O
smallest -X- _ O
dataset -X- _ O
. -X- _ O

