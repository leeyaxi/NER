2022-11-08 13:44:12.132237: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
11/08/2022 13:44:13 - Training/evaluation parameters ExTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
crf_learning_rate=0.005,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=50,
evaluation_strategy=IntervalStrategy.STEPS,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=models/role_gp/runs/Nov08_13-44-13_7135cc6fcf45,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=30,
optim=OptimizerNames.ADAMW_HF,
output_dir=models/role_gp,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=models/role_gp,
save_on_each_node=False,
save_steps=50,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=5,
seed=12,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/08/2022 13:44:14 - Tagging schema: BIO
Some weights of the model checkpoint at chem-pretrain/role were not used when initializing BertGlobalPointerForRoleLabeling: ['crf._constraint_mask', 'crf.end_transitions', 'crf.transitions', 'crf.start_transitions']
- This IS expected if you are initializing BertGlobalPointerForRoleLabeling from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertGlobalPointerForRoleLabeling from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertGlobalPointerForRoleLabeling were not initialized from the model checkpoint at chem-pretrain/role and are newly initialized: ['global_pointer.position_embedding.cos_position', 'global_pointer.position_embedding.sin_position', 'global_pointer.dense.bias', 'global_pointer.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertGlobalPointerForRoleLabeling were not initialized from the model checkpoint at chem-pretrain/role and are newly initialized because the shapes did not match:
- classifier.weight: found shape torch.Size([17, 2304]) in the checkpoint and torch.Size([9, 768]) in the model instantiated
- classifier.bias: found shape torch.Size([17]) in the checkpoint and torch.Size([9]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/08/2022 13:44:14 - Creating features from dataset file at tests/data/role/train.txt
11/08/2022 13:44:14 - Writing example 0 of 599
11/08/2022 13:44:14 - *** Example ***
11/08/2022 13:44:14 - guid: 1 (length: 71)
11/08/2022 13:44:14 - tokens: [CLS] As observed for the g ##ly ##cos ##yla ##tions of the 4 - OH accept ##or 7 , the use of e ##qui ##mo ##lar proportions of the donor 6 and the accept ##or 16 , in g ##ly ##cos ##yla ##tion reactions , led to the isolation of significant quantities of the g ##lu ##cal [Prod] 9 [/Prod] and low yields of the di ##sa ##cc ##hari ##des [SEP]
11/08/2022 13:44:14 - input_ids: 101 1249 4379 1111 1103 176 1193 13538 22948 6126 1104 1103 125 118 18719 4392 1766 128 117 1103 1329 1104 174 18276 3702 5815 21136 1104 1103 16667 127 1105 1103 4392 1766 1479 117 1107 176 1193 13538 22948 2116 9535 117 1521 1106 1103 13345 1104 2418 12709 1104 1103 176 7535 7867 28996 130 28997 1105 1822 17376 1104 1103 4267 3202 19515 16234 4704 102
11/08/2022 13:44:14 - label_ids: -100 0 0 0 0 0 -100 -100 -100 -100 0 0 0 -100 -100 0 -100 0 0 0 0 0 0 -100 -100 -100 0 0 0 0 0 0 0 0 -100 0 0 0 7 -100 -100 -100 -100 0 0 0 0 0 0 0 11 12 0 0 0 -100 -100 -100 -100 -100 0 0 0 0 0 0 -100 -100 -100 -100 -100
11/08/2022 13:44:14 - label_matrix: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
11/08/2022 13:44:14 - decoder_mask: False True True True True True False False False False True True True False False True False True True True True True True False False False True True True True True True True True False True True True True False False False False True True True True True True True True True True True True False False False False False True True True True True True False False False False False
11/08/2022 13:44:15 - Saving features into cached file tests/data/role/cached_train.txt_BertTokenizerFast_256
11/08/2022 13:44:31 - Creating features from dataset file at tests/data/role/dev.txt
11/08/2022 13:44:31 - Writing example 0 of 96
11/08/2022 13:44:31 - *** Example ***
11/08/2022 13:44:31 - guid: 1 (length: 89)
11/08/2022 13:44:31 - tokens: [CLS] In order to check this select ##ivity trend in other dip ##ero ##xy acids , we carried out reaction of ben ##zen ##e - 1 with he ##xa ##ne ##bis ( acid ) and do ##de ##cane ##bis ( acid ) ( with 6 and 12 carbon atoms , respectively ) , which also give 100 % conversion to [Prod] 2 - ni ##tro ##ani ##line [/Prod] with 90 % and 92 % isolated yields , respectively ( Table 4 , entries 7 and 8 ) . [SEP]
11/08/2022 13:44:31 - input_ids: 101 1130 1546 1106 4031 1142 8247 6366 10209 1107 1168 20866 10771 16844 13087 117 1195 2446 1149 3943 1104 26181 10947 1162 118 122 1114 1119 20192 1673 14866 113 5190 114 1105 1202 2007 27313 14866 113 5190 114 113 1114 127 1105 1367 6302 14296 117 3569 114 117 1134 1145 1660 1620 110 7497 1106 28996 123 118 11437 8005 7192 2568 28997 1114 3078 110 1105 5556 110 6841 17376 117 3569 113 11389 125 117 10813 128 1105 129 114 119 102
11/08/2022 13:44:31 - label_ids: -100 0 0 0 0 0 0 -100 0 0 0 0 -100 -100 0 0 0 0 0 0 0 1 -100 -100 -100 -100 0 1 -100 -100 -100 -100 2 2 0 1 -100 -100 -100 -100 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 0 11 12 0 11 12 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100
11/08/2022 13:44:31 - label_matrix: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
11/08/2022 13:44:31 - decoder_mask: False True True True True True True False True True True True False False True True True True True True True True False False False False True True False False False False True True True True False False False False True True True True True True True True True True True True True True True True True True True True False False False False False False False False True True True True True True True True True True True True True True True True True True True False False
11/08/2022 13:44:31 - Saving features into cached file tests/data/role/cached_dev.txt_BertTokenizerFast_256
***** Running training *****
  Num examples = 599
  Num Epochs = 30
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 570
  0%|          | 0/570 [00:00<?, ?it/s]  0%|          | 1/570 [00:02<19:49,  2.09s/it]  0%|          | 2/570 [00:04<19:45,  2.09s/it]  1%|          | 3/570 [00:06<19:47,  2.09s/it]  1%|          | 4/570 [00:08<19:37,  2.08s/it]  1%|          | 5/570 [00:10<19:30,  2.07s/it]  1%|          | 6/570 [00:12<19:27,  2.07s/it]  1%|          | 7/570 [00:14<19:42,  2.10s/it]  1%|â–         | 8/570 [00:16<19:39,  2.10s/it]  2%|â–         | 9/570 [00:18<19:30,  2.09s/it]  2%|â–         | 10/570 [00:20<19:28,  2.09s/it]  2%|â–         | 11/570 [00:23<19:38,  2.11s/it]  2%|â–         | 12/570 [00:25<19:35,  2.11s/it]  2%|â–         | 13/570 [00:27<19:24,  2.09s/it]  2%|â–         | 14/570 [00:29<19:19,  2.09s/it]  3%|â–Ž         | 15/570 [00:31<19:24,  2.10s/it]  3%|â–Ž         | 16/570 [00:33<19:17,  2.09s/it]  3%|â–Ž         | 17/570 [00:35<19:10,  2.08s/it]  3%|â–Ž         | 18/570 [00:37<19:07,  2.08s/it]  3%|â–Ž         | 19/570 [00:39<17:25,  1.90s/it]  4%|â–Ž         | 20/570 [00:41<17:52,  1.95s/it]  4%|â–Ž         | 21/570 [00:43<18:18,  2.00s/it]  4%|â–         | 22/570 [00:45<18:32,  2.03s/it]  4%|â–         | 23/570 [00:47<18:37,  2.04s/it]  4%|â–         | 24/570 [00:49<18:38,  2.05s/it]  4%|â–         | 25/570 [00:51<18:37,  2.05s/it]  5%|â–         | 26/570 [00:53<18:38,  2.06s/it]  5%|â–         | 27/570 [00:55<18:38,  2.06s/it]  5%|â–         | 28/570 [00:57<18:53,  2.09s/it]  5%|â–Œ         | 29/570 [00:59<18:44,  2.08s/it]  5%|â–Œ         | 30/570 [01:01<18:36,  2.07s/it]  5%|â–Œ         | 31/570 [01:04<18:35,  2.07s/it]  6%|â–Œ         | 32/570 [01:06<18:37,  2.08s/it]  6%|â–Œ         | 33/570 [01:08<18:32,  2.07s/it]  6%|â–Œ         | 34/570 [01:10<18:29,  2.07s/it]  6%|â–Œ         | 35/570 [01:12<18:31,  2.08s/it]  6%|â–‹         | 36/570 [01:14<18:35,  2.09s/it]  6%|â–‹         | 37/570 [01:16<18:29,  2.08s/it]  7%|â–‹         | 38/570 [01:17<16:52,  1.90s/it]  7%|â–‹         | 39/570 [01:20<17:15,  1.95s/it]  7%|â–‹         | 40/570 [01:22<17:38,  2.00s/it]  7%|â–‹         | 41/570 [01:24<17:45,  2.01s/it]  7%|â–‹         | 42/570 [01:26<17:51,  2.03s/it]  8%|â–Š         | 43/570 [01:28<17:54,  2.04s/it]  8%|â–Š         | 44/570 [01:30<18:02,  2.06s/it]  8%|â–Š         | 45/570 [01:32<18:00,  2.06s/it]  8%|â–Š         | 46/570 [01:34<17:59,  2.06s/it]  8%|â–Š         | 47/570 [01:36<17:56,  2.06s/it]  8%|â–Š         | 48/570 [01:38<18:01,  2.07s/it]  9%|â–Š         | 49/570 [01:40<17:56,  2.07s/it]  9%|â–‰         | 50/570 [01:42<17:51,  2.06s/it]11/08/2022 13:46:19 - ***** Running Evaluation *****
11/08/2022 13:46:19 -   Num examples = 96
11/08/2022 13:46:19 -   Batch size = 32

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.90s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.92s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.92s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.92s/it]
                                                  9%|â–‰         | 50/570 [01:49<17:51,  2.06s/it]Saving model checkpoint to models/role_gp/checkpoint-50
Configuration saved in models/role_gp/checkpoint-50/config.json
Model weights saved in models/role_gp/checkpoint-50/pytorch_model.bin
  9%|â–‰         | 51/570 [01:53<39:51,  4.61s/it]  9%|â–‰         | 52/570 [01:55<33:24,  3.87s/it]  9%|â–‰         | 53/570 [01:57<28:40,  3.33s/it]  9%|â–‰         | 54/570 [01:59<25:18,  2.94s/it] 10%|â–‰         | 55/570 [02:01<22:58,  2.68s/it] 10%|â–‰         | 56/570 [02:03<21:34,  2.52s/it] 10%|â–ˆ         | 57/570 [02:05<18:52,  2.21s/it] 10%|â–ˆ         | 58/570 [02:07<18:25,  2.16s/it] 10%|â–ˆ         | 59/570 [02:09<18:06,  2.13s/it] 11%|â–ˆ         | 60/570 [02:11<17:57,  2.11s/it] 11%|â–ˆ         | 61/570 [02:13<17:50,  2.10s/it] 11%|â–ˆ         | 62/570 [02:15<17:39,  2.09s/it] 11%|â–ˆ         | 63/570 [02:17<17:34,  2.08s/it] 11%|â–ˆ         | 64/570 [02:19<17:31,  2.08s/it] 11%|â–ˆâ–        | 65/570 [02:21<17:36,  2.09s/it] 12%|â–ˆâ–        | 66/570 [02:23<17:27,  2.08s/it] 12%|â–ˆâ–        | 67/570 [02:25<17:20,  2.07s/it] 12%|â–ˆâ–        | 68/570 [02:28<17:15,  2.06s/it] 12%|â–ˆâ–        | 69/570 [02:30<17:19,  2.08s/it] 12%|â–ˆâ–        | 70/570 [02:32<17:16,  2.07s/it] 12%|â–ˆâ–        | 71/570 [02:34<17:11,  2.07s/it] 13%|â–ˆâ–Ž        | 72/570 [02:36<17:07,  2.06s/it] 13%|â–ˆâ–Ž        | 73/570 [02:38<17:09,  2.07s/it] 13%|â–ˆâ–Ž        | 74/570 [02:40<17:02,  2.06s/it] 13%|â–ˆâ–Ž        | 75/570 [02:42<16:57,  2.06s/it] 13%|â–ˆâ–Ž        | 76/570 [02:43<15:29,  1.88s/it] 14%|â–ˆâ–Ž        | 77/570 [02:46<16:00,  1.95s/it] 14%|â–ˆâ–Ž        | 78/570 [02:48<16:14,  1.98s/it] 14%|â–ˆâ–        | 79/570 [02:50<16:24,  2.00s/it] 14%|â–ˆâ–        | 80/570 [02:52<16:28,  2.02s/it] 14%|â–ˆâ–        | 81/570 [02:54<16:37,  2.04s/it] 14%|â–ˆâ–        | 82/570 [02:56<16:35,  2.04s/it] 15%|â–ˆâ–        | 83/570 [02:58<16:35,  2.04s/it] 15%|â–ˆâ–        | 84/570 [03:00<16:34,  2.05s/it] 15%|â–ˆâ–        | 85/570 [03:02<16:45,  2.07s/it] 15%|â–ˆâ–Œ        | 86/570 [03:04<16:42,  2.07s/it] 15%|â–ˆâ–Œ        | 87/570 [03:06<16:38,  2.07s/it] 15%|â–ˆâ–Œ        | 88/570 [03:08<16:34,  2.06s/it] 16%|â–ˆâ–Œ        | 89/570 [03:10<16:37,  2.07s/it] 16%|â–ˆâ–Œ        | 90/570 [03:12<16:31,  2.07s/it] 16%|â–ˆâ–Œ        | 91/570 [03:14<16:26,  2.06s/it] 16%|â–ˆâ–Œ        | 92/570 [03:16<16:22,  2.05s/it] 16%|â–ˆâ–‹        | 93/570 [03:19<16:19,  2.05s/it] 16%|â–ˆâ–‹        | 94/570 [03:21<16:17,  2.05s/it] 17%|â–ˆâ–‹        | 95/570 [03:22<14:51,  1.88s/it] 17%|â–ˆâ–‹        | 96/570 [03:24<15:15,  1.93s/it] 17%|â–ˆâ–‹        | 97/570 [03:26<15:30,  1.97s/it] 17%|â–ˆâ–‹        | 98/570 [03:28<15:49,  2.01s/it] 17%|â–ˆâ–‹        | 99/570 [03:30<15:54,  2.03s/it] 18%|â–ˆâ–Š        | 100/570 [03:32<15:56,  2.03s/it]11/08/2022 13:48:09 - ***** Running Evaluation *****
11/08/2022 13:48:09 -   Num examples = 96
11/08/2022 13:48:09 -   Batch size = 32
{'eval_loss': 1.0996010303497314, 'eval_precision': 0.46987951807228917, 'eval_recall': 0.5, 'eval_f1': 0.484472049689441, 'epoch': 2.63}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.89s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.92s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it]
                                                  18%|â–ˆâ–Š        | 100/570 [03:39<15:56,  2.03s/it]Saving model checkpoint to models/role_gp/checkpoint-100
Configuration saved in models/role_gp/checkpoint-100/config.json
Model weights saved in models/role_gp/checkpoint-100/pytorch_model.bin
 18%|â–ˆâ–Š        | 101/570 [03:43<35:20,  4.52s/it] 18%|â–ˆâ–Š        | 102/570 [03:45<29:36,  3.80s/it] 18%|â–ˆâ–Š        | 103/570 [03:47<25:28,  3.27s/it] 18%|â–ˆâ–Š        | 104/570 [03:49<22:33,  2.90s/it] 18%|â–ˆâ–Š        | 105/570 [03:51<20:31,  2.65s/it] 19%|â–ˆâ–Š        | 106/570 [03:53<19:14,  2.49s/it] 19%|â–ˆâ–‰        | 107/570 [03:55<18:11,  2.36s/it] 19%|â–ˆâ–‰        | 108/570 [03:57<17:26,  2.26s/it] 19%|â–ˆâ–‰        | 109/570 [03:59<16:53,  2.20s/it] 19%|â–ˆâ–‰        | 110/570 [04:01<16:37,  2.17s/it] 19%|â–ˆâ–‰        | 111/570 [04:03<16:17,  2.13s/it] 20%|â–ˆâ–‰        | 112/570 [04:05<16:02,  2.10s/it] 20%|â–ˆâ–‰        | 113/570 [04:07<15:52,  2.08s/it] 20%|â–ˆâ–ˆ        | 114/570 [04:09<14:26,  1.90s/it] 20%|â–ˆâ–ˆ        | 115/570 [04:11<14:42,  1.94s/it] 20%|â–ˆâ–ˆ        | 116/570 [04:13<14:53,  1.97s/it] 21%|â–ˆâ–ˆ        | 117/570 [04:15<15:01,  1.99s/it] 21%|â–ˆâ–ˆ        | 118/570 [04:17<15:06,  2.01s/it] 21%|â–ˆâ–ˆ        | 119/570 [04:19<15:13,  2.03s/it] 21%|â–ˆâ–ˆ        | 120/570 [04:21<15:12,  2.03s/it] 21%|â–ˆâ–ˆ        | 121/570 [04:23<15:11,  2.03s/it] 21%|â–ˆâ–ˆâ–       | 122/570 [04:25<15:10,  2.03s/it] 22%|â–ˆâ–ˆâ–       | 123/570 [04:27<15:15,  2.05s/it] 22%|â–ˆâ–ˆâ–       | 124/570 [04:29<15:12,  2.04s/it] 22%|â–ˆâ–ˆâ–       | 125/570 [04:31<15:07,  2.04s/it] 22%|â–ˆâ–ˆâ–       | 126/570 [04:33<15:04,  2.04s/it] 22%|â–ˆâ–ˆâ–       | 127/570 [04:36<15:08,  2.05s/it] 22%|â–ˆâ–ˆâ–       | 128/570 [04:38<15:06,  2.05s/it] 23%|â–ˆâ–ˆâ–Ž       | 129/570 [04:40<15:01,  2.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 130/570 [04:42<14:59,  2.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 131/570 [04:44<15:03,  2.06s/it] 23%|â–ˆâ–ˆâ–Ž       | 132/570 [04:46<14:58,  2.05s/it] 23%|â–ˆâ–ˆâ–Ž       | 133/570 [04:47<13:40,  1.88s/it] 24%|â–ˆâ–ˆâ–Ž       | 134/570 [04:49<13:59,  1.93s/it] 24%|â–ˆâ–ˆâ–Ž       | 135/570 [04:51<14:19,  1.98s/it] 24%|â–ˆâ–ˆâ–       | 136/570 [04:53<14:23,  1.99s/it] 24%|â–ˆâ–ˆâ–       | 137/570 [04:55<14:26,  2.00s/it] 24%|â–ˆâ–ˆâ–       | 138/570 [04:57<14:29,  2.01s/it] 24%|â–ˆâ–ˆâ–       | 139/570 [05:00<14:31,  2.02s/it] 25%|â–ˆâ–ˆâ–       | 140/570 [05:02<14:32,  2.03s/it] 25%|â–ˆâ–ˆâ–       | 141/570 [05:04<14:32,  2.03s/it] 25%|â–ˆâ–ˆâ–       | 142/570 [05:06<14:30,  2.03s/it] 25%|â–ˆâ–ˆâ–Œ       | 143/570 [05:08<14:30,  2.04s/it] 25%|â–ˆâ–ˆâ–Œ       | 144/570 [05:10<14:30,  2.04s/it] 25%|â–ˆâ–ˆâ–Œ       | 145/570 [05:12<14:28,  2.04s/it] 26%|â–ˆâ–ˆâ–Œ       | 146/570 [05:14<14:24,  2.04s/it] 26%|â–ˆâ–ˆâ–Œ       | 147/570 [05:16<14:22,  2.04s/it] 26%|â–ˆâ–ˆâ–Œ       | 148/570 [05:18<14:27,  2.05s/it] 26%|â–ˆâ–ˆâ–Œ       | 149/570 [05:20<14:23,  2.05s/it] 26%|â–ˆâ–ˆâ–‹       | 150/570 [05:22<14:20,  2.05s/it]11/08/2022 13:49:58 - ***** Running Evaluation *****
11/08/2022 13:49:58 -   Num examples = 96
11/08/2022 13:49:58 -   Batch size = 32
{'eval_loss': 1.2886539697647095, 'eval_precision': 0.6161971830985915, 'eval_recall': 0.5608974358974359, 'eval_f1': 0.587248322147651, 'epoch': 5.26}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.90s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it]
                                                  26%|â–ˆâ–ˆâ–‹       | 150/570 [05:28<14:20,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-150
Configuration saved in models/role_gp/checkpoint-150/config.json
Model weights saved in models/role_gp/checkpoint-150/pytorch_model.bin
 26%|â–ˆâ–ˆâ–‹       | 151/570 [05:32<30:51,  4.42s/it] 27%|â–ˆâ–ˆâ–‹       | 152/570 [05:33<24:42,  3.55s/it] 27%|â–ˆâ–ˆâ–‹       | 153/570 [05:36<21:32,  3.10s/it] 27%|â–ˆâ–ˆâ–‹       | 154/570 [05:38<19:19,  2.79s/it] 27%|â–ˆâ–ˆâ–‹       | 155/570 [05:40<17:45,  2.57s/it] 27%|â–ˆâ–ˆâ–‹       | 156/570 [05:42<16:43,  2.42s/it] 28%|â–ˆâ–ˆâ–Š       | 157/570 [05:44<16:06,  2.34s/it] 28%|â–ˆâ–ˆâ–Š       | 158/570 [05:46<15:39,  2.28s/it] 28%|â–ˆâ–ˆâ–Š       | 159/570 [05:48<15:20,  2.24s/it] 28%|â–ˆâ–ˆâ–Š       | 160/570 [05:50<15:16,  2.23s/it] 28%|â–ˆâ–ˆâ–Š       | 161/570 [05:52<14:51,  2.18s/it] 28%|â–ˆâ–ˆâ–Š       | 162/570 [05:55<14:34,  2.14s/it] 29%|â–ˆâ–ˆâ–Š       | 163/570 [05:57<14:21,  2.12s/it] 29%|â–ˆâ–ˆâ–‰       | 164/570 [05:59<14:18,  2.11s/it] 29%|â–ˆâ–ˆâ–‰       | 165/570 [06:01<14:09,  2.10s/it] 29%|â–ˆâ–ˆâ–‰       | 166/570 [06:03<14:03,  2.09s/it] 29%|â–ˆâ–ˆâ–‰       | 167/570 [06:05<13:56,  2.08s/it] 29%|â–ˆâ–ˆâ–‰       | 168/570 [06:07<13:53,  2.07s/it] 30%|â–ˆâ–ˆâ–‰       | 169/570 [06:09<13:50,  2.07s/it] 30%|â–ˆâ–ˆâ–‰       | 170/570 [06:11<13:45,  2.06s/it] 30%|â–ˆâ–ˆâ–ˆ       | 171/570 [06:13<12:38,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 172/570 [06:15<12:55,  1.95s/it] 30%|â–ˆâ–ˆâ–ˆ       | 173/570 [06:17<13:11,  1.99s/it] 31%|â–ˆâ–ˆâ–ˆ       | 174/570 [06:19<13:16,  2.01s/it] 31%|â–ˆâ–ˆâ–ˆ       | 175/570 [06:21<13:19,  2.02s/it] 31%|â–ˆâ–ˆâ–ˆ       | 176/570 [06:23<13:20,  2.03s/it] 31%|â–ˆâ–ˆâ–ˆ       | 177/570 [06:25<13:26,  2.05s/it] 31%|â–ˆâ–ˆâ–ˆ       | 178/570 [06:27<13:27,  2.06s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 179/570 [06:29<13:24,  2.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 180/570 [06:31<13:22,  2.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 181/570 [06:33<13:25,  2.07s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 182/570 [06:35<13:22,  2.07s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 183/570 [06:37<13:19,  2.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 184/570 [06:39<13:15,  2.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 185/570 [06:42<13:18,  2.07s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 186/570 [06:44<13:14,  2.07s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 187/570 [06:46<13:10,  2.06s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 188/570 [06:48<13:07,  2.06s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 189/570 [06:50<13:09,  2.07s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 190/570 [06:51<11:59,  1.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 191/570 [06:53<12:15,  1.94s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 192/570 [06:55<12:26,  1.97s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 193/570 [06:57<12:36,  2.01s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 194/570 [06:59<12:38,  2.02s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 195/570 [07:02<12:40,  2.03s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 196/570 [07:04<12:41,  2.04s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 197/570 [07:06<12:42,  2.04s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 198/570 [07:08<12:41,  2.05s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 199/570 [07:10<12:39,  2.05s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 200/570 [07:12<12:39,  2.05s/it]11/08/2022 13:51:48 - ***** Running Evaluation *****
11/08/2022 13:51:48 -   Num examples = 96
11/08/2022 13:51:48 -   Batch size = 32
{'eval_loss': 1.412975549697876, 'eval_precision': 0.6464285714285715, 'eval_recall': 0.5801282051282052, 'eval_f1': 0.6114864864864865, 'epoch': 7.89}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.90s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.95s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.94s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.93s/it]
                                                  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 200/570 [07:18<12:39,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-200
Configuration saved in models/role_gp/checkpoint-200/config.json
Model weights saved in models/role_gp/checkpoint-200/pytorch_model.bin
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 201/570 [07:22<27:26,  4.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 202/570 [07:24<23:01,  3.75s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 203/570 [07:26<19:51,  3.25s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 204/570 [07:28<17:38,  2.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 205/570 [07:30<16:04,  2.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 206/570 [07:32<15:04,  2.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 207/570 [07:34<14:15,  2.36s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 208/570 [07:36<13:40,  2.27s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 209/570 [07:38<12:12,  2.03s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 210/570 [07:40<12:18,  2.05s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 211/570 [07:42<12:15,  2.05s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 212/570 [07:44<12:13,  2.05s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 213/570 [07:46<12:11,  2.05s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 214/570 [07:48<12:15,  2.06s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 215/570 [07:50<12:11,  2.06s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 216/570 [07:52<12:08,  2.06s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 217/570 [07:54<12:05,  2.05s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 218/570 [07:57<12:08,  2.07s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 219/570 [07:59<12:04,  2.07s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 220/570 [08:01<12:01,  2.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 221/570 [08:03<11:58,  2.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 222/570 [08:05<11:56,  2.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 223/570 [08:07<11:53,  2.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 224/570 [08:09<11:50,  2.05s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 225/570 [08:11<11:47,  2.05s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 226/570 [08:13<11:45,  2.05s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 227/570 [08:15<11:43,  2.05s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 228/570 [08:16<10:42,  1.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 229/570 [08:19<10:58,  1.93s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 230/570 [08:21<11:09,  1.97s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 231/570 [08:23<11:20,  2.01s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 232/570 [08:25<11:23,  2.02s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 233/570 [08:27<11:24,  2.03s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 234/570 [08:29<11:26,  2.04s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 235/570 [08:31<11:31,  2.07s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 236/570 [08:33<11:27,  2.06s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 237/570 [08:35<11:25,  2.06s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 238/570 [08:37<11:23,  2.06s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 239/570 [08:39<11:27,  2.08s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 240/570 [08:41<11:23,  2.07s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 241/570 [08:43<11:19,  2.07s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 242/570 [08:45<11:16,  2.06s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 243/570 [08:48<11:18,  2.07s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 244/570 [08:50<11:14,  2.07s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 245/570 [08:52<11:10,  2.06s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 246/570 [08:54<11:06,  2.06s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 247/570 [08:55<10:11,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 248/570 [08:57<10:25,  1.94s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 249/570 [08:59<10:36,  1.98s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/570 [09:01<10:40,  2.00s/it]11/08/2022 13:53:38 - ***** Running Evaluation *****
11/08/2022 13:53:38 -   Num examples = 96
11/08/2022 13:53:38 -   Batch size = 32
{'eval_loss': 1.4505313237508137, 'eval_precision': 0.5953757225433526, 'eval_recall': 0.6602564102564102, 'eval_f1': 0.6261398176291794, 'epoch': 10.53}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.90s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.90s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it]
                                                  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/570 [09:08<10:40,  2.00s/it]Saving model checkpoint to models/role_gp/checkpoint-250
Configuration saved in models/role_gp/checkpoint-250/config.json
Model weights saved in models/role_gp/checkpoint-250/pytorch_model.bin
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 251/570 [09:11<23:32,  4.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 252/570 [09:14<19:48,  3.74s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 253/570 [09:16<17:06,  3.24s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 254/570 [09:18<15:13,  2.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 255/570 [09:20<13:52,  2.64s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 256/570 [09:22<13:01,  2.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 257/570 [09:24<12:17,  2.36s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 258/570 [09:26<11:46,  2.26s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 259/570 [09:28<11:23,  2.20s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 260/570 [09:30<11:10,  2.16s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 261/570 [09:32<10:56,  2.13s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 262/570 [09:34<10:46,  2.10s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 263/570 [09:36<10:38,  2.08s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 264/570 [09:38<10:37,  2.08s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 265/570 [09:40<10:31,  2.07s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 266/570 [09:42<09:35,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 267/570 [09:44<09:47,  1.94s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 268/570 [09:46<09:59,  1.99s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 269/570 [09:48<10:03,  2.00s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 270/570 [09:50<10:04,  2.02s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 271/570 [09:52<10:05,  2.02s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 272/570 [09:54<10:08,  2.04s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 273/570 [09:56<10:05,  2.04s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 274/570 [09:58<10:03,  2.04s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 275/570 [10:00<10:02,  2.04s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 276/570 [10:02<10:00,  2.04s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 277/570 [10:04<09:58,  2.04s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 278/570 [10:06<09:56,  2.04s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 279/570 [10:09<09:55,  2.05s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 280/570 [10:11<09:54,  2.05s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 281/570 [10:13<09:52,  2.05s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 282/570 [10:15<09:52,  2.06s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 283/570 [10:17<09:51,  2.06s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 284/570 [10:19<09:51,  2.07s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 285/570 [10:20<09:02,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 286/570 [10:22<09:15,  1.96s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 287/570 [10:25<09:23,  1.99s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 288/570 [10:27<09:29,  2.02s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 289/570 [10:29<09:36,  2.05s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 290/570 [10:31<09:36,  2.06s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 291/570 [10:33<09:39,  2.08s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 292/570 [10:35<09:34,  2.07s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 293/570 [10:37<09:34,  2.07s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 294/570 [10:39<09:30,  2.07s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 295/570 [10:41<09:26,  2.06s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 296/570 [10:43<09:23,  2.06s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 297/570 [10:45<09:25,  2.07s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 298/570 [10:47<09:20,  2.06s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 299/570 [10:49<09:16,  2.05s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 300/570 [10:51<09:14,  2.05s/it]11/08/2022 13:55:28 - ***** Running Evaluation *****
11/08/2022 13:55:28 -   Num examples = 96
11/08/2022 13:55:28 -   Batch size = 32
{'eval_loss': 1.6322153806686401, 'eval_precision': 0.6190476190476191, 'eval_recall': 0.625, 'eval_f1': 0.6220095693779905, 'epoch': 13.16}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.93s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.90s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it]
                                                  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 300/570 [10:58<09:14,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-300
Configuration saved in models/role_gp/checkpoint-300/config.json
Model weights saved in models/role_gp/checkpoint-300/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-50] due to args.save_total_limit
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 301/570 [11:02<20:07,  4.49s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 302/570 [11:04<16:46,  3.76s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 303/570 [11:06<14:25,  3.24s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 304/570 [11:07<12:01,  2.71s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 305/570 [11:09<11:04,  2.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 306/570 [11:11<10:28,  2.38s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 307/570 [11:13<09:57,  2.27s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 308/570 [11:15<09:36,  2.20s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 309/570 [11:17<09:21,  2.15s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 310/570 [11:19<09:14,  2.13s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 311/570 [11:21<09:04,  2.10s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 312/570 [11:24<08:57,  2.08s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 313/570 [11:26<08:51,  2.07s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 314/570 [11:28<08:50,  2.07s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 315/570 [11:30<08:45,  2.06s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 316/570 [11:32<08:41,  2.05s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 317/570 [11:34<08:38,  2.05s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 318/570 [11:36<08:39,  2.06s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 319/570 [11:38<08:35,  2.05s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 320/570 [11:40<08:31,  2.05s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 321/570 [11:42<08:28,  2.04s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 322/570 [11:44<08:29,  2.05s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 323/570 [11:45<07:43,  1.88s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 324/570 [11:48<07:53,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 325/570 [11:50<07:58,  1.95s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 326/570 [11:52<08:03,  1.98s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 327/570 [11:54<08:05,  2.00s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 328/570 [11:56<08:06,  2.01s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 329/570 [11:58<08:06,  2.02s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 330/570 [12:00<08:05,  2.02s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 331/570 [12:02<08:07,  2.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 332/570 [12:04<08:05,  2.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 333/570 [12:06<08:03,  2.04s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 334/570 [12:08<08:01,  2.04s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 335/570 [12:10<08:02,  2.05s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 336/570 [12:12<07:59,  2.05s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 337/570 [12:14<07:56,  2.05s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 338/570 [12:16<07:55,  2.05s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 339/570 [12:18<07:56,  2.06s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 340/570 [12:20<07:52,  2.06s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 341/570 [12:22<07:50,  2.05s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 342/570 [12:24<07:08,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 343/570 [12:26<07:22,  1.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 344/570 [12:28<07:27,  1.98s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 345/570 [12:30<07:29,  2.00s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 346/570 [12:32<07:29,  2.01s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 347/570 [12:34<07:32,  2.03s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 348/570 [12:36<07:31,  2.03s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 349/570 [12:38<07:30,  2.04s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 350/570 [12:40<07:29,  2.04s/it]11/08/2022 13:57:16 - ***** Running Evaluation *****
11/08/2022 13:57:16 -   Num examples = 96
11/08/2022 13:57:16 -   Batch size = 32
{'eval_loss': 1.7166871229807537, 'eval_precision': 0.5958702064896755, 'eval_recall': 0.6474358974358975, 'eval_f1': 0.620583717357911, 'epoch': 15.79}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.89s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.88s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.87s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.87s/it]
                                                  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 350/570 [12:46<07:29,  2.04s/it]Saving model checkpoint to models/role_gp/checkpoint-350
Configuration saved in models/role_gp/checkpoint-350/config.json
Model weights saved in models/role_gp/checkpoint-350/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-100] due to args.save_total_limit
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 351/570 [12:50<16:16,  4.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 352/570 [12:52<13:36,  3.75s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 353/570 [12:54<11:42,  3.24s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 354/570 [12:57<10:22,  2.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 355/570 [12:59<09:25,  2.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 356/570 [13:01<08:48,  2.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 357/570 [13:03<08:18,  2.34s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 358/570 [13:05<07:57,  2.25s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 359/570 [13:07<07:41,  2.19s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 360/570 [13:09<07:33,  2.16s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 361/570 [13:10<06:49,  1.96s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 362/570 [13:12<06:52,  1.98s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 363/570 [13:14<06:53,  2.00s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 364/570 [13:17<06:56,  2.02s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 365/570 [13:19<06:55,  2.03s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 366/570 [13:21<06:54,  2.03s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 367/570 [13:23<06:52,  2.03s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 368/570 [13:25<06:53,  2.05s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 369/570 [13:27<06:50,  2.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 370/570 [13:29<06:48,  2.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 371/570 [13:31<06:46,  2.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 372/570 [13:33<06:46,  2.05s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 373/570 [13:35<06:44,  2.06s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 374/570 [13:37<06:42,  2.05s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 375/570 [13:39<06:39,  2.05s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 376/570 [13:41<06:38,  2.05s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 377/570 [13:43<06:36,  2.05s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 378/570 [13:45<06:34,  2.05s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 379/570 [13:47<06:31,  2.05s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 380/570 [13:49<05:57,  1.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 381/570 [13:51<06:08,  1.95s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 382/570 [13:53<06:12,  1.98s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 383/570 [13:55<06:14,  2.00s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 384/570 [13:57<06:14,  2.01s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 385/570 [13:59<06:17,  2.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 386/570 [14:01<06:16,  2.05s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 387/570 [14:03<06:13,  2.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 388/570 [14:05<06:12,  2.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 389/570 [14:07<06:12,  2.06s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 390/570 [14:09<06:10,  2.06s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 391/570 [14:11<06:07,  2.05s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 392/570 [14:14<06:05,  2.05s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 393/570 [14:16<06:06,  2.07s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 394/570 [14:18<06:02,  2.06s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 395/570 [14:20<05:59,  2.06s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 396/570 [14:22<05:57,  2.05s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 397/570 [14:24<05:57,  2.06s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 398/570 [14:26<05:54,  2.06s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 399/570 [14:27<05:22,  1.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 400/570 [14:29<05:28,  1.93s/it]11/08/2022 13:59:06 - ***** Running Evaluation *****
11/08/2022 13:59:06 -   Num examples = 96
11/08/2022 13:59:06 -   Batch size = 32
{'eval_loss': 1.6796355644861858, 'eval_precision': 0.638095238095238, 'eval_recall': 0.6442307692307693, 'eval_f1': 0.6411483253588517, 'epoch': 18.42}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.89s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.89s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.88s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it]
                                                  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 400/570 [14:36<05:28,  1.93s/it]Saving model checkpoint to models/role_gp/checkpoint-400
Configuration saved in models/role_gp/checkpoint-400/config.json
Model weights saved in models/role_gp/checkpoint-400/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-150] due to args.save_total_limit
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 401/570 [14:39<12:19,  4.38s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 402/570 [14:42<10:20,  3.69s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 403/570 [14:44<08:54,  3.20s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 404/570 [14:46<07:53,  2.85s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 405/570 [14:48<07:10,  2.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 406/570 [14:50<06:42,  2.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 407/570 [14:52<06:19,  2.33s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 408/570 [14:54<06:03,  2.25s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 409/570 [14:56<05:51,  2.18s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 410/570 [14:58<05:44,  2.15s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 411/570 [15:00<05:37,  2.12s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 412/570 [15:02<05:31,  2.10s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 413/570 [15:04<05:27,  2.09s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 414/570 [15:06<05:26,  2.09s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 415/570 [15:08<05:22,  2.08s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 416/570 [15:10<05:18,  2.07s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 417/570 [15:12<05:16,  2.07s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 418/570 [15:14<04:50,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 419/570 [15:16<04:56,  1.96s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 420/570 [15:18<04:59,  2.00s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 421/570 [15:20<05:00,  2.02s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 422/570 [15:22<05:02,  2.05s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 423/570 [15:25<05:10,  2.11s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 424/570 [15:27<05:14,  2.15s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 425/570 [15:29<05:14,  2.17s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 426/570 [15:31<05:13,  2.18s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 427/570 [15:33<05:05,  2.14s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 428/570 [15:35<04:59,  2.11s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 429/570 [15:37<04:54,  2.09s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 430/570 [15:39<04:52,  2.09s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 431/570 [15:42<04:48,  2.08s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 432/570 [15:44<04:45,  2.07s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 433/570 [15:46<04:42,  2.06s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 434/570 [15:48<04:42,  2.07s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 435/570 [15:50<04:38,  2.06s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 436/570 [15:52<04:35,  2.06s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 437/570 [15:53<04:10,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 438/570 [15:55<04:15,  1.93s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 439/570 [15:57<04:19,  1.98s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 440/570 [15:59<04:19,  2.00s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 441/570 [16:01<04:18,  2.01s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 442/570 [16:04<04:18,  2.02s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 443/570 [16:06<04:18,  2.04s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 444/570 [16:08<04:17,  2.04s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 445/570 [16:10<04:14,  2.04s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 446/570 [16:12<04:12,  2.04s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 447/570 [16:14<04:12,  2.06s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 448/570 [16:16<04:10,  2.05s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 449/570 [16:18<04:07,  2.05s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 450/570 [16:20<04:05,  2.05s/it]11/08/2022 14:00:56 - ***** Running Evaluation *****
11/08/2022 14:00:56 -   Num examples = 96
11/08/2022 14:00:56 -   Batch size = 32
{'eval_loss': 1.7936936219533284, 'eval_precision': 0.6403785488958991, 'eval_recall': 0.6506410256410257, 'eval_f1': 0.6454689984101749, 'epoch': 21.05}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.94s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.92s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.92s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.92s/it]
                                                  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 450/570 [16:26<04:05,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-450
Configuration saved in models/role_gp/checkpoint-450/config.json
Model weights saved in models/role_gp/checkpoint-450/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-200] due to args.save_total_limit
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 451/570 [16:30<08:57,  4.52s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 452/570 [16:32<07:25,  3.77s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 453/570 [16:34<06:20,  3.25s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 454/570 [16:36<05:35,  2.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 455/570 [16:38<05:04,  2.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 456/570 [16:40<04:22,  2.30s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 457/570 [16:42<04:11,  2.22s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 458/570 [16:44<04:02,  2.17s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 459/570 [16:46<03:56,  2.13s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 460/570 [16:48<03:51,  2.10s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 461/570 [16:50<03:46,  2.08s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 462/570 [16:52<03:43,  2.07s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 463/570 [16:54<03:40,  2.06s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 464/570 [16:56<03:39,  2.07s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 465/570 [16:58<03:36,  2.06s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 466/570 [17:00<03:33,  2.05s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 467/570 [17:02<03:30,  2.05s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 468/570 [17:04<03:29,  2.06s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 469/570 [17:07<03:27,  2.05s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 470/570 [17:09<03:25,  2.06s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 471/570 [17:11<03:23,  2.05s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 472/570 [17:13<03:22,  2.06s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 473/570 [17:15<03:19,  2.06s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 474/570 [17:17<03:16,  2.05s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 475/570 [17:18<02:58,  1.88s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 476/570 [17:20<03:02,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 477/570 [17:22<03:04,  1.98s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 478/570 [17:24<03:04,  2.00s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 479/570 [17:27<03:03,  2.01s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 480/570 [17:29<03:03,  2.04s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 481/570 [17:31<03:01,  2.04s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 482/570 [17:33<02:59,  2.04s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 483/570 [17:35<02:57,  2.04s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 484/570 [17:37<02:56,  2.05s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 485/570 [17:39<02:54,  2.05s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 486/570 [17:41<02:51,  2.05s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 487/570 [17:43<02:49,  2.05s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 488/570 [17:45<02:47,  2.05s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 489/570 [17:47<02:46,  2.05s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 490/570 [17:49<02:43,  2.05s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 491/570 [17:51<02:41,  2.05s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 492/570 [17:53<02:39,  2.05s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 493/570 [17:55<02:37,  2.05s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 494/570 [17:57<02:22,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 495/570 [17:59<02:24,  1.93s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 496/570 [18:01<02:25,  1.96s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 497/570 [18:03<02:26,  2.00s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 498/570 [18:05<02:24,  2.01s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 499/570 [18:07<02:23,  2.02s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 500/570 [18:09<02:21,  2.03s/it]                                                  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 500/570 [18:09<02:21,  2.03s/it]11/08/2022 14:02:45 - ***** Running Evaluation *****
11/08/2022 14:02:45 -   Num examples = 96
11/08/2022 14:02:45 -   Batch size = 32
{'eval_loss': 1.7749327023824055, 'eval_precision': 0.5988538681948424, 'eval_recall': 0.6698717948717948, 'eval_f1': 0.632375189107413, 'epoch': 23.68}
{'loss': 0.2661, 'learning_rate': 6.140350877192982e-06, 'epoch': 26.32}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.93s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.90s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it]
                                                  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 500/570 [18:15<02:21,  2.03s/it]Saving model checkpoint to models/role_gp/checkpoint-500
Configuration saved in models/role_gp/checkpoint-500/config.json
Model weights saved in models/role_gp/checkpoint-500/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-250] due to args.save_total_limit
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 501/570 [18:19<05:07,  4.45s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 502/570 [18:21<04:13,  3.73s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 503/570 [18:23<03:35,  3.22s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 504/570 [18:25<03:08,  2.86s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 505/570 [18:27<02:50,  2.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 506/570 [18:29<02:36,  2.45s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 507/570 [18:31<02:26,  2.32s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 508/570 [18:33<02:18,  2.24s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 509/570 [18:35<02:12,  2.17s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 510/570 [18:37<02:08,  2.14s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 511/570 [18:40<02:04,  2.11s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 512/570 [18:42<02:00,  2.08s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 513/570 [18:43<01:48,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 514/570 [18:45<01:49,  1.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 515/570 [18:47<01:48,  1.98s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 516/570 [18:49<01:47,  1.99s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 517/570 [18:51<01:46,  2.00s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 518/570 [18:53<01:45,  2.03s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 519/570 [18:55<01:43,  2.03s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 520/570 [18:57<01:41,  2.03s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 521/570 [18:59<01:39,  2.03s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 522/570 [19:01<01:38,  2.05s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 523/570 [19:04<01:35,  2.04s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 524/570 [19:06<01:33,  2.04s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 525/570 [19:08<01:31,  2.03s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 526/570 [19:10<01:30,  2.05s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 527/570 [19:12<01:28,  2.05s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 528/570 [19:14<01:25,  2.05s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 529/570 [19:16<01:23,  2.04s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 530/570 [19:18<01:22,  2.05s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 531/570 [19:20<01:19,  2.05s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 532/570 [19:21<01:11,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 533/570 [19:23<01:11,  1.92s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 534/570 [19:25<01:10,  1.96s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 535/570 [19:27<01:09,  1.99s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 536/570 [19:30<01:07,  2.00s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 537/570 [19:32<01:06,  2.01s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 538/570 [19:34<01:04,  2.01s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 539/570 [19:36<01:03,  2.04s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 540/570 [19:38<01:00,  2.03s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 541/570 [19:40<00:58,  2.03s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 542/570 [19:42<00:56,  2.03s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 543/570 [19:44<00:55,  2.04s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 544/570 [19:46<00:52,  2.04s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 545/570 [19:48<00:50,  2.03s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 546/570 [19:50<00:48,  2.03s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 547/570 [19:52<00:47,  2.05s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 548/570 [19:54<00:44,  2.04s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 549/570 [19:56<00:42,  2.04s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 550/570 [19:58<00:40,  2.03s/it]11/08/2022 14:04:34 - ***** Running Evaluation *****
11/08/2022 14:04:34 -   Num examples = 96
11/08/2022 14:04:34 -   Batch size = 32
{'eval_loss': 1.8584980567296345, 'eval_precision': 0.6369426751592356, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6389776357827476, 'epoch': 26.32}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.91s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.89s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it]
                                                  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 550/570 [20:04<00:40,  2.03s/it]Saving model checkpoint to models/role_gp/checkpoint-550
Configuration saved in models/role_gp/checkpoint-550/config.json
Model weights saved in models/role_gp/checkpoint-550/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-300] due to args.save_total_limit
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 551/570 [20:08<01:21,  4.29s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 552/570 [20:10<01:05,  3.63s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 553/570 [20:12<00:53,  3.14s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 554/570 [20:14<00:44,  2.81s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 555/570 [20:16<00:38,  2.57s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 556/570 [20:18<00:33,  2.42s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 557/570 [20:20<00:29,  2.30s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 558/570 [20:22<00:26,  2.22s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 559/570 [20:24<00:23,  2.16s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 560/570 [20:26<00:21,  2.14s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 561/570 [20:28<00:18,  2.11s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 562/570 [20:30<00:16,  2.08s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 563/570 [20:32<00:14,  2.07s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 564/570 [20:34<00:12,  2.07s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 565/570 [20:36<00:10,  2.06s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 566/570 [20:38<00:08,  2.05s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 567/570 [20:40<00:06,  2.04s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 568/570 [20:42<00:04,  2.05s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 569/570 [20:44<00:02,  2.04s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [20:46<00:00,  1.87s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [20:46<00:00,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [20:46<00:00,  2.19s/it]
***** Running training *****
  Num examples = 599
  Num Epochs = 30
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 570
{'eval_loss': 1.8740636110305786, 'eval_precision': 0.6483870967741936, 'eval_recall': 0.6442307692307693, 'eval_f1': 0.6463022508038585, 'epoch': 28.95}
{'train_runtime': 1246.2835, 'train_samples_per_second': 14.419, 'train_steps_per_second': 0.457, 'train_loss': 0.23614103647700527, 'epoch': 30.0}
  0%|          | 0/570 [00:00<?, ?it/s]  0%|          | 1/570 [00:02<19:17,  2.03s/it]  0%|          | 2/570 [00:04<19:13,  2.03s/it]  1%|          | 3/570 [00:06<19:14,  2.04s/it]  1%|          | 4/570 [00:08<19:07,  2.03s/it]  1%|          | 5/570 [00:10<19:06,  2.03s/it]  1%|          | 6/570 [00:12<19:05,  2.03s/it]  1%|          | 7/570 [00:14<19:14,  2.05s/it]  1%|â–         | 8/570 [00:16<19:11,  2.05s/it]  2%|â–         | 9/570 [00:18<19:04,  2.04s/it]  2%|â–         | 10/570 [00:20<19:00,  2.04s/it]  2%|â–         | 11/570 [00:22<19:04,  2.05s/it]  2%|â–         | 12/570 [00:24<18:59,  2.04s/it]  2%|â–         | 13/570 [00:26<18:56,  2.04s/it]  2%|â–         | 14/570 [00:28<18:58,  2.05s/it]  3%|â–Ž         | 15/570 [00:30<19:01,  2.06s/it]  3%|â–Ž         | 16/570 [00:32<18:58,  2.05s/it]  3%|â–Ž         | 17/570 [00:34<18:52,  2.05s/it]  3%|â–Ž         | 18/570 [00:36<18:47,  2.04s/it]  3%|â–Ž         | 19/570 [00:38<17:23,  1.89s/it]  4%|â–Ž         | 20/570 [00:40<17:47,  1.94s/it]  4%|â–Ž         | 21/570 [00:42<18:02,  1.97s/it]  4%|â–         | 22/570 [00:44<18:12,  1.99s/it]  4%|â–         | 23/570 [00:46<18:22,  2.02s/it]  4%|â–         | 24/570 [00:48<18:24,  2.02s/it]  4%|â–         | 25/570 [00:50<18:27,  2.03s/it]  5%|â–         | 26/570 [00:52<18:27,  2.04s/it]  5%|â–         | 27/570 [00:54<18:26,  2.04s/it]  5%|â–         | 28/570 [00:56<18:25,  2.04s/it]  5%|â–Œ         | 29/570 [00:58<18:25,  2.04s/it]  5%|â–Œ         | 30/570 [01:00<18:24,  2.05s/it]  5%|â–Œ         | 31/570 [01:02<18:23,  2.05s/it]  6%|â–Œ         | 32/570 [01:04<18:26,  2.06s/it]  6%|â–Œ         | 33/570 [01:07<18:21,  2.05s/it]  6%|â–Œ         | 34/570 [01:09<18:17,  2.05s/it]  6%|â–Œ         | 35/570 [01:11<18:15,  2.05s/it]  6%|â–‹         | 36/570 [01:13<18:20,  2.06s/it]  6%|â–‹         | 37/570 [01:15<18:16,  2.06s/it]  7%|â–‹         | 38/570 [01:16<16:47,  1.89s/it]  7%|â–‹         | 39/570 [01:18<17:10,  1.94s/it]  7%|â–‹         | 40/570 [01:20<17:34,  1.99s/it]  7%|â–‹         | 41/570 [01:22<17:41,  2.01s/it]  7%|â–‹         | 42/570 [01:24<17:44,  2.02s/it]  8%|â–Š         | 43/570 [01:27<17:46,  2.02s/it]  8%|â–Š         | 44/570 [01:29<17:56,  2.05s/it]  8%|â–Š         | 45/570 [01:31<17:56,  2.05s/it]  8%|â–Š         | 46/570 [01:33<17:55,  2.05s/it]  8%|â–Š         | 47/570 [01:35<17:52,  2.05s/it]  8%|â–Š         | 48/570 [01:37<17:57,  2.06s/it]  9%|â–Š         | 49/570 [01:39<17:52,  2.06s/it]  9%|â–‰         | 50/570 [01:41<17:49,  2.06s/it]11/08/2022 14:07:04 - ***** Running Evaluation *****
11/08/2022 14:07:04 -   Num examples = 96
11/08/2022 14:07:04 -   Batch size = 32

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.92s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.94s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.93s/it]
                                                  9%|â–‰         | 50/570 [01:47<17:49,  2.06s/it]Saving model checkpoint to models/role_gp/checkpoint-50
Configuration saved in models/role_gp/checkpoint-50/config.json
Model weights saved in models/role_gp/checkpoint-50/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-350] due to args.save_total_limit
  9%|â–‰         | 51/570 [01:51<39:29,  4.57s/it]  9%|â–‰         | 52/570 [01:54<33:11,  3.84s/it]  9%|â–‰         | 53/570 [01:56<28:43,  3.33s/it]  9%|â–‰         | 54/570 [01:58<25:34,  2.97s/it] 10%|â–‰         | 55/570 [02:00<23:21,  2.72s/it] 10%|â–‰         | 56/570 [02:02<21:54,  2.56s/it] 10%|â–ˆ         | 57/570 [02:04<19:20,  2.26s/it] 10%|â–ˆ         | 58/570 [02:06<18:57,  2.22s/it] 10%|â–ˆ         | 59/570 [02:08<18:41,  2.19s/it] 11%|â–ˆ         | 60/570 [02:10<18:34,  2.18s/it] 11%|â–ˆ         | 61/570 [02:12<18:25,  2.17s/it] 11%|â–ˆ         | 62/570 [02:14<18:18,  2.16s/it] 11%|â–ˆ         | 63/570 [02:17<18:14,  2.16s/it] 11%|â–ˆ         | 64/570 [02:19<18:15,  2.16s/it] 11%|â–ˆâ–        | 65/570 [02:21<18:09,  2.16s/it] 12%|â–ˆâ–        | 66/570 [02:23<18:05,  2.15s/it] 12%|â–ˆâ–        | 67/570 [02:25<18:02,  2.15s/it] 12%|â–ˆâ–        | 68/570 [02:27<18:04,  2.16s/it] 12%|â–ˆâ–        | 69/570 [02:30<17:59,  2.15s/it] 12%|â–ˆâ–        | 70/570 [02:32<17:55,  2.15s/it] 12%|â–ˆâ–        | 71/570 [02:34<17:53,  2.15s/it] 13%|â–ˆâ–Ž        | 72/570 [02:36<17:55,  2.16s/it] 13%|â–ˆâ–Ž        | 73/570 [02:38<17:50,  2.15s/it] 13%|â–ˆâ–Ž        | 74/570 [02:40<17:46,  2.15s/it] 13%|â–ˆâ–Ž        | 75/570 [02:42<17:44,  2.15s/it] 13%|â–ˆâ–Ž        | 76/570 [02:44<16:20,  1.98s/it] 14%|â–ˆâ–Ž        | 77/570 [02:46<16:40,  2.03s/it] 14%|â–ˆâ–Ž        | 78/570 [02:48<16:54,  2.06s/it] 14%|â–ˆâ–        | 79/570 [02:50<17:02,  2.08s/it] 14%|â–ˆâ–        | 80/570 [02:53<17:14,  2.11s/it] 14%|â–ˆâ–        | 81/570 [02:55<17:17,  2.12s/it] 14%|â–ˆâ–        | 82/570 [02:57<17:18,  2.13s/it] 15%|â–ˆâ–        | 83/570 [02:59<17:17,  2.13s/it] 15%|â–ˆâ–        | 84/570 [03:01<17:22,  2.15s/it] 15%|â–ˆâ–        | 85/570 [03:03<17:19,  2.14s/it] 15%|â–ˆâ–Œ        | 86/570 [03:05<17:16,  2.14s/it] 15%|â–ˆâ–Œ        | 87/570 [03:08<17:14,  2.14s/it] 15%|â–ˆâ–Œ        | 88/570 [03:10<17:17,  2.15s/it] 16%|â–ˆâ–Œ        | 89/570 [03:12<17:13,  2.15s/it] 16%|â–ˆâ–Œ        | 90/570 [03:14<17:10,  2.15s/it] 16%|â–ˆâ–Œ        | 91/570 [03:16<17:09,  2.15s/it] 16%|â–ˆâ–Œ        | 92/570 [03:18<17:12,  2.16s/it] 16%|â–ˆâ–‹        | 93/570 [03:21<17:08,  2.16s/it] 16%|â–ˆâ–‹        | 94/570 [03:23<17:05,  2.15s/it] 17%|â–ˆâ–‹        | 95/570 [03:24<15:37,  1.97s/it] 17%|â–ˆâ–‹        | 96/570 [03:26<16:07,  2.04s/it] 17%|â–ˆâ–‹        | 97/570 [03:29<16:18,  2.07s/it] 17%|â–ˆâ–‹        | 98/570 [03:31<16:26,  2.09s/it] 17%|â–ˆâ–‹        | 99/570 [03:33<16:27,  2.10s/it] 18%|â–ˆâ–Š        | 100/570 [03:35<16:28,  2.10s/it]11/08/2022 14:08:58 - ***** Running Evaluation *****
11/08/2022 14:08:58 -   Num examples = 96
11/08/2022 14:08:58 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 2.63}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.88s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.88s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.88s/it]
                                                  18%|â–ˆâ–Š        | 100/570 [03:41<16:28,  2.10s/it]Saving model checkpoint to models/role_gp/checkpoint-100
Configuration saved in models/role_gp/checkpoint-100/config.json
Model weights saved in models/role_gp/checkpoint-100/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-400] due to args.save_total_limit
 18%|â–ˆâ–Š        | 101/570 [03:45<35:21,  4.52s/it] 18%|â–ˆâ–Š        | 102/570 [03:47<29:29,  3.78s/it] 18%|â–ˆâ–Š        | 103/570 [03:49<25:22,  3.26s/it] 18%|â–ˆâ–Š        | 104/570 [03:51<22:37,  2.91s/it] 18%|â–ˆâ–Š        | 105/570 [03:53<20:34,  2.66s/it] 19%|â–ˆâ–Š        | 106/570 [03:55<19:04,  2.47s/it] 19%|â–ˆâ–‰        | 107/570 [03:57<18:02,  2.34s/it] 19%|â–ˆâ–‰        | 108/570 [04:00<17:25,  2.26s/it] 19%|â–ˆâ–‰        | 109/570 [04:02<16:51,  2.19s/it] 19%|â–ˆâ–‰        | 110/570 [04:04<16:27,  2.15s/it] 19%|â–ˆâ–‰        | 111/570 [04:06<16:09,  2.11s/it] 20%|â–ˆâ–‰        | 112/570 [04:08<15:57,  2.09s/it] 20%|â–ˆâ–‰        | 113/570 [04:10<15:49,  2.08s/it] 20%|â–ˆâ–ˆ        | 114/570 [04:11<14:26,  1.90s/it] 20%|â–ˆâ–ˆ        | 115/570 [04:13<14:44,  1.94s/it] 20%|â–ˆâ–ˆ        | 116/570 [04:15<14:56,  1.97s/it] 21%|â–ˆâ–ˆ        | 117/570 [04:17<15:10,  2.01s/it] 21%|â–ˆâ–ˆ        | 118/570 [04:19<15:12,  2.02s/it] 21%|â–ˆâ–ˆ        | 119/570 [04:22<15:14,  2.03s/it] 21%|â–ˆâ–ˆ        | 120/570 [04:24<15:14,  2.03s/it] 21%|â–ˆâ–ˆ        | 121/570 [04:26<15:20,  2.05s/it] 21%|â–ˆâ–ˆâ–       | 122/570 [04:28<15:17,  2.05s/it] 22%|â–ˆâ–ˆâ–       | 123/570 [04:30<15:15,  2.05s/it] 22%|â–ˆâ–ˆâ–       | 124/570 [04:32<15:12,  2.04s/it] 22%|â–ˆâ–ˆâ–       | 125/570 [04:34<15:16,  2.06s/it] 22%|â–ˆâ–ˆâ–       | 126/570 [04:36<15:12,  2.05s/it] 22%|â–ˆâ–ˆâ–       | 127/570 [04:38<15:08,  2.05s/it] 22%|â–ˆâ–ˆâ–       | 128/570 [04:40<15:04,  2.05s/it] 23%|â–ˆâ–ˆâ–Ž       | 129/570 [04:42<15:08,  2.06s/it] 23%|â–ˆâ–ˆâ–Ž       | 130/570 [04:44<15:03,  2.05s/it] 23%|â–ˆâ–ˆâ–Ž       | 131/570 [04:46<14:59,  2.05s/it] 23%|â–ˆâ–ˆâ–Ž       | 132/570 [04:48<14:56,  2.05s/it] 23%|â–ˆâ–ˆâ–Ž       | 133/570 [04:50<13:40,  1.88s/it] 24%|â–ˆâ–ˆâ–Ž       | 134/570 [04:52<14:00,  1.93s/it] 24%|â–ˆâ–ˆâ–Ž       | 135/570 [04:54<14:13,  1.96s/it] 24%|â–ˆâ–ˆâ–       | 136/570 [04:56<14:22,  1.99s/it] 24%|â–ˆâ–ˆâ–       | 137/570 [04:58<14:29,  2.01s/it] 24%|â–ˆâ–ˆâ–       | 138/570 [05:00<14:36,  2.03s/it] 24%|â–ˆâ–ˆâ–       | 139/570 [05:02<14:36,  2.03s/it] 25%|â–ˆâ–ˆâ–       | 140/570 [05:04<14:34,  2.03s/it] 25%|â–ˆâ–ˆâ–       | 141/570 [05:06<14:33,  2.04s/it] 25%|â–ˆâ–ˆâ–       | 142/570 [05:08<14:36,  2.05s/it] 25%|â–ˆâ–ˆâ–Œ       | 143/570 [05:10<14:32,  2.04s/it] 25%|â–ˆâ–ˆâ–Œ       | 144/570 [05:12<14:30,  2.04s/it] 25%|â–ˆâ–ˆâ–Œ       | 145/570 [05:14<14:28,  2.04s/it] 26%|â–ˆâ–ˆâ–Œ       | 146/570 [05:16<14:34,  2.06s/it] 26%|â–ˆâ–ˆâ–Œ       | 147/570 [05:18<14:30,  2.06s/it] 26%|â–ˆâ–ˆâ–Œ       | 148/570 [05:20<14:27,  2.05s/it] 26%|â–ˆâ–ˆâ–Œ       | 149/570 [05:23<14:23,  2.05s/it] 26%|â–ˆâ–ˆâ–‹       | 150/570 [05:25<14:26,  2.06s/it]11/08/2022 14:10:47 - ***** Running Evaluation *****
11/08/2022 14:10:47 -   Num examples = 96
11/08/2022 14:10:47 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 5.26}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.89s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.89s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it]
                                                  26%|â–ˆâ–ˆâ–‹       | 150/570 [05:31<14:26,  2.06s/it]Saving model checkpoint to models/role_gp/checkpoint-150
Configuration saved in models/role_gp/checkpoint-150/config.json
Model weights saved in models/role_gp/checkpoint-150/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-450] due to args.save_total_limit
 26%|â–ˆâ–ˆâ–‹       | 151/570 [05:35<31:19,  4.49s/it] 27%|â–ˆâ–ˆâ–‹       | 152/570 [05:36<24:59,  3.59s/it] 27%|â–ˆâ–ˆâ–‹       | 153/570 [05:38<21:42,  3.12s/it] 27%|â–ˆâ–ˆâ–‹       | 154/570 [05:40<19:30,  2.81s/it] 27%|â–ˆâ–ˆâ–‹       | 155/570 [05:42<17:51,  2.58s/it] 27%|â–ˆâ–ˆâ–‹       | 156/570 [05:44<16:42,  2.42s/it] 28%|â–ˆâ–ˆâ–Š       | 157/570 [05:46<15:53,  2.31s/it] 28%|â–ˆâ–ˆâ–Š       | 158/570 [05:49<15:19,  2.23s/it] 28%|â–ˆâ–ˆâ–Š       | 159/570 [05:51<14:54,  2.18s/it] 28%|â–ˆâ–ˆâ–Š       | 160/570 [05:53<14:36,  2.14s/it] 28%|â–ˆâ–ˆâ–Š       | 161/570 [05:55<14:23,  2.11s/it] 28%|â–ˆâ–ˆâ–Š       | 162/570 [05:57<14:13,  2.09s/it] 29%|â–ˆâ–ˆâ–Š       | 163/570 [05:59<14:06,  2.08s/it] 29%|â–ˆâ–ˆâ–‰       | 164/570 [06:01<14:00,  2.07s/it] 29%|â–ˆâ–ˆâ–‰       | 165/570 [06:03<13:55,  2.06s/it] 29%|â–ˆâ–ˆâ–‰       | 166/570 [06:05<13:51,  2.06s/it] 29%|â–ˆâ–ˆâ–‰       | 167/570 [06:07<14:16,  2.13s/it] 29%|â–ˆâ–ˆâ–‰       | 168/570 [06:09<14:25,  2.15s/it] 30%|â–ˆâ–ˆâ–‰       | 169/570 [06:12<14:33,  2.18s/it] 30%|â–ˆâ–ˆâ–‰       | 170/570 [06:14<14:35,  2.19s/it] 30%|â–ˆâ–ˆâ–ˆ       | 171/570 [06:15<13:09,  1.98s/it] 30%|â–ˆâ–ˆâ–ˆ       | 172/570 [06:17<13:15,  2.00s/it] 30%|â–ˆâ–ˆâ–ˆ       | 173/570 [06:19<13:19,  2.01s/it] 31%|â–ˆâ–ˆâ–ˆ       | 174/570 [06:21<13:20,  2.02s/it] 31%|â–ˆâ–ˆâ–ˆ       | 175/570 [06:24<13:26,  2.04s/it] 31%|â–ˆâ–ˆâ–ˆ       | 176/570 [06:26<13:25,  2.04s/it] 31%|â–ˆâ–ˆâ–ˆ       | 177/570 [06:28<13:23,  2.05s/it] 31%|â–ˆâ–ˆâ–ˆ       | 178/570 [06:30<13:21,  2.05s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 179/570 [06:32<13:26,  2.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 180/570 [06:34<13:22,  2.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 181/570 [06:36<13:17,  2.05s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 182/570 [06:38<13:13,  2.05s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 183/570 [06:40<13:16,  2.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 184/570 [06:42<13:12,  2.05s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 185/570 [06:44<13:08,  2.05s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 186/570 [06:46<13:05,  2.05s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 187/570 [06:48<13:09,  2.06s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 188/570 [06:50<13:05,  2.06s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 189/570 [06:52<13:01,  2.05s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 190/570 [06:54<11:53,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 191/570 [06:56<12:11,  1.93s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 192/570 [06:58<12:23,  1.97s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 193/570 [07:00<12:33,  2.00s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 194/570 [07:02<12:38,  2.02s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 195/570 [07:04<12:41,  2.03s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 196/570 [07:06<12:50,  2.06s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 197/570 [07:08<12:56,  2.08s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 198/570 [07:11<13:04,  2.11s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 199/570 [07:13<13:10,  2.13s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 200/570 [07:15<13:10,  2.14s/it]11/08/2022 14:12:37 - ***** Running Evaluation *****
11/08/2022 14:12:37 -   Num examples = 96
11/08/2022 14:12:37 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 7.89}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.97s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.97s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.93s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.94s/it]
                                                  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 200/570 [07:21<13:10,  2.14s/it]Saving model checkpoint to models/role_gp/checkpoint-200
Configuration saved in models/role_gp/checkpoint-200/config.json
Model weights saved in models/role_gp/checkpoint-200/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-500] due to args.save_total_limit
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 201/570 [07:25<28:05,  4.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 202/570 [07:27<23:22,  3.81s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 203/570 [07:29<20:04,  3.28s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 204/570 [07:31<17:46,  2.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 205/570 [07:33<16:12,  2.66s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 206/570 [07:35<15:03,  2.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 207/570 [07:37<14:13,  2.35s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 208/570 [07:40<13:43,  2.27s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 209/570 [07:41<12:15,  2.04s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 210/570 [07:43<12:13,  2.04s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 211/570 [07:45<12:12,  2.04s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 212/570 [07:47<12:16,  2.06s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 213/570 [07:49<12:12,  2.05s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 214/570 [07:51<12:09,  2.05s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 215/570 [07:53<12:06,  2.05s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 216/570 [07:55<12:09,  2.06s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 217/570 [07:57<12:05,  2.05s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 218/570 [07:59<12:01,  2.05s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 219/570 [08:02<11:59,  2.05s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 220/570 [08:04<12:02,  2.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 221/570 [08:06<11:59,  2.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 222/570 [08:08<11:54,  2.05s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 223/570 [08:10<11:51,  2.05s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 224/570 [08:12<11:53,  2.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 225/570 [08:14<11:48,  2.05s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 226/570 [08:16<11:44,  2.05s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 227/570 [08:18<11:42,  2.05s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 228/570 [08:19<10:43,  1.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 229/570 [08:22<11:03,  1.95s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 230/570 [08:24<11:12,  1.98s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 231/570 [08:26<11:18,  2.00s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 232/570 [08:28<11:22,  2.02s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 233/570 [08:30<11:30,  2.05s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 234/570 [08:32<11:29,  2.05s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 235/570 [08:34<11:26,  2.05s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 236/570 [08:36<11:24,  2.05s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 237/570 [08:38<11:25,  2.06s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 238/570 [08:40<11:21,  2.05s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 239/570 [08:42<11:18,  2.05s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 240/570 [08:44<11:15,  2.05s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 241/570 [08:46<11:25,  2.08s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 242/570 [08:49<11:34,  2.12s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 243/570 [08:51<11:40,  2.14s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 244/570 [08:53<11:47,  2.17s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 245/570 [08:55<11:42,  2.16s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 246/570 [08:57<11:30,  2.13s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 247/570 [08:59<10:27,  1.94s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 248/570 [09:01<10:35,  1.97s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 249/570 [09:03<10:44,  2.01s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/570 [09:05<10:45,  2.02s/it]11/08/2022 14:14:27 - ***** Running Evaluation *****
11/08/2022 14:14:27 -   Num examples = 96
11/08/2022 14:14:27 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 10.53}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.87s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it]
                                                  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/570 [09:11<10:45,  2.02s/it]Saving model checkpoint to models/role_gp/checkpoint-250
Configuration saved in models/role_gp/checkpoint-250/config.json
Model weights saved in models/role_gp/checkpoint-250/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-550] due to args.save_total_limit
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 251/570 [09:15<23:32,  4.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 252/570 [09:17<19:40,  3.71s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 253/570 [09:19<17:01,  3.22s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 254/570 [09:21<15:06,  2.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 255/570 [09:23<13:45,  2.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 256/570 [09:25<12:47,  2.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 257/570 [09:27<12:10,  2.33s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 258/570 [09:29<11:40,  2.25s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 259/570 [09:31<11:18,  2.18s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 260/570 [09:33<11:03,  2.14s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 261/570 [09:35<10:52,  2.11s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 262/570 [09:37<10:44,  2.09s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 263/570 [09:40<10:38,  2.08s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 264/570 [09:42<10:33,  2.07s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 265/570 [09:44<10:30,  2.07s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 266/570 [09:45<09:36,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 267/570 [09:47<09:48,  1.94s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 268/570 [09:49<09:55,  1.97s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 269/570 [09:51<10:00,  1.99s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 270/570 [09:53<10:06,  2.02s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 271/570 [09:55<10:05,  2.03s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 272/570 [09:57<10:06,  2.03s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 273/570 [09:59<10:04,  2.04s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 274/570 [10:02<10:07,  2.05s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 275/570 [10:04<10:03,  2.05s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 276/570 [10:06<10:00,  2.04s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 277/570 [10:08<09:59,  2.05s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 278/570 [10:10<10:02,  2.06s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 279/570 [10:12<09:58,  2.06s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 280/570 [10:14<09:54,  2.05s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 281/570 [10:16<09:51,  2.05s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 282/570 [10:18<09:54,  2.06s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 283/570 [10:20<09:50,  2.06s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 284/570 [10:22<09:46,  2.05s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 285/570 [10:24<08:56,  1.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 286/570 [10:26<09:07,  1.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 287/570 [10:28<09:17,  1.97s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 288/570 [10:30<09:21,  1.99s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 289/570 [10:32<09:23,  2.00s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 290/570 [10:34<09:23,  2.01s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 291/570 [10:36<09:27,  2.03s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 292/570 [10:38<09:25,  2.03s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 293/570 [10:40<09:23,  2.03s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 294/570 [10:42<09:21,  2.03s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 295/570 [10:44<09:23,  2.05s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 296/570 [10:46<09:21,  2.05s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 297/570 [10:48<09:18,  2.04s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 298/570 [10:50<09:16,  2.05s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 299/570 [10:52<09:18,  2.06s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 300/570 [10:54<09:14,  2.05s/it]11/08/2022 14:16:17 - ***** Running Evaluation *****
11/08/2022 14:16:17 -   Num examples = 96
11/08/2022 14:16:17 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 13.16}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.88s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.91s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it]
                                                  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 300/570 [11:01<09:14,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-300
Configuration saved in models/role_gp/checkpoint-300/config.json
Model weights saved in models/role_gp/checkpoint-300/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-50] due to args.save_total_limit
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 301/570 [11:04<20:02,  4.47s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 302/570 [11:06<16:43,  3.74s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 303/570 [11:09<14:26,  3.25s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 304/570 [11:10<12:03,  2.72s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 305/570 [11:12<11:07,  2.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 306/570 [11:14<10:27,  2.38s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 307/570 [11:16<09:58,  2.28s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 308/570 [11:18<09:38,  2.21s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 309/570 [11:20<09:22,  2.16s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 310/570 [11:22<09:11,  2.12s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 311/570 [11:24<09:04,  2.10s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 312/570 [11:26<09:02,  2.10s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 313/570 [11:29<08:56,  2.09s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 314/570 [11:31<08:51,  2.08s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 315/570 [11:33<08:47,  2.07s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 316/570 [11:35<08:48,  2.08s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 317/570 [11:37<08:43,  2.07s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 318/570 [11:39<08:39,  2.06s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 319/570 [11:41<08:36,  2.06s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 320/570 [11:43<08:37,  2.07s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 321/570 [11:45<08:33,  2.06s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 322/570 [11:47<08:30,  2.06s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 323/570 [11:49<07:46,  1.89s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 324/570 [11:51<07:59,  1.95s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 325/570 [11:53<08:04,  1.98s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 326/570 [11:55<08:08,  2.00s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 327/570 [11:57<08:09,  2.01s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 328/570 [11:59<08:12,  2.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 329/570 [12:01<08:11,  2.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 330/570 [12:03<08:10,  2.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 331/570 [12:05<08:08,  2.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 332/570 [12:07<08:10,  2.06s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 333/570 [12:09<08:05,  2.05s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 334/570 [12:11<08:02,  2.05s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 335/570 [12:13<08:00,  2.04s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 336/570 [12:15<07:57,  2.04s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 337/570 [12:17<07:54,  2.04s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 338/570 [12:19<07:52,  2.04s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 339/570 [12:21<07:49,  2.03s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 340/570 [12:23<07:47,  2.03s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 341/570 [12:25<07:46,  2.04s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 342/570 [12:27<07:06,  1.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 343/570 [12:29<07:16,  1.92s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 344/570 [12:31<07:22,  1.96s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 345/570 [12:33<07:30,  2.00s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 346/570 [12:35<07:31,  2.02s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 347/570 [12:37<07:32,  2.03s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 348/570 [12:39<07:32,  2.04s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 349/570 [12:41<07:34,  2.06s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 350/570 [12:43<07:32,  2.06s/it]11/08/2022 14:18:06 - ***** Running Evaluation *****
11/08/2022 14:18:06 -   Num examples = 96
11/08/2022 14:18:06 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 15.79}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.88s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.91s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it]
                                                  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 350/570 [12:50<07:32,  2.06s/it]Saving model checkpoint to models/role_gp/checkpoint-350
Configuration saved in models/role_gp/checkpoint-350/config.json
Model weights saved in models/role_gp/checkpoint-350/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-100] due to args.save_total_limit
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 351/570 [12:54<16:22,  4.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 352/570 [12:56<13:38,  3.75s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 353/570 [12:58<11:46,  3.26s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 354/570 [13:00<10:24,  2.89s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 355/570 [13:02<09:26,  2.64s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 356/570 [13:04<08:45,  2.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 357/570 [13:06<08:19,  2.34s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 358/570 [13:08<07:57,  2.25s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 359/570 [13:10<07:41,  2.19s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 360/570 [13:12<07:29,  2.14s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 361/570 [13:14<06:46,  1.94s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 362/570 [13:16<06:53,  1.99s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 363/570 [13:18<06:54,  2.00s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 364/570 [13:20<06:54,  2.01s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 365/570 [13:22<06:54,  2.02s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 366/570 [13:24<06:56,  2.04s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 367/570 [13:26<06:54,  2.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 368/570 [13:28<06:52,  2.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 369/570 [13:30<06:49,  2.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 370/570 [13:32<06:50,  2.05s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 371/570 [13:34<06:46,  2.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 372/570 [13:36<06:44,  2.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 373/570 [13:38<06:41,  2.04s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 374/570 [13:40<06:41,  2.05s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 375/570 [13:42<06:38,  2.04s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 376/570 [13:44<06:36,  2.04s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 377/570 [13:46<06:33,  2.04s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 378/570 [13:48<06:34,  2.05s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 379/570 [13:50<06:30,  2.05s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 380/570 [13:52<05:56,  1.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 381/570 [13:54<06:03,  1.93s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 382/570 [13:56<06:08,  1.96s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 383/570 [13:58<06:11,  1.98s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 384/570 [14:00<06:12,  2.00s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 385/570 [14:02<06:12,  2.01s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 386/570 [14:04<06:11,  2.02s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 387/570 [14:06<06:14,  2.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 388/570 [14:08<06:11,  2.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 389/570 [14:10<06:11,  2.05s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 390/570 [14:12<06:08,  2.05s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 391/570 [14:14<06:09,  2.06s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 392/570 [14:17<06:06,  2.06s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 393/570 [14:19<06:07,  2.07s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 394/570 [14:21<06:03,  2.07s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 395/570 [14:23<06:02,  2.07s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 396/570 [14:25<05:59,  2.06s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 397/570 [14:27<05:56,  2.06s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 398/570 [14:29<05:53,  2.06s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 399/570 [14:30<05:24,  1.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 400/570 [14:33<05:30,  1.95s/it]11/08/2022 14:19:55 - ***** Running Evaluation *****
11/08/2022 14:19:55 -   Num examples = 96
11/08/2022 14:19:55 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 18.42}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.87s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.86s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.88s/it]
                                                  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 400/570 [14:39<05:30,  1.95s/it]Saving model checkpoint to models/role_gp/checkpoint-400
Configuration saved in models/role_gp/checkpoint-400/config.json
Model weights saved in models/role_gp/checkpoint-400/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-150] due to args.save_total_limit
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 401/570 [14:43<12:22,  4.39s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 402/570 [14:45<10:20,  3.70s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 403/570 [14:47<08:57,  3.22s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 404/570 [14:49<07:56,  2.87s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 405/570 [14:51<07:13,  2.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 406/570 [14:53<06:42,  2.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 407/570 [14:55<06:20,  2.33s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 408/570 [14:57<06:04,  2.25s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 409/570 [14:59<05:52,  2.19s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 410/570 [15:01<05:43,  2.15s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 411/570 [15:03<05:36,  2.12s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 412/570 [15:05<05:30,  2.09s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 413/570 [15:07<05:25,  2.07s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 414/570 [15:09<05:22,  2.06s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 415/570 [15:11<05:18,  2.06s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 416/570 [15:13<05:17,  2.06s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 417/570 [15:15<05:14,  2.05s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 418/570 [15:17<04:45,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 419/570 [15:19<04:51,  1.93s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 420/570 [15:21<04:57,  1.98s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 421/570 [15:23<04:58,  2.00s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 422/570 [15:25<04:58,  2.01s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 423/570 [15:27<04:57,  2.02s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 424/570 [15:29<04:58,  2.05s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 425/570 [15:31<04:56,  2.05s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 426/570 [15:33<04:55,  2.05s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 427/570 [15:35<04:53,  2.05s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 428/570 [15:38<04:53,  2.07s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 429/570 [15:40<04:50,  2.06s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 430/570 [15:42<04:47,  2.05s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 431/570 [15:44<04:44,  2.05s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 432/570 [15:46<04:44,  2.06s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 433/570 [15:48<04:41,  2.06s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 434/570 [15:50<04:39,  2.05s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 435/570 [15:52<04:36,  2.05s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 436/570 [15:54<04:36,  2.06s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 437/570 [15:55<04:10,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 438/570 [15:58<04:15,  1.93s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 439/570 [16:00<04:17,  1.97s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 440/570 [16:02<04:19,  1.99s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 441/570 [16:04<04:21,  2.02s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 442/570 [16:06<04:20,  2.03s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 443/570 [16:08<04:18,  2.04s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 444/570 [16:10<04:17,  2.04s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 445/570 [16:12<04:17,  2.06s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 446/570 [16:14<04:15,  2.06s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 447/570 [16:16<04:13,  2.06s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 448/570 [16:18<04:11,  2.06s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 449/570 [16:20<04:10,  2.07s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 450/570 [16:22<04:07,  2.07s/it]11/08/2022 14:21:45 - ***** Running Evaluation *****
11/08/2022 14:21:45 -   Num examples = 96
11/08/2022 14:21:45 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 21.05}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.87s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it]
                                                  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 450/570 [16:28<04:07,  2.07s/it]Saving model checkpoint to models/role_gp/checkpoint-450
Configuration saved in models/role_gp/checkpoint-450/config.json
Model weights saved in models/role_gp/checkpoint-450/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-200] due to args.save_total_limit
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 451/570 [16:32<08:51,  4.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 452/570 [16:34<07:21,  3.74s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 453/570 [16:37<06:20,  3.25s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 454/570 [16:39<05:35,  2.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 455/570 [16:41<05:03,  2.64s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 456/570 [16:42<04:20,  2.29s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 457/570 [16:44<04:10,  2.21s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 458/570 [16:46<04:02,  2.16s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 459/570 [16:48<03:56,  2.13s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 460/570 [16:50<03:51,  2.10s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 461/570 [16:52<03:47,  2.09s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 462/570 [16:54<03:44,  2.08s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 463/570 [16:56<03:41,  2.07s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 464/570 [16:58<03:39,  2.07s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 465/570 [17:01<03:36,  2.06s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 466/570 [17:03<03:35,  2.07s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 467/570 [17:05<03:33,  2.08s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 468/570 [17:07<03:31,  2.07s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 469/570 [17:09<03:28,  2.07s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 470/570 [17:11<03:28,  2.08s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 471/570 [17:13<03:25,  2.07s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 472/570 [17:15<03:22,  2.07s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 473/570 [17:17<03:20,  2.06s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 474/570 [17:19<03:19,  2.08s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 475/570 [17:21<03:00,  1.90s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 476/570 [17:23<03:03,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 477/570 [17:25<03:04,  1.98s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 478/570 [17:27<03:06,  2.02s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 479/570 [17:29<03:05,  2.03s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 480/570 [17:31<03:03,  2.04s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 481/570 [17:33<03:01,  2.04s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 482/570 [17:35<03:01,  2.06s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 483/570 [17:37<02:59,  2.06s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 484/570 [17:39<02:56,  2.05s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 485/570 [17:41<02:54,  2.05s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 486/570 [17:43<02:54,  2.07s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 487/570 [17:46<02:51,  2.06s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 488/570 [17:48<02:48,  2.06s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 489/570 [17:50<02:46,  2.05s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 490/570 [17:52<02:45,  2.07s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 491/570 [17:54<02:42,  2.06s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 492/570 [17:56<02:40,  2.06s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 493/570 [17:58<02:38,  2.06s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 494/570 [17:59<02:23,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 495/570 [18:01<02:26,  1.96s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 496/570 [18:04<02:28,  2.00s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 497/570 [18:06<02:28,  2.04s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 498/570 [18:08<02:28,  2.06s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 499/570 [18:10<02:28,  2.10s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 500/570 [18:12<02:27,  2.10s/it]                                                  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 500/570 [18:12<02:27,  2.10s/it]11/08/2022 14:23:35 - ***** Running Evaluation *****
11/08/2022 14:23:35 -   Num examples = 96
11/08/2022 14:23:35 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 23.68}
{'loss': 0.0213, 'learning_rate': 0.0, 'epoch': 26.32}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.87s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.86s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.88s/it]
                                                  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 500/570 [18:18<02:27,  2.10s/it]Saving model checkpoint to models/role_gp/checkpoint-500
Configuration saved in models/role_gp/checkpoint-500/config.json
Model weights saved in models/role_gp/checkpoint-500/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-250] due to args.save_total_limit
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 501/570 [18:22<05:08,  4.48s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 502/570 [18:24<04:14,  3.75s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 503/570 [18:26<03:37,  3.25s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 504/570 [18:28<03:10,  2.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 505/570 [18:30<02:51,  2.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 506/570 [18:32<02:37,  2.46s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 507/570 [18:35<02:28,  2.35s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 508/570 [18:37<02:20,  2.26s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 509/570 [18:39<02:14,  2.20s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 510/570 [18:41<02:09,  2.16s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 511/570 [18:43<02:06,  2.14s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 512/570 [18:45<02:02,  2.11s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 513/570 [18:46<01:49,  1.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 514/570 [18:48<01:49,  1.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 515/570 [18:50<01:49,  2.00s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 516/570 [18:52<01:48,  2.01s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 517/570 [18:55<01:47,  2.02s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 518/570 [18:57<01:45,  2.03s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 519/570 [18:59<01:43,  2.03s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 520/570 [19:01<01:41,  2.04s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 521/570 [19:03<01:39,  2.04s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 522/570 [19:05<01:37,  2.04s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 523/570 [19:07<01:35,  2.04s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 524/570 [19:09<01:34,  2.05s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 525/570 [19:11<01:32,  2.05s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 526/570 [19:13<01:30,  2.05s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 527/570 [19:15<01:28,  2.05s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 528/570 [19:17<01:26,  2.06s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 529/570 [19:19<01:24,  2.06s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 530/570 [19:21<01:21,  2.05s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 531/570 [19:23<01:19,  2.05s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 532/570 [19:25<01:12,  1.90s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 533/570 [19:27<01:11,  1.94s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 534/570 [19:29<01:10,  1.97s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 535/570 [19:31<01:09,  1.99s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 536/570 [19:33<01:08,  2.02s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 537/570 [19:35<01:06,  2.03s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 538/570 [19:37<01:05,  2.03s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 539/570 [19:39<01:03,  2.04s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 540/570 [19:41<01:01,  2.05s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 541/570 [19:43<00:59,  2.05s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 542/570 [19:45<00:57,  2.05s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 543/570 [19:47<00:55,  2.04s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 544/570 [19:49<00:53,  2.06s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 545/570 [19:51<00:51,  2.06s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 546/570 [19:53<00:49,  2.05s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 547/570 [19:56<00:47,  2.05s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 548/570 [19:58<00:45,  2.05s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 549/570 [20:00<00:43,  2.05s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 550/570 [20:02<00:40,  2.05s/it]11/08/2022 14:25:24 - ***** Running Evaluation *****
11/08/2022 14:25:24 -   Num examples = 96
11/08/2022 14:25:24 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 26.32}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.86s/it][A
Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.86s/it][A
Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.88s/it][AEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.87s/it]
                                                  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 550/570 [20:08<00:40,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-550
Configuration saved in models/role_gp/checkpoint-550/config.json
Model weights saved in models/role_gp/checkpoint-550/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-300] due to args.save_total_limit
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 551/570 [20:11<01:20,  4.26s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 552/570 [20:13<01:04,  3.59s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 553/570 [20:15<00:53,  3.14s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 554/570 [20:17<00:44,  2.81s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 555/570 [20:19<00:38,  2.58s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 556/570 [20:21<00:33,  2.42s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 557/570 [20:23<00:30,  2.31s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 558/570 [20:25<00:26,  2.23s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 559/570 [20:27<00:23,  2.18s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 560/570 [20:30<00:21,  2.14s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 561/570 [20:32<00:19,  2.12s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 562/570 [20:34<00:16,  2.09s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 563/570 [20:36<00:14,  2.08s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 564/570 [20:38<00:12,  2.07s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 565/570 [20:40<00:10,  2.07s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 566/570 [20:42<00:08,  2.08s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 567/570 [20:44<00:06,  2.07s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 568/570 [20:46<00:04,  2.06s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 569/570 [20:48<00:02,  2.06s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [20:50<00:00,  1.89s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [20:50<00:00,  1.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [20:50<00:00,  2.19s/it]
Saving model checkpoint to models/role_gp/best
Configuration saved in models/role_gp/best/config.json
Model weights saved in models/role_gp/best/pytorch_model.bin
11/08/2022 14:26:13 - *** Evaluate ***
11/08/2022 14:26:13 - ***** Running Evaluation *****
11/08/2022 14:26:13 -   Num examples = 96
11/08/2022 14:26:13 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 28.95}
{'train_runtime': 1250.0367, 'train_samples_per_second': 14.376, 'train_steps_per_second': 0.456, 'train_loss': 0.021391594200803523, 'epoch': 30.0}
***** train metrics *****
  epoch                    =       30.0
  train_loss               =     0.0214
  train_runtime            = 0:20:50.03
  train_samples_per_second =     14.376
  train_steps_per_second   =      0.456
Evaluation:   0%|          | 0/3 [00:00<?, ?it/s]Evaluation:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.86s/it]Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.86s/it]Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.86s/it]Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.86s/it]
11/08/2022 14:26:19 - ***** Eval results *****
11/08/2022 14:26:19 -   eval_loss = 1.879099448521932
11/08/2022 14:26:19 -   eval_precision = 0.6493506493506493
11/08/2022 14:26:19 -   eval_recall = 0.6410256410256411
11/08/2022 14:26:19 -   eval_f1 = 0.6451612903225806
11/08/2022 14:26:19 -   epoch = 30.0
0it [00:00, ?it/s]2460it [00:00, 379952.42it/s]
11/08/2022 14:26:19 - Creating features from dataset file at tests/data/role/test.txt
11/08/2022 14:26:19 - Writing example 0 of 111
11/08/2022 14:26:19 - *** Example ***
11/08/2022 14:26:19 - guid: 1 (length: 57)
11/08/2022 14:26:19 - tokens: [CLS] Re ##action of dip ##hen ##yla ##ce ##ty with complex 19 ##A led to only [Prod] c ##y ##c ##lo ##he [/Prod] 23 ##A in 30 % yield ; with ( p ##hen ##yl ##cy car ##ben ##e complex 19 ##B , c ##y ##c ##lo ##he 25 was produced in 53 % yield . [SEP]
11/08/2022 14:26:19 - input_ids: 101 11336 15022 1104 20866 10436 22948 2093 2340 1114 2703 1627 1592 1521 1106 1178 28996 172 1183 1665 2858 4638 28997 1695 1592 1107 1476 110 10972 132 1114 113 185 10436 7777 3457 1610 9672 1162 2703 1627 2064 117 172 1183 1665 2858 4638 1512 1108 1666 1107 4389 110 10972 119 102
11/08/2022 14:26:19 - label_ids: -100 0 -100 0 1 -100 -100 -100 -100 0 0 1 -100 0 0 0 -100 -100 -100 -100 -100 -100 -100 0 -100 0 11 12 0 0 0 0 -100 -100 -100 -100 0 -100 -100 0 0 -100 0 0 -100 -100 -100 -100 0 0 0 0 0 0 0 -100 -100
11/08/2022 14:26:19 - label_matrix: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
11/08/2022 14:26:19 - decoder_mask: False True False True True False False False False True True True False True True True False False False False False False False True False True True True True True True True False False False False True False False True True False True True False False False False True True True True True True True False False
11/08/2022 14:26:19 - Saving features into cached file tests/data/role/cached_test.txt_BertTokenizerFast_256
11/08/2022 14:26:22 - ***** Running Prediction *****
11/08/2022 14:26:22 -   Num examples = 111
11/08/2022 14:26:22 -   Batch size = 32
Prediction:   0%|          | 0/4 [00:00<?, ?it/s]Prediction:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.85s/it]Prediction:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.85s/it]Prediction:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.86s/it]Prediction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.47s/it]Prediction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
11/08/2022 14:26:29 -   eval_loss = 1.5720282047986984
11/08/2022 14:26:29 -   eval_precision = 0.7097791798107256
11/08/2022 14:26:29 -   eval_recall = 0.6923076923076923
11/08/2022 14:26:29 -   eval_f1 = 0.7009345794392523
0it [00:00, ?it/s]2396it [00:00, 382141.32it/s]
