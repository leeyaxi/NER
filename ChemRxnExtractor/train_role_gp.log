2022-11-08 13:44:12.132237: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
11/08/2022 13:44:13 - Training/evaluation parameters ExTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
crf_learning_rate=0.005,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=50,
evaluation_strategy=IntervalStrategy.STEPS,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=models/role_gp/runs/Nov08_13-44-13_7135cc6fcf45,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=30,
optim=OptimizerNames.ADAMW_HF,
output_dir=models/role_gp,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=models/role_gp,
save_on_each_node=False,
save_steps=50,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=5,
seed=12,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/08/2022 13:44:14 - Tagging schema: BIO
Some weights of the model checkpoint at chem-pretrain/role were not used when initializing BertGlobalPointerForRoleLabeling: ['crf._constraint_mask', 'crf.end_transitions', 'crf.transitions', 'crf.start_transitions']
- This IS expected if you are initializing BertGlobalPointerForRoleLabeling from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertGlobalPointerForRoleLabeling from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertGlobalPointerForRoleLabeling were not initialized from the model checkpoint at chem-pretrain/role and are newly initialized: ['global_pointer.position_embedding.cos_position', 'global_pointer.position_embedding.sin_position', 'global_pointer.dense.bias', 'global_pointer.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertGlobalPointerForRoleLabeling were not initialized from the model checkpoint at chem-pretrain/role and are newly initialized because the shapes did not match:
- classifier.weight: found shape torch.Size([17, 2304]) in the checkpoint and torch.Size([9, 768]) in the model instantiated
- classifier.bias: found shape torch.Size([17]) in the checkpoint and torch.Size([9]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/08/2022 13:44:14 - Creating features from dataset file at tests/data/role/train.txt
11/08/2022 13:44:14 - Writing example 0 of 599
11/08/2022 13:44:14 - *** Example ***
11/08/2022 13:44:14 - guid: 1 (length: 71)
11/08/2022 13:44:14 - tokens: [CLS] As observed for the g ##ly ##cos ##yla ##tions of the 4 - OH accept ##or 7 , the use of e ##qui ##mo ##lar proportions of the donor 6 and the accept ##or 16 , in g ##ly ##cos ##yla ##tion reactions , led to the isolation of significant quantities of the g ##lu ##cal [Prod] 9 [/Prod] and low yields of the di ##sa ##cc ##hari ##des [SEP]
11/08/2022 13:44:14 - input_ids: 101 1249 4379 1111 1103 176 1193 13538 22948 6126 1104 1103 125 118 18719 4392 1766 128 117 1103 1329 1104 174 18276 3702 5815 21136 1104 1103 16667 127 1105 1103 4392 1766 1479 117 1107 176 1193 13538 22948 2116 9535 117 1521 1106 1103 13345 1104 2418 12709 1104 1103 176 7535 7867 28996 130 28997 1105 1822 17376 1104 1103 4267 3202 19515 16234 4704 102
11/08/2022 13:44:14 - label_ids: -100 0 0 0 0 0 -100 -100 -100 -100 0 0 0 -100 -100 0 -100 0 0 0 0 0 0 -100 -100 -100 0 0 0 0 0 0 0 0 -100 0 0 0 7 -100 -100 -100 -100 0 0 0 0 0 0 0 11 12 0 0 0 -100 -100 -100 -100 -100 0 0 0 0 0 0 -100 -100 -100 -100 -100
11/08/2022 13:44:14 - label_matrix: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
11/08/2022 13:44:14 - decoder_mask: False True True True True True False False False False True True True False False True False True True True True True True False False False True True True True True True True True False True True True True False False False False True True True True True True True True True True True True False False False False False True True True True True True False False False False False
11/08/2022 13:44:15 - Saving features into cached file tests/data/role/cached_train.txt_BertTokenizerFast_256
11/08/2022 13:44:31 - Creating features from dataset file at tests/data/role/dev.txt
11/08/2022 13:44:31 - Writing example 0 of 96
11/08/2022 13:44:31 - *** Example ***
11/08/2022 13:44:31 - guid: 1 (length: 89)
11/08/2022 13:44:31 - tokens: [CLS] In order to check this select ##ivity trend in other dip ##ero ##xy acids , we carried out reaction of ben ##zen ##e - 1 with he ##xa ##ne ##bis ( acid ) and do ##de ##cane ##bis ( acid ) ( with 6 and 12 carbon atoms , respectively ) , which also give 100 % conversion to [Prod] 2 - ni ##tro ##ani ##line [/Prod] with 90 % and 92 % isolated yields , respectively ( Table 4 , entries 7 and 8 ) . [SEP]
11/08/2022 13:44:31 - input_ids: 101 1130 1546 1106 4031 1142 8247 6366 10209 1107 1168 20866 10771 16844 13087 117 1195 2446 1149 3943 1104 26181 10947 1162 118 122 1114 1119 20192 1673 14866 113 5190 114 1105 1202 2007 27313 14866 113 5190 114 113 1114 127 1105 1367 6302 14296 117 3569 114 117 1134 1145 1660 1620 110 7497 1106 28996 123 118 11437 8005 7192 2568 28997 1114 3078 110 1105 5556 110 6841 17376 117 3569 113 11389 125 117 10813 128 1105 129 114 119 102
11/08/2022 13:44:31 - label_ids: -100 0 0 0 0 0 0 -100 0 0 0 0 -100 -100 0 0 0 0 0 0 0 1 -100 -100 -100 -100 0 1 -100 -100 -100 -100 2 2 0 1 -100 -100 -100 -100 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 0 11 12 0 11 12 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100
11/08/2022 13:44:31 - label_matrix: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
11/08/2022 13:44:31 - decoder_mask: False True True True True True True False True True True True False False True True True True True True True True False False False False True True False False False False True True True True False False False False True True True True True True True True True True True True True True True True True True True True False False False False False False False False True True True True True True True True True True True True True True True True True True True False False
11/08/2022 13:44:31 - Saving features into cached file tests/data/role/cached_dev.txt_BertTokenizerFast_256
***** Running training *****
  Num examples = 599
  Num Epochs = 30
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 570
  0%|          | 0/570 [00:00<?, ?it/s]  0%|          | 1/570 [00:02<19:49,  2.09s/it]  0%|          | 2/570 [00:04<19:45,  2.09s/it]  1%|          | 3/570 [00:06<19:47,  2.09s/it]  1%|          | 4/570 [00:08<19:37,  2.08s/it]  1%|          | 5/570 [00:10<19:30,  2.07s/it]  1%|          | 6/570 [00:12<19:27,  2.07s/it]  1%|          | 7/570 [00:14<19:42,  2.10s/it]  1%|▏         | 8/570 [00:16<19:39,  2.10s/it]  2%|▏         | 9/570 [00:18<19:30,  2.09s/it]  2%|▏         | 10/570 [00:20<19:28,  2.09s/it]  2%|▏         | 11/570 [00:23<19:38,  2.11s/it]  2%|▏         | 12/570 [00:25<19:35,  2.11s/it]  2%|▏         | 13/570 [00:27<19:24,  2.09s/it]  2%|▏         | 14/570 [00:29<19:19,  2.09s/it]  3%|▎         | 15/570 [00:31<19:24,  2.10s/it]  3%|▎         | 16/570 [00:33<19:17,  2.09s/it]  3%|▎         | 17/570 [00:35<19:10,  2.08s/it]  3%|▎         | 18/570 [00:37<19:07,  2.08s/it]  3%|▎         | 19/570 [00:39<17:25,  1.90s/it]  4%|▎         | 20/570 [00:41<17:52,  1.95s/it]  4%|▎         | 21/570 [00:43<18:18,  2.00s/it]  4%|▍         | 22/570 [00:45<18:32,  2.03s/it]  4%|▍         | 23/570 [00:47<18:37,  2.04s/it]  4%|▍         | 24/570 [00:49<18:38,  2.05s/it]  4%|▍         | 25/570 [00:51<18:37,  2.05s/it]  5%|▍         | 26/570 [00:53<18:38,  2.06s/it]  5%|▍         | 27/570 [00:55<18:38,  2.06s/it]  5%|▍         | 28/570 [00:57<18:53,  2.09s/it]  5%|▌         | 29/570 [00:59<18:44,  2.08s/it]  5%|▌         | 30/570 [01:01<18:36,  2.07s/it]  5%|▌         | 31/570 [01:04<18:35,  2.07s/it]  6%|▌         | 32/570 [01:06<18:37,  2.08s/it]  6%|▌         | 33/570 [01:08<18:32,  2.07s/it]  6%|▌         | 34/570 [01:10<18:29,  2.07s/it]  6%|▌         | 35/570 [01:12<18:31,  2.08s/it]  6%|▋         | 36/570 [01:14<18:35,  2.09s/it]  6%|▋         | 37/570 [01:16<18:29,  2.08s/it]  7%|▋         | 38/570 [01:17<16:52,  1.90s/it]  7%|▋         | 39/570 [01:20<17:15,  1.95s/it]  7%|▋         | 40/570 [01:22<17:38,  2.00s/it]  7%|▋         | 41/570 [01:24<17:45,  2.01s/it]  7%|▋         | 42/570 [01:26<17:51,  2.03s/it]  8%|▊         | 43/570 [01:28<17:54,  2.04s/it]  8%|▊         | 44/570 [01:30<18:02,  2.06s/it]  8%|▊         | 45/570 [01:32<18:00,  2.06s/it]  8%|▊         | 46/570 [01:34<17:59,  2.06s/it]  8%|▊         | 47/570 [01:36<17:56,  2.06s/it]  8%|▊         | 48/570 [01:38<18:01,  2.07s/it]  9%|▊         | 49/570 [01:40<17:56,  2.07s/it]  9%|▉         | 50/570 [01:42<17:51,  2.06s/it]11/08/2022 13:46:19 - ***** Running Evaluation *****
11/08/2022 13:46:19 -   Num examples = 96
11/08/2022 13:46:19 -   Batch size = 32

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.90s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
                                                  9%|▉         | 50/570 [01:49<17:51,  2.06s/it]Saving model checkpoint to models/role_gp/checkpoint-50
Configuration saved in models/role_gp/checkpoint-50/config.json
Model weights saved in models/role_gp/checkpoint-50/pytorch_model.bin
  9%|▉         | 51/570 [01:53<39:51,  4.61s/it]  9%|▉         | 52/570 [01:55<33:24,  3.87s/it]  9%|▉         | 53/570 [01:57<28:40,  3.33s/it]  9%|▉         | 54/570 [01:59<25:18,  2.94s/it] 10%|▉         | 55/570 [02:01<22:58,  2.68s/it] 10%|▉         | 56/570 [02:03<21:34,  2.52s/it] 10%|█         | 57/570 [02:05<18:52,  2.21s/it] 10%|█         | 58/570 [02:07<18:25,  2.16s/it] 10%|█         | 59/570 [02:09<18:06,  2.13s/it] 11%|█         | 60/570 [02:11<17:57,  2.11s/it] 11%|█         | 61/570 [02:13<17:50,  2.10s/it] 11%|█         | 62/570 [02:15<17:39,  2.09s/it] 11%|█         | 63/570 [02:17<17:34,  2.08s/it] 11%|█         | 64/570 [02:19<17:31,  2.08s/it] 11%|█▏        | 65/570 [02:21<17:36,  2.09s/it] 12%|█▏        | 66/570 [02:23<17:27,  2.08s/it] 12%|█▏        | 67/570 [02:25<17:20,  2.07s/it] 12%|█▏        | 68/570 [02:28<17:15,  2.06s/it] 12%|█▏        | 69/570 [02:30<17:19,  2.08s/it] 12%|█▏        | 70/570 [02:32<17:16,  2.07s/it] 12%|█▏        | 71/570 [02:34<17:11,  2.07s/it] 13%|█▎        | 72/570 [02:36<17:07,  2.06s/it] 13%|█▎        | 73/570 [02:38<17:09,  2.07s/it] 13%|█▎        | 74/570 [02:40<17:02,  2.06s/it] 13%|█▎        | 75/570 [02:42<16:57,  2.06s/it] 13%|█▎        | 76/570 [02:43<15:29,  1.88s/it] 14%|█▎        | 77/570 [02:46<16:00,  1.95s/it] 14%|█▎        | 78/570 [02:48<16:14,  1.98s/it] 14%|█▍        | 79/570 [02:50<16:24,  2.00s/it] 14%|█▍        | 80/570 [02:52<16:28,  2.02s/it] 14%|█▍        | 81/570 [02:54<16:37,  2.04s/it] 14%|█▍        | 82/570 [02:56<16:35,  2.04s/it] 15%|█▍        | 83/570 [02:58<16:35,  2.04s/it] 15%|█▍        | 84/570 [03:00<16:34,  2.05s/it] 15%|█▍        | 85/570 [03:02<16:45,  2.07s/it] 15%|█▌        | 86/570 [03:04<16:42,  2.07s/it] 15%|█▌        | 87/570 [03:06<16:38,  2.07s/it] 15%|█▌        | 88/570 [03:08<16:34,  2.06s/it] 16%|█▌        | 89/570 [03:10<16:37,  2.07s/it] 16%|█▌        | 90/570 [03:12<16:31,  2.07s/it] 16%|█▌        | 91/570 [03:14<16:26,  2.06s/it] 16%|█▌        | 92/570 [03:16<16:22,  2.05s/it] 16%|█▋        | 93/570 [03:19<16:19,  2.05s/it] 16%|█▋        | 94/570 [03:21<16:17,  2.05s/it] 17%|█▋        | 95/570 [03:22<14:51,  1.88s/it] 17%|█▋        | 96/570 [03:24<15:15,  1.93s/it] 17%|█▋        | 97/570 [03:26<15:30,  1.97s/it] 17%|█▋        | 98/570 [03:28<15:49,  2.01s/it] 17%|█▋        | 99/570 [03:30<15:54,  2.03s/it] 18%|█▊        | 100/570 [03:32<15:56,  2.03s/it]11/08/2022 13:48:09 - ***** Running Evaluation *****
11/08/2022 13:48:09 -   Num examples = 96
11/08/2022 13:48:09 -   Batch size = 32
{'eval_loss': 1.0996010303497314, 'eval_precision': 0.46987951807228917, 'eval_recall': 0.5, 'eval_f1': 0.484472049689441, 'epoch': 2.63}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.89s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
                                                  18%|█▊        | 100/570 [03:39<15:56,  2.03s/it]Saving model checkpoint to models/role_gp/checkpoint-100
Configuration saved in models/role_gp/checkpoint-100/config.json
Model weights saved in models/role_gp/checkpoint-100/pytorch_model.bin
 18%|█▊        | 101/570 [03:43<35:20,  4.52s/it] 18%|█▊        | 102/570 [03:45<29:36,  3.80s/it] 18%|█▊        | 103/570 [03:47<25:28,  3.27s/it] 18%|█▊        | 104/570 [03:49<22:33,  2.90s/it] 18%|█▊        | 105/570 [03:51<20:31,  2.65s/it] 19%|█▊        | 106/570 [03:53<19:14,  2.49s/it] 19%|█▉        | 107/570 [03:55<18:11,  2.36s/it] 19%|█▉        | 108/570 [03:57<17:26,  2.26s/it] 19%|█▉        | 109/570 [03:59<16:53,  2.20s/it] 19%|█▉        | 110/570 [04:01<16:37,  2.17s/it] 19%|█▉        | 111/570 [04:03<16:17,  2.13s/it] 20%|█▉        | 112/570 [04:05<16:02,  2.10s/it] 20%|█▉        | 113/570 [04:07<15:52,  2.08s/it] 20%|██        | 114/570 [04:09<14:26,  1.90s/it] 20%|██        | 115/570 [04:11<14:42,  1.94s/it] 20%|██        | 116/570 [04:13<14:53,  1.97s/it] 21%|██        | 117/570 [04:15<15:01,  1.99s/it] 21%|██        | 118/570 [04:17<15:06,  2.01s/it] 21%|██        | 119/570 [04:19<15:13,  2.03s/it] 21%|██        | 120/570 [04:21<15:12,  2.03s/it] 21%|██        | 121/570 [04:23<15:11,  2.03s/it] 21%|██▏       | 122/570 [04:25<15:10,  2.03s/it] 22%|██▏       | 123/570 [04:27<15:15,  2.05s/it] 22%|██▏       | 124/570 [04:29<15:12,  2.04s/it] 22%|██▏       | 125/570 [04:31<15:07,  2.04s/it] 22%|██▏       | 126/570 [04:33<15:04,  2.04s/it] 22%|██▏       | 127/570 [04:36<15:08,  2.05s/it] 22%|██▏       | 128/570 [04:38<15:06,  2.05s/it] 23%|██▎       | 129/570 [04:40<15:01,  2.04s/it] 23%|██▎       | 130/570 [04:42<14:59,  2.04s/it] 23%|██▎       | 131/570 [04:44<15:03,  2.06s/it] 23%|██▎       | 132/570 [04:46<14:58,  2.05s/it] 23%|██▎       | 133/570 [04:47<13:40,  1.88s/it] 24%|██▎       | 134/570 [04:49<13:59,  1.93s/it] 24%|██▎       | 135/570 [04:51<14:19,  1.98s/it] 24%|██▍       | 136/570 [04:53<14:23,  1.99s/it] 24%|██▍       | 137/570 [04:55<14:26,  2.00s/it] 24%|██▍       | 138/570 [04:57<14:29,  2.01s/it] 24%|██▍       | 139/570 [05:00<14:31,  2.02s/it] 25%|██▍       | 140/570 [05:02<14:32,  2.03s/it] 25%|██▍       | 141/570 [05:04<14:32,  2.03s/it] 25%|██▍       | 142/570 [05:06<14:30,  2.03s/it] 25%|██▌       | 143/570 [05:08<14:30,  2.04s/it] 25%|██▌       | 144/570 [05:10<14:30,  2.04s/it] 25%|██▌       | 145/570 [05:12<14:28,  2.04s/it] 26%|██▌       | 146/570 [05:14<14:24,  2.04s/it] 26%|██▌       | 147/570 [05:16<14:22,  2.04s/it] 26%|██▌       | 148/570 [05:18<14:27,  2.05s/it] 26%|██▌       | 149/570 [05:20<14:23,  2.05s/it] 26%|██▋       | 150/570 [05:22<14:20,  2.05s/it]11/08/2022 13:49:58 - ***** Running Evaluation *****
11/08/2022 13:49:58 -   Num examples = 96
11/08/2022 13:49:58 -   Batch size = 32
{'eval_loss': 1.2886539697647095, 'eval_precision': 0.6161971830985915, 'eval_recall': 0.5608974358974359, 'eval_f1': 0.587248322147651, 'epoch': 5.26}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.90s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
                                                  26%|██▋       | 150/570 [05:28<14:20,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-150
Configuration saved in models/role_gp/checkpoint-150/config.json
Model weights saved in models/role_gp/checkpoint-150/pytorch_model.bin
 26%|██▋       | 151/570 [05:32<30:51,  4.42s/it] 27%|██▋       | 152/570 [05:33<24:42,  3.55s/it] 27%|██▋       | 153/570 [05:36<21:32,  3.10s/it] 27%|██▋       | 154/570 [05:38<19:19,  2.79s/it] 27%|██▋       | 155/570 [05:40<17:45,  2.57s/it] 27%|██▋       | 156/570 [05:42<16:43,  2.42s/it] 28%|██▊       | 157/570 [05:44<16:06,  2.34s/it] 28%|██▊       | 158/570 [05:46<15:39,  2.28s/it] 28%|██▊       | 159/570 [05:48<15:20,  2.24s/it] 28%|██▊       | 160/570 [05:50<15:16,  2.23s/it] 28%|██▊       | 161/570 [05:52<14:51,  2.18s/it] 28%|██▊       | 162/570 [05:55<14:34,  2.14s/it] 29%|██▊       | 163/570 [05:57<14:21,  2.12s/it] 29%|██▉       | 164/570 [05:59<14:18,  2.11s/it] 29%|██▉       | 165/570 [06:01<14:09,  2.10s/it] 29%|██▉       | 166/570 [06:03<14:03,  2.09s/it] 29%|██▉       | 167/570 [06:05<13:56,  2.08s/it] 29%|██▉       | 168/570 [06:07<13:53,  2.07s/it] 30%|██▉       | 169/570 [06:09<13:50,  2.07s/it] 30%|██▉       | 170/570 [06:11<13:45,  2.06s/it] 30%|███       | 171/570 [06:13<12:38,  1.90s/it] 30%|███       | 172/570 [06:15<12:55,  1.95s/it] 30%|███       | 173/570 [06:17<13:11,  1.99s/it] 31%|███       | 174/570 [06:19<13:16,  2.01s/it] 31%|███       | 175/570 [06:21<13:19,  2.02s/it] 31%|███       | 176/570 [06:23<13:20,  2.03s/it] 31%|███       | 177/570 [06:25<13:26,  2.05s/it] 31%|███       | 178/570 [06:27<13:27,  2.06s/it] 31%|███▏      | 179/570 [06:29<13:24,  2.06s/it] 32%|███▏      | 180/570 [06:31<13:22,  2.06s/it] 32%|███▏      | 181/570 [06:33<13:25,  2.07s/it] 32%|███▏      | 182/570 [06:35<13:22,  2.07s/it] 32%|███▏      | 183/570 [06:37<13:19,  2.06s/it] 32%|███▏      | 184/570 [06:39<13:15,  2.06s/it] 32%|███▏      | 185/570 [06:42<13:18,  2.07s/it] 33%|███▎      | 186/570 [06:44<13:14,  2.07s/it] 33%|███▎      | 187/570 [06:46<13:10,  2.06s/it] 33%|███▎      | 188/570 [06:48<13:07,  2.06s/it] 33%|███▎      | 189/570 [06:50<13:09,  2.07s/it] 33%|███▎      | 190/570 [06:51<11:59,  1.89s/it] 34%|███▎      | 191/570 [06:53<12:15,  1.94s/it] 34%|███▎      | 192/570 [06:55<12:26,  1.97s/it] 34%|███▍      | 193/570 [06:57<12:36,  2.01s/it] 34%|███▍      | 194/570 [06:59<12:38,  2.02s/it] 34%|███▍      | 195/570 [07:02<12:40,  2.03s/it] 34%|███▍      | 196/570 [07:04<12:41,  2.04s/it] 35%|███▍      | 197/570 [07:06<12:42,  2.04s/it] 35%|███▍      | 198/570 [07:08<12:41,  2.05s/it] 35%|███▍      | 199/570 [07:10<12:39,  2.05s/it] 35%|███▌      | 200/570 [07:12<12:39,  2.05s/it]11/08/2022 13:51:48 - ***** Running Evaluation *****
11/08/2022 13:51:48 -   Num examples = 96
11/08/2022 13:51:48 -   Batch size = 32
{'eval_loss': 1.412975549697876, 'eval_precision': 0.6464285714285715, 'eval_recall': 0.5801282051282052, 'eval_f1': 0.6114864864864865, 'epoch': 7.89}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.90s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.95s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.94s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]
                                                  35%|███▌      | 200/570 [07:18<12:39,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-200
Configuration saved in models/role_gp/checkpoint-200/config.json
Model weights saved in models/role_gp/checkpoint-200/pytorch_model.bin
 35%|███▌      | 201/570 [07:22<27:26,  4.46s/it] 35%|███▌      | 202/570 [07:24<23:01,  3.75s/it] 36%|███▌      | 203/570 [07:26<19:51,  3.25s/it] 36%|███▌      | 204/570 [07:28<17:38,  2.89s/it] 36%|███▌      | 205/570 [07:30<16:04,  2.64s/it] 36%|███▌      | 206/570 [07:32<15:04,  2.48s/it] 36%|███▋      | 207/570 [07:34<14:15,  2.36s/it] 36%|███▋      | 208/570 [07:36<13:40,  2.27s/it] 37%|███▋      | 209/570 [07:38<12:12,  2.03s/it] 37%|███▋      | 210/570 [07:40<12:18,  2.05s/it] 37%|███▋      | 211/570 [07:42<12:15,  2.05s/it] 37%|███▋      | 212/570 [07:44<12:13,  2.05s/it] 37%|███▋      | 213/570 [07:46<12:11,  2.05s/it] 38%|███▊      | 214/570 [07:48<12:15,  2.06s/it] 38%|███▊      | 215/570 [07:50<12:11,  2.06s/it] 38%|███▊      | 216/570 [07:52<12:08,  2.06s/it] 38%|███▊      | 217/570 [07:54<12:05,  2.05s/it] 38%|███▊      | 218/570 [07:57<12:08,  2.07s/it] 38%|███▊      | 219/570 [07:59<12:04,  2.07s/it] 39%|███▊      | 220/570 [08:01<12:01,  2.06s/it] 39%|███▉      | 221/570 [08:03<11:58,  2.06s/it] 39%|███▉      | 222/570 [08:05<11:56,  2.06s/it] 39%|███▉      | 223/570 [08:07<11:53,  2.06s/it] 39%|███▉      | 224/570 [08:09<11:50,  2.05s/it] 39%|███▉      | 225/570 [08:11<11:47,  2.05s/it] 40%|███▉      | 226/570 [08:13<11:45,  2.05s/it] 40%|███▉      | 227/570 [08:15<11:43,  2.05s/it] 40%|████      | 228/570 [08:16<10:42,  1.88s/it] 40%|████      | 229/570 [08:19<10:58,  1.93s/it] 40%|████      | 230/570 [08:21<11:09,  1.97s/it] 41%|████      | 231/570 [08:23<11:20,  2.01s/it] 41%|████      | 232/570 [08:25<11:23,  2.02s/it] 41%|████      | 233/570 [08:27<11:24,  2.03s/it] 41%|████      | 234/570 [08:29<11:26,  2.04s/it] 41%|████      | 235/570 [08:31<11:31,  2.07s/it] 41%|████▏     | 236/570 [08:33<11:27,  2.06s/it] 42%|████▏     | 237/570 [08:35<11:25,  2.06s/it] 42%|████▏     | 238/570 [08:37<11:23,  2.06s/it] 42%|████▏     | 239/570 [08:39<11:27,  2.08s/it] 42%|████▏     | 240/570 [08:41<11:23,  2.07s/it] 42%|████▏     | 241/570 [08:43<11:19,  2.07s/it] 42%|████▏     | 242/570 [08:45<11:16,  2.06s/it] 43%|████▎     | 243/570 [08:48<11:18,  2.07s/it] 43%|████▎     | 244/570 [08:50<11:14,  2.07s/it] 43%|████▎     | 245/570 [08:52<11:10,  2.06s/it] 43%|████▎     | 246/570 [08:54<11:06,  2.06s/it] 43%|████▎     | 247/570 [08:55<10:11,  1.89s/it] 44%|████▎     | 248/570 [08:57<10:25,  1.94s/it] 44%|████▎     | 249/570 [08:59<10:36,  1.98s/it] 44%|████▍     | 250/570 [09:01<10:40,  2.00s/it]11/08/2022 13:53:38 - ***** Running Evaluation *****
11/08/2022 13:53:38 -   Num examples = 96
11/08/2022 13:53:38 -   Batch size = 32
{'eval_loss': 1.4505313237508137, 'eval_precision': 0.5953757225433526, 'eval_recall': 0.6602564102564102, 'eval_f1': 0.6261398176291794, 'epoch': 10.53}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.90s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.90s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
                                                  44%|████▍     | 250/570 [09:08<10:40,  2.00s/it]Saving model checkpoint to models/role_gp/checkpoint-250
Configuration saved in models/role_gp/checkpoint-250/config.json
Model weights saved in models/role_gp/checkpoint-250/pytorch_model.bin
 44%|████▍     | 251/570 [09:11<23:32,  4.43s/it] 44%|████▍     | 252/570 [09:14<19:48,  3.74s/it] 44%|████▍     | 253/570 [09:16<17:06,  3.24s/it] 45%|████▍     | 254/570 [09:18<15:13,  2.89s/it] 45%|████▍     | 255/570 [09:20<13:52,  2.64s/it] 45%|████▍     | 256/570 [09:22<13:01,  2.49s/it] 45%|████▌     | 257/570 [09:24<12:17,  2.36s/it] 45%|████▌     | 258/570 [09:26<11:46,  2.26s/it] 45%|████▌     | 259/570 [09:28<11:23,  2.20s/it] 46%|████▌     | 260/570 [09:30<11:10,  2.16s/it] 46%|████▌     | 261/570 [09:32<10:56,  2.13s/it] 46%|████▌     | 262/570 [09:34<10:46,  2.10s/it] 46%|████▌     | 263/570 [09:36<10:38,  2.08s/it] 46%|████▋     | 264/570 [09:38<10:37,  2.08s/it] 46%|████▋     | 265/570 [09:40<10:31,  2.07s/it] 47%|████▋     | 266/570 [09:42<09:35,  1.89s/it] 47%|████▋     | 267/570 [09:44<09:47,  1.94s/it] 47%|████▋     | 268/570 [09:46<09:59,  1.99s/it] 47%|████▋     | 269/570 [09:48<10:03,  2.00s/it] 47%|████▋     | 270/570 [09:50<10:04,  2.02s/it] 48%|████▊     | 271/570 [09:52<10:05,  2.02s/it] 48%|████▊     | 272/570 [09:54<10:08,  2.04s/it] 48%|████▊     | 273/570 [09:56<10:05,  2.04s/it] 48%|████▊     | 274/570 [09:58<10:03,  2.04s/it] 48%|████▊     | 275/570 [10:00<10:02,  2.04s/it] 48%|████▊     | 276/570 [10:02<10:00,  2.04s/it] 49%|████▊     | 277/570 [10:04<09:58,  2.04s/it] 49%|████▉     | 278/570 [10:06<09:56,  2.04s/it] 49%|████▉     | 279/570 [10:09<09:55,  2.05s/it] 49%|████▉     | 280/570 [10:11<09:54,  2.05s/it] 49%|████▉     | 281/570 [10:13<09:52,  2.05s/it] 49%|████▉     | 282/570 [10:15<09:52,  2.06s/it] 50%|████▉     | 283/570 [10:17<09:51,  2.06s/it] 50%|████▉     | 284/570 [10:19<09:51,  2.07s/it] 50%|█████     | 285/570 [10:20<09:02,  1.90s/it] 50%|█████     | 286/570 [10:22<09:15,  1.96s/it] 50%|█████     | 287/570 [10:25<09:23,  1.99s/it] 51%|█████     | 288/570 [10:27<09:29,  2.02s/it] 51%|█████     | 289/570 [10:29<09:36,  2.05s/it] 51%|█████     | 290/570 [10:31<09:36,  2.06s/it] 51%|█████     | 291/570 [10:33<09:39,  2.08s/it] 51%|█████     | 292/570 [10:35<09:34,  2.07s/it] 51%|█████▏    | 293/570 [10:37<09:34,  2.07s/it] 52%|█████▏    | 294/570 [10:39<09:30,  2.07s/it] 52%|█████▏    | 295/570 [10:41<09:26,  2.06s/it] 52%|█████▏    | 296/570 [10:43<09:23,  2.06s/it] 52%|█████▏    | 297/570 [10:45<09:25,  2.07s/it] 52%|█████▏    | 298/570 [10:47<09:20,  2.06s/it] 52%|█████▏    | 299/570 [10:49<09:16,  2.05s/it] 53%|█████▎    | 300/570 [10:51<09:14,  2.05s/it]11/08/2022 13:55:28 - ***** Running Evaluation *****
11/08/2022 13:55:28 -   Num examples = 96
11/08/2022 13:55:28 -   Batch size = 32
{'eval_loss': 1.6322153806686401, 'eval_precision': 0.6190476190476191, 'eval_recall': 0.625, 'eval_f1': 0.6220095693779905, 'epoch': 13.16}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.93s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.90s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
                                                  53%|█████▎    | 300/570 [10:58<09:14,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-300
Configuration saved in models/role_gp/checkpoint-300/config.json
Model weights saved in models/role_gp/checkpoint-300/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-50] due to args.save_total_limit
 53%|█████▎    | 301/570 [11:02<20:07,  4.49s/it] 53%|█████▎    | 302/570 [11:04<16:46,  3.76s/it] 53%|█████▎    | 303/570 [11:06<14:25,  3.24s/it] 53%|█████▎    | 304/570 [11:07<12:01,  2.71s/it] 54%|█████▎    | 305/570 [11:09<11:04,  2.51s/it] 54%|█████▎    | 306/570 [11:11<10:28,  2.38s/it] 54%|█████▍    | 307/570 [11:13<09:57,  2.27s/it] 54%|█████▍    | 308/570 [11:15<09:36,  2.20s/it] 54%|█████▍    | 309/570 [11:17<09:21,  2.15s/it] 54%|█████▍    | 310/570 [11:19<09:14,  2.13s/it] 55%|█████▍    | 311/570 [11:21<09:04,  2.10s/it] 55%|█████▍    | 312/570 [11:24<08:57,  2.08s/it] 55%|█████▍    | 313/570 [11:26<08:51,  2.07s/it] 55%|█████▌    | 314/570 [11:28<08:50,  2.07s/it] 55%|█████▌    | 315/570 [11:30<08:45,  2.06s/it] 55%|█████▌    | 316/570 [11:32<08:41,  2.05s/it] 56%|█████▌    | 317/570 [11:34<08:38,  2.05s/it] 56%|█████▌    | 318/570 [11:36<08:39,  2.06s/it] 56%|█████▌    | 319/570 [11:38<08:35,  2.05s/it] 56%|█████▌    | 320/570 [11:40<08:31,  2.05s/it] 56%|█████▋    | 321/570 [11:42<08:28,  2.04s/it] 56%|█████▋    | 322/570 [11:44<08:29,  2.05s/it] 57%|█████▋    | 323/570 [11:45<07:43,  1.88s/it] 57%|█████▋    | 324/570 [11:48<07:53,  1.92s/it] 57%|█████▋    | 325/570 [11:50<07:58,  1.95s/it] 57%|█████▋    | 326/570 [11:52<08:03,  1.98s/it] 57%|█████▋    | 327/570 [11:54<08:05,  2.00s/it] 58%|█████▊    | 328/570 [11:56<08:06,  2.01s/it] 58%|█████▊    | 329/570 [11:58<08:06,  2.02s/it] 58%|█████▊    | 330/570 [12:00<08:05,  2.02s/it] 58%|█████▊    | 331/570 [12:02<08:07,  2.04s/it] 58%|█████▊    | 332/570 [12:04<08:05,  2.04s/it] 58%|█████▊    | 333/570 [12:06<08:03,  2.04s/it] 59%|█████▊    | 334/570 [12:08<08:01,  2.04s/it] 59%|█████▉    | 335/570 [12:10<08:02,  2.05s/it] 59%|█████▉    | 336/570 [12:12<07:59,  2.05s/it] 59%|█████▉    | 337/570 [12:14<07:56,  2.05s/it] 59%|█████▉    | 338/570 [12:16<07:55,  2.05s/it] 59%|█████▉    | 339/570 [12:18<07:56,  2.06s/it] 60%|█████▉    | 340/570 [12:20<07:52,  2.06s/it] 60%|█████▉    | 341/570 [12:22<07:50,  2.05s/it] 60%|██████    | 342/570 [12:24<07:08,  1.88s/it] 60%|██████    | 343/570 [12:26<07:22,  1.95s/it] 60%|██████    | 344/570 [12:28<07:27,  1.98s/it] 61%|██████    | 345/570 [12:30<07:29,  2.00s/it] 61%|██████    | 346/570 [12:32<07:29,  2.01s/it] 61%|██████    | 347/570 [12:34<07:32,  2.03s/it] 61%|██████    | 348/570 [12:36<07:31,  2.03s/it] 61%|██████    | 349/570 [12:38<07:30,  2.04s/it] 61%|██████▏   | 350/570 [12:40<07:29,  2.04s/it]11/08/2022 13:57:16 - ***** Running Evaluation *****
11/08/2022 13:57:16 -   Num examples = 96
11/08/2022 13:57:16 -   Batch size = 32
{'eval_loss': 1.7166871229807537, 'eval_precision': 0.5958702064896755, 'eval_recall': 0.6474358974358975, 'eval_f1': 0.620583717357911, 'epoch': 15.79}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.89s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.88s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]
                                                  61%|██████▏   | 350/570 [12:46<07:29,  2.04s/it]Saving model checkpoint to models/role_gp/checkpoint-350
Configuration saved in models/role_gp/checkpoint-350/config.json
Model weights saved in models/role_gp/checkpoint-350/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-100] due to args.save_total_limit
 62%|██████▏   | 351/570 [12:50<16:16,  4.46s/it] 62%|██████▏   | 352/570 [12:52<13:36,  3.75s/it] 62%|██████▏   | 353/570 [12:54<11:42,  3.24s/it] 62%|██████▏   | 354/570 [12:57<10:22,  2.88s/it] 62%|██████▏   | 355/570 [12:59<09:25,  2.63s/it] 62%|██████▏   | 356/570 [13:01<08:48,  2.47s/it] 63%|██████▎   | 357/570 [13:03<08:18,  2.34s/it] 63%|██████▎   | 358/570 [13:05<07:57,  2.25s/it] 63%|██████▎   | 359/570 [13:07<07:41,  2.19s/it] 63%|██████▎   | 360/570 [13:09<07:33,  2.16s/it] 63%|██████▎   | 361/570 [13:10<06:49,  1.96s/it] 64%|██████▎   | 362/570 [13:12<06:52,  1.98s/it] 64%|██████▎   | 363/570 [13:14<06:53,  2.00s/it] 64%|██████▍   | 364/570 [13:17<06:56,  2.02s/it] 64%|██████▍   | 365/570 [13:19<06:55,  2.03s/it] 64%|██████▍   | 366/570 [13:21<06:54,  2.03s/it] 64%|██████▍   | 367/570 [13:23<06:52,  2.03s/it] 65%|██████▍   | 368/570 [13:25<06:53,  2.05s/it] 65%|██████▍   | 369/570 [13:27<06:50,  2.04s/it] 65%|██████▍   | 370/570 [13:29<06:48,  2.04s/it] 65%|██████▌   | 371/570 [13:31<06:46,  2.04s/it] 65%|██████▌   | 372/570 [13:33<06:46,  2.05s/it] 65%|██████▌   | 373/570 [13:35<06:44,  2.06s/it] 66%|██████▌   | 374/570 [13:37<06:42,  2.05s/it] 66%|██████▌   | 375/570 [13:39<06:39,  2.05s/it] 66%|██████▌   | 376/570 [13:41<06:38,  2.05s/it] 66%|██████▌   | 377/570 [13:43<06:36,  2.05s/it] 66%|██████▋   | 378/570 [13:45<06:34,  2.05s/it] 66%|██████▋   | 379/570 [13:47<06:31,  2.05s/it] 67%|██████▋   | 380/570 [13:49<05:57,  1.88s/it] 67%|██████▋   | 381/570 [13:51<06:08,  1.95s/it] 67%|██████▋   | 382/570 [13:53<06:12,  1.98s/it] 67%|██████▋   | 383/570 [13:55<06:14,  2.00s/it] 67%|██████▋   | 384/570 [13:57<06:14,  2.01s/it] 68%|██████▊   | 385/570 [13:59<06:17,  2.04s/it] 68%|██████▊   | 386/570 [14:01<06:16,  2.05s/it] 68%|██████▊   | 387/570 [14:03<06:13,  2.04s/it] 68%|██████▊   | 388/570 [14:05<06:12,  2.04s/it] 68%|██████▊   | 389/570 [14:07<06:12,  2.06s/it] 68%|██████▊   | 390/570 [14:09<06:10,  2.06s/it] 69%|██████▊   | 391/570 [14:11<06:07,  2.05s/it] 69%|██████▉   | 392/570 [14:14<06:05,  2.05s/it] 69%|██████▉   | 393/570 [14:16<06:06,  2.07s/it] 69%|██████▉   | 394/570 [14:18<06:02,  2.06s/it] 69%|██████▉   | 395/570 [14:20<05:59,  2.06s/it] 69%|██████▉   | 396/570 [14:22<05:57,  2.05s/it] 70%|██████▉   | 397/570 [14:24<05:57,  2.06s/it] 70%|██████▉   | 398/570 [14:26<05:54,  2.06s/it] 70%|███████   | 399/570 [14:27<05:22,  1.88s/it] 70%|███████   | 400/570 [14:29<05:28,  1.93s/it]11/08/2022 13:59:06 - ***** Running Evaluation *****
11/08/2022 13:59:06 -   Num examples = 96
11/08/2022 13:59:06 -   Batch size = 32
{'eval_loss': 1.6796355644861858, 'eval_precision': 0.638095238095238, 'eval_recall': 0.6442307692307693, 'eval_f1': 0.6411483253588517, 'epoch': 18.42}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.89s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.89s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
                                                  70%|███████   | 400/570 [14:36<05:28,  1.93s/it]Saving model checkpoint to models/role_gp/checkpoint-400
Configuration saved in models/role_gp/checkpoint-400/config.json
Model weights saved in models/role_gp/checkpoint-400/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-150] due to args.save_total_limit
 70%|███████   | 401/570 [14:39<12:19,  4.38s/it] 71%|███████   | 402/570 [14:42<10:20,  3.69s/it] 71%|███████   | 403/570 [14:44<08:54,  3.20s/it] 71%|███████   | 404/570 [14:46<07:53,  2.85s/it] 71%|███████   | 405/570 [14:48<07:10,  2.61s/it] 71%|███████   | 406/570 [14:50<06:42,  2.45s/it] 71%|███████▏  | 407/570 [14:52<06:19,  2.33s/it] 72%|███████▏  | 408/570 [14:54<06:03,  2.25s/it] 72%|███████▏  | 409/570 [14:56<05:51,  2.18s/it] 72%|███████▏  | 410/570 [14:58<05:44,  2.15s/it] 72%|███████▏  | 411/570 [15:00<05:37,  2.12s/it] 72%|███████▏  | 412/570 [15:02<05:31,  2.10s/it] 72%|███████▏  | 413/570 [15:04<05:27,  2.09s/it] 73%|███████▎  | 414/570 [15:06<05:26,  2.09s/it] 73%|███████▎  | 415/570 [15:08<05:22,  2.08s/it] 73%|███████▎  | 416/570 [15:10<05:18,  2.07s/it] 73%|███████▎  | 417/570 [15:12<05:16,  2.07s/it] 73%|███████▎  | 418/570 [15:14<04:50,  1.91s/it] 74%|███████▎  | 419/570 [15:16<04:56,  1.96s/it] 74%|███████▎  | 420/570 [15:18<04:59,  2.00s/it] 74%|███████▍  | 421/570 [15:20<05:00,  2.02s/it] 74%|███████▍  | 422/570 [15:22<05:02,  2.05s/it] 74%|███████▍  | 423/570 [15:25<05:10,  2.11s/it] 74%|███████▍  | 424/570 [15:27<05:14,  2.15s/it] 75%|███████▍  | 425/570 [15:29<05:14,  2.17s/it] 75%|███████▍  | 426/570 [15:31<05:13,  2.18s/it] 75%|███████▍  | 427/570 [15:33<05:05,  2.14s/it] 75%|███████▌  | 428/570 [15:35<04:59,  2.11s/it] 75%|███████▌  | 429/570 [15:37<04:54,  2.09s/it] 75%|███████▌  | 430/570 [15:39<04:52,  2.09s/it] 76%|███████▌  | 431/570 [15:42<04:48,  2.08s/it] 76%|███████▌  | 432/570 [15:44<04:45,  2.07s/it] 76%|███████▌  | 433/570 [15:46<04:42,  2.06s/it] 76%|███████▌  | 434/570 [15:48<04:42,  2.07s/it] 76%|███████▋  | 435/570 [15:50<04:38,  2.06s/it] 76%|███████▋  | 436/570 [15:52<04:35,  2.06s/it] 77%|███████▋  | 437/570 [15:53<04:10,  1.88s/it] 77%|███████▋  | 438/570 [15:55<04:15,  1.93s/it] 77%|███████▋  | 439/570 [15:57<04:19,  1.98s/it] 77%|███████▋  | 440/570 [15:59<04:19,  2.00s/it] 77%|███████▋  | 441/570 [16:01<04:18,  2.01s/it] 78%|███████▊  | 442/570 [16:04<04:18,  2.02s/it] 78%|███████▊  | 443/570 [16:06<04:18,  2.04s/it] 78%|███████▊  | 444/570 [16:08<04:17,  2.04s/it] 78%|███████▊  | 445/570 [16:10<04:14,  2.04s/it] 78%|███████▊  | 446/570 [16:12<04:12,  2.04s/it] 78%|███████▊  | 447/570 [16:14<04:12,  2.06s/it] 79%|███████▊  | 448/570 [16:16<04:10,  2.05s/it] 79%|███████▉  | 449/570 [16:18<04:07,  2.05s/it] 79%|███████▉  | 450/570 [16:20<04:05,  2.05s/it]11/08/2022 14:00:56 - ***** Running Evaluation *****
11/08/2022 14:00:56 -   Num examples = 96
11/08/2022 14:00:56 -   Batch size = 32
{'eval_loss': 1.7936936219533284, 'eval_precision': 0.6403785488958991, 'eval_recall': 0.6506410256410257, 'eval_f1': 0.6454689984101749, 'epoch': 21.05}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.94s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
                                                  79%|███████▉  | 450/570 [16:26<04:05,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-450
Configuration saved in models/role_gp/checkpoint-450/config.json
Model weights saved in models/role_gp/checkpoint-450/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-200] due to args.save_total_limit
 79%|███████▉  | 451/570 [16:30<08:57,  4.52s/it] 79%|███████▉  | 452/570 [16:32<07:25,  3.77s/it] 79%|███████▉  | 453/570 [16:34<06:20,  3.25s/it] 80%|███████▉  | 454/570 [16:36<05:35,  2.89s/it] 80%|███████▉  | 455/570 [16:38<05:04,  2.65s/it] 80%|████████  | 456/570 [16:40<04:22,  2.30s/it] 80%|████████  | 457/570 [16:42<04:11,  2.22s/it] 80%|████████  | 458/570 [16:44<04:02,  2.17s/it] 81%|████████  | 459/570 [16:46<03:56,  2.13s/it] 81%|████████  | 460/570 [16:48<03:51,  2.10s/it] 81%|████████  | 461/570 [16:50<03:46,  2.08s/it] 81%|████████  | 462/570 [16:52<03:43,  2.07s/it] 81%|████████  | 463/570 [16:54<03:40,  2.06s/it] 81%|████████▏ | 464/570 [16:56<03:39,  2.07s/it] 82%|████████▏ | 465/570 [16:58<03:36,  2.06s/it] 82%|████████▏ | 466/570 [17:00<03:33,  2.05s/it] 82%|████████▏ | 467/570 [17:02<03:30,  2.05s/it] 82%|████████▏ | 468/570 [17:04<03:29,  2.06s/it] 82%|████████▏ | 469/570 [17:07<03:27,  2.05s/it] 82%|████████▏ | 470/570 [17:09<03:25,  2.06s/it] 83%|████████▎ | 471/570 [17:11<03:23,  2.05s/it] 83%|████████▎ | 472/570 [17:13<03:22,  2.06s/it] 83%|████████▎ | 473/570 [17:15<03:19,  2.06s/it] 83%|████████▎ | 474/570 [17:17<03:16,  2.05s/it] 83%|████████▎ | 475/570 [17:18<02:58,  1.88s/it] 84%|████████▎ | 476/570 [17:20<03:02,  1.95s/it] 84%|████████▎ | 477/570 [17:22<03:04,  1.98s/it] 84%|████████▍ | 478/570 [17:24<03:04,  2.00s/it] 84%|████████▍ | 479/570 [17:27<03:03,  2.01s/it] 84%|████████▍ | 480/570 [17:29<03:03,  2.04s/it] 84%|████████▍ | 481/570 [17:31<03:01,  2.04s/it] 85%|████████▍ | 482/570 [17:33<02:59,  2.04s/it] 85%|████████▍ | 483/570 [17:35<02:57,  2.04s/it] 85%|████████▍ | 484/570 [17:37<02:56,  2.05s/it] 85%|████████▌ | 485/570 [17:39<02:54,  2.05s/it] 85%|████████▌ | 486/570 [17:41<02:51,  2.05s/it] 85%|████████▌ | 487/570 [17:43<02:49,  2.05s/it] 86%|████████▌ | 488/570 [17:45<02:47,  2.05s/it] 86%|████████▌ | 489/570 [17:47<02:46,  2.05s/it] 86%|████████▌ | 490/570 [17:49<02:43,  2.05s/it] 86%|████████▌ | 491/570 [17:51<02:41,  2.05s/it] 86%|████████▋ | 492/570 [17:53<02:39,  2.05s/it] 86%|████████▋ | 493/570 [17:55<02:37,  2.05s/it] 87%|████████▋ | 494/570 [17:57<02:22,  1.88s/it] 87%|████████▋ | 495/570 [17:59<02:24,  1.93s/it] 87%|████████▋ | 496/570 [18:01<02:25,  1.96s/it] 87%|████████▋ | 497/570 [18:03<02:26,  2.00s/it] 87%|████████▋ | 498/570 [18:05<02:24,  2.01s/it] 88%|████████▊ | 499/570 [18:07<02:23,  2.02s/it] 88%|████████▊ | 500/570 [18:09<02:21,  2.03s/it]                                                  88%|████████▊ | 500/570 [18:09<02:21,  2.03s/it]11/08/2022 14:02:45 - ***** Running Evaluation *****
11/08/2022 14:02:45 -   Num examples = 96
11/08/2022 14:02:45 -   Batch size = 32
{'eval_loss': 1.7749327023824055, 'eval_precision': 0.5988538681948424, 'eval_recall': 0.6698717948717948, 'eval_f1': 0.632375189107413, 'epoch': 23.68}
{'loss': 0.2661, 'learning_rate': 6.140350877192982e-06, 'epoch': 26.32}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.93s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.90s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
                                                  88%|████████▊ | 500/570 [18:15<02:21,  2.03s/it]Saving model checkpoint to models/role_gp/checkpoint-500
Configuration saved in models/role_gp/checkpoint-500/config.json
Model weights saved in models/role_gp/checkpoint-500/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-250] due to args.save_total_limit
 88%|████████▊ | 501/570 [18:19<05:07,  4.45s/it] 88%|████████▊ | 502/570 [18:21<04:13,  3.73s/it] 88%|████████▊ | 503/570 [18:23<03:35,  3.22s/it] 88%|████████▊ | 504/570 [18:25<03:08,  2.86s/it] 89%|████████▊ | 505/570 [18:27<02:50,  2.63s/it] 89%|████████▉ | 506/570 [18:29<02:36,  2.45s/it] 89%|████████▉ | 507/570 [18:31<02:26,  2.32s/it] 89%|████████▉ | 508/570 [18:33<02:18,  2.24s/it] 89%|████████▉ | 509/570 [18:35<02:12,  2.17s/it] 89%|████████▉ | 510/570 [18:37<02:08,  2.14s/it] 90%|████████▉ | 511/570 [18:40<02:04,  2.11s/it] 90%|████████▉ | 512/570 [18:42<02:00,  2.08s/it] 90%|█████████ | 513/570 [18:43<01:48,  1.90s/it] 90%|█████████ | 514/570 [18:45<01:49,  1.96s/it] 90%|█████████ | 515/570 [18:47<01:48,  1.98s/it] 91%|█████████ | 516/570 [18:49<01:47,  1.99s/it] 91%|█████████ | 517/570 [18:51<01:46,  2.00s/it] 91%|█████████ | 518/570 [18:53<01:45,  2.03s/it] 91%|█████████ | 519/570 [18:55<01:43,  2.03s/it] 91%|█████████ | 520/570 [18:57<01:41,  2.03s/it] 91%|█████████▏| 521/570 [18:59<01:39,  2.03s/it] 92%|█████████▏| 522/570 [19:01<01:38,  2.05s/it] 92%|█████████▏| 523/570 [19:04<01:35,  2.04s/it] 92%|█████████▏| 524/570 [19:06<01:33,  2.04s/it] 92%|█████████▏| 525/570 [19:08<01:31,  2.03s/it] 92%|█████████▏| 526/570 [19:10<01:30,  2.05s/it] 92%|█████████▏| 527/570 [19:12<01:28,  2.05s/it] 93%|█████████▎| 528/570 [19:14<01:25,  2.05s/it] 93%|█████████▎| 529/570 [19:16<01:23,  2.04s/it] 93%|█████████▎| 530/570 [19:18<01:22,  2.05s/it] 93%|█████████▎| 531/570 [19:20<01:19,  2.05s/it] 93%|█████████▎| 532/570 [19:21<01:11,  1.88s/it] 94%|█████████▎| 533/570 [19:23<01:11,  1.92s/it] 94%|█████████▎| 534/570 [19:25<01:10,  1.96s/it] 94%|█████████▍| 535/570 [19:27<01:09,  1.99s/it] 94%|█████████▍| 536/570 [19:30<01:07,  2.00s/it] 94%|█████████▍| 537/570 [19:32<01:06,  2.01s/it] 94%|█████████▍| 538/570 [19:34<01:04,  2.01s/it] 95%|█████████▍| 539/570 [19:36<01:03,  2.04s/it] 95%|█████████▍| 540/570 [19:38<01:00,  2.03s/it] 95%|█████████▍| 541/570 [19:40<00:58,  2.03s/it] 95%|█████████▌| 542/570 [19:42<00:56,  2.03s/it] 95%|█████████▌| 543/570 [19:44<00:55,  2.04s/it] 95%|█████████▌| 544/570 [19:46<00:52,  2.04s/it] 96%|█████████▌| 545/570 [19:48<00:50,  2.03s/it] 96%|█████████▌| 546/570 [19:50<00:48,  2.03s/it] 96%|█████████▌| 547/570 [19:52<00:47,  2.05s/it] 96%|█████████▌| 548/570 [19:54<00:44,  2.04s/it] 96%|█████████▋| 549/570 [19:56<00:42,  2.04s/it] 96%|█████████▋| 550/570 [19:58<00:40,  2.03s/it]11/08/2022 14:04:34 - ***** Running Evaluation *****
11/08/2022 14:04:34 -   Num examples = 96
11/08/2022 14:04:34 -   Batch size = 32
{'eval_loss': 1.8584980567296345, 'eval_precision': 0.6369426751592356, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6389776357827476, 'epoch': 26.32}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.91s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.89s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
                                                  96%|█████████▋| 550/570 [20:04<00:40,  2.03s/it]Saving model checkpoint to models/role_gp/checkpoint-550
Configuration saved in models/role_gp/checkpoint-550/config.json
Model weights saved in models/role_gp/checkpoint-550/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-300] due to args.save_total_limit
 97%|█████████▋| 551/570 [20:08<01:21,  4.29s/it] 97%|█████████▋| 552/570 [20:10<01:05,  3.63s/it] 97%|█████████▋| 553/570 [20:12<00:53,  3.14s/it] 97%|█████████▋| 554/570 [20:14<00:44,  2.81s/it] 97%|█████████▋| 555/570 [20:16<00:38,  2.57s/it] 98%|█████████▊| 556/570 [20:18<00:33,  2.42s/it] 98%|█████████▊| 557/570 [20:20<00:29,  2.30s/it] 98%|█████████▊| 558/570 [20:22<00:26,  2.22s/it] 98%|█████████▊| 559/570 [20:24<00:23,  2.16s/it] 98%|█████████▊| 560/570 [20:26<00:21,  2.14s/it] 98%|█████████▊| 561/570 [20:28<00:18,  2.11s/it] 99%|█████████▊| 562/570 [20:30<00:16,  2.08s/it] 99%|█████████▉| 563/570 [20:32<00:14,  2.07s/it] 99%|█████████▉| 564/570 [20:34<00:12,  2.07s/it] 99%|█████████▉| 565/570 [20:36<00:10,  2.06s/it] 99%|█████████▉| 566/570 [20:38<00:08,  2.05s/it] 99%|█████████▉| 567/570 [20:40<00:06,  2.04s/it]100%|█████████▉| 568/570 [20:42<00:04,  2.05s/it]100%|█████████▉| 569/570 [20:44<00:02,  2.04s/it]100%|██████████| 570/570 [20:46<00:00,  1.87s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 570/570 [20:46<00:00,  1.87s/it]100%|██████████| 570/570 [20:46<00:00,  2.19s/it]
***** Running training *****
  Num examples = 599
  Num Epochs = 30
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 570
{'eval_loss': 1.8740636110305786, 'eval_precision': 0.6483870967741936, 'eval_recall': 0.6442307692307693, 'eval_f1': 0.6463022508038585, 'epoch': 28.95}
{'train_runtime': 1246.2835, 'train_samples_per_second': 14.419, 'train_steps_per_second': 0.457, 'train_loss': 0.23614103647700527, 'epoch': 30.0}
  0%|          | 0/570 [00:00<?, ?it/s]  0%|          | 1/570 [00:02<19:17,  2.03s/it]  0%|          | 2/570 [00:04<19:13,  2.03s/it]  1%|          | 3/570 [00:06<19:14,  2.04s/it]  1%|          | 4/570 [00:08<19:07,  2.03s/it]  1%|          | 5/570 [00:10<19:06,  2.03s/it]  1%|          | 6/570 [00:12<19:05,  2.03s/it]  1%|          | 7/570 [00:14<19:14,  2.05s/it]  1%|▏         | 8/570 [00:16<19:11,  2.05s/it]  2%|▏         | 9/570 [00:18<19:04,  2.04s/it]  2%|▏         | 10/570 [00:20<19:00,  2.04s/it]  2%|▏         | 11/570 [00:22<19:04,  2.05s/it]  2%|▏         | 12/570 [00:24<18:59,  2.04s/it]  2%|▏         | 13/570 [00:26<18:56,  2.04s/it]  2%|▏         | 14/570 [00:28<18:58,  2.05s/it]  3%|▎         | 15/570 [00:30<19:01,  2.06s/it]  3%|▎         | 16/570 [00:32<18:58,  2.05s/it]  3%|▎         | 17/570 [00:34<18:52,  2.05s/it]  3%|▎         | 18/570 [00:36<18:47,  2.04s/it]  3%|▎         | 19/570 [00:38<17:23,  1.89s/it]  4%|▎         | 20/570 [00:40<17:47,  1.94s/it]  4%|▎         | 21/570 [00:42<18:02,  1.97s/it]  4%|▍         | 22/570 [00:44<18:12,  1.99s/it]  4%|▍         | 23/570 [00:46<18:22,  2.02s/it]  4%|▍         | 24/570 [00:48<18:24,  2.02s/it]  4%|▍         | 25/570 [00:50<18:27,  2.03s/it]  5%|▍         | 26/570 [00:52<18:27,  2.04s/it]  5%|▍         | 27/570 [00:54<18:26,  2.04s/it]  5%|▍         | 28/570 [00:56<18:25,  2.04s/it]  5%|▌         | 29/570 [00:58<18:25,  2.04s/it]  5%|▌         | 30/570 [01:00<18:24,  2.05s/it]  5%|▌         | 31/570 [01:02<18:23,  2.05s/it]  6%|▌         | 32/570 [01:04<18:26,  2.06s/it]  6%|▌         | 33/570 [01:07<18:21,  2.05s/it]  6%|▌         | 34/570 [01:09<18:17,  2.05s/it]  6%|▌         | 35/570 [01:11<18:15,  2.05s/it]  6%|▋         | 36/570 [01:13<18:20,  2.06s/it]  6%|▋         | 37/570 [01:15<18:16,  2.06s/it]  7%|▋         | 38/570 [01:16<16:47,  1.89s/it]  7%|▋         | 39/570 [01:18<17:10,  1.94s/it]  7%|▋         | 40/570 [01:20<17:34,  1.99s/it]  7%|▋         | 41/570 [01:22<17:41,  2.01s/it]  7%|▋         | 42/570 [01:24<17:44,  2.02s/it]  8%|▊         | 43/570 [01:27<17:46,  2.02s/it]  8%|▊         | 44/570 [01:29<17:56,  2.05s/it]  8%|▊         | 45/570 [01:31<17:56,  2.05s/it]  8%|▊         | 46/570 [01:33<17:55,  2.05s/it]  8%|▊         | 47/570 [01:35<17:52,  2.05s/it]  8%|▊         | 48/570 [01:37<17:57,  2.06s/it]  9%|▊         | 49/570 [01:39<17:52,  2.06s/it]  9%|▉         | 50/570 [01:41<17:49,  2.06s/it]11/08/2022 14:07:04 - ***** Running Evaluation *****
11/08/2022 14:07:04 -   Num examples = 96
11/08/2022 14:07:04 -   Batch size = 32

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.94s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]
                                                  9%|▉         | 50/570 [01:47<17:49,  2.06s/it]Saving model checkpoint to models/role_gp/checkpoint-50
Configuration saved in models/role_gp/checkpoint-50/config.json
Model weights saved in models/role_gp/checkpoint-50/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-350] due to args.save_total_limit
  9%|▉         | 51/570 [01:51<39:29,  4.57s/it]  9%|▉         | 52/570 [01:54<33:11,  3.84s/it]  9%|▉         | 53/570 [01:56<28:43,  3.33s/it]  9%|▉         | 54/570 [01:58<25:34,  2.97s/it] 10%|▉         | 55/570 [02:00<23:21,  2.72s/it] 10%|▉         | 56/570 [02:02<21:54,  2.56s/it] 10%|█         | 57/570 [02:04<19:20,  2.26s/it] 10%|█         | 58/570 [02:06<18:57,  2.22s/it] 10%|█         | 59/570 [02:08<18:41,  2.19s/it] 11%|█         | 60/570 [02:10<18:34,  2.18s/it] 11%|█         | 61/570 [02:12<18:25,  2.17s/it] 11%|█         | 62/570 [02:14<18:18,  2.16s/it] 11%|█         | 63/570 [02:17<18:14,  2.16s/it] 11%|█         | 64/570 [02:19<18:15,  2.16s/it] 11%|█▏        | 65/570 [02:21<18:09,  2.16s/it] 12%|█▏        | 66/570 [02:23<18:05,  2.15s/it] 12%|█▏        | 67/570 [02:25<18:02,  2.15s/it] 12%|█▏        | 68/570 [02:27<18:04,  2.16s/it] 12%|█▏        | 69/570 [02:30<17:59,  2.15s/it] 12%|█▏        | 70/570 [02:32<17:55,  2.15s/it] 12%|█▏        | 71/570 [02:34<17:53,  2.15s/it] 13%|█▎        | 72/570 [02:36<17:55,  2.16s/it] 13%|█▎        | 73/570 [02:38<17:50,  2.15s/it] 13%|█▎        | 74/570 [02:40<17:46,  2.15s/it] 13%|█▎        | 75/570 [02:42<17:44,  2.15s/it] 13%|█▎        | 76/570 [02:44<16:20,  1.98s/it] 14%|█▎        | 77/570 [02:46<16:40,  2.03s/it] 14%|█▎        | 78/570 [02:48<16:54,  2.06s/it] 14%|█▍        | 79/570 [02:50<17:02,  2.08s/it] 14%|█▍        | 80/570 [02:53<17:14,  2.11s/it] 14%|█▍        | 81/570 [02:55<17:17,  2.12s/it] 14%|█▍        | 82/570 [02:57<17:18,  2.13s/it] 15%|█▍        | 83/570 [02:59<17:17,  2.13s/it] 15%|█▍        | 84/570 [03:01<17:22,  2.15s/it] 15%|█▍        | 85/570 [03:03<17:19,  2.14s/it] 15%|█▌        | 86/570 [03:05<17:16,  2.14s/it] 15%|█▌        | 87/570 [03:08<17:14,  2.14s/it] 15%|█▌        | 88/570 [03:10<17:17,  2.15s/it] 16%|█▌        | 89/570 [03:12<17:13,  2.15s/it] 16%|█▌        | 90/570 [03:14<17:10,  2.15s/it] 16%|█▌        | 91/570 [03:16<17:09,  2.15s/it] 16%|█▌        | 92/570 [03:18<17:12,  2.16s/it] 16%|█▋        | 93/570 [03:21<17:08,  2.16s/it] 16%|█▋        | 94/570 [03:23<17:05,  2.15s/it] 17%|█▋        | 95/570 [03:24<15:37,  1.97s/it] 17%|█▋        | 96/570 [03:26<16:07,  2.04s/it] 17%|█▋        | 97/570 [03:29<16:18,  2.07s/it] 17%|█▋        | 98/570 [03:31<16:26,  2.09s/it] 17%|█▋        | 99/570 [03:33<16:27,  2.10s/it] 18%|█▊        | 100/570 [03:35<16:28,  2.10s/it]11/08/2022 14:08:58 - ***** Running Evaluation *****
11/08/2022 14:08:58 -   Num examples = 96
11/08/2022 14:08:58 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 2.63}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.88s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]
                                                  18%|█▊        | 100/570 [03:41<16:28,  2.10s/it]Saving model checkpoint to models/role_gp/checkpoint-100
Configuration saved in models/role_gp/checkpoint-100/config.json
Model weights saved in models/role_gp/checkpoint-100/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-400] due to args.save_total_limit
 18%|█▊        | 101/570 [03:45<35:21,  4.52s/it] 18%|█▊        | 102/570 [03:47<29:29,  3.78s/it] 18%|█▊        | 103/570 [03:49<25:22,  3.26s/it] 18%|█▊        | 104/570 [03:51<22:37,  2.91s/it] 18%|█▊        | 105/570 [03:53<20:34,  2.66s/it] 19%|█▊        | 106/570 [03:55<19:04,  2.47s/it] 19%|█▉        | 107/570 [03:57<18:02,  2.34s/it] 19%|█▉        | 108/570 [04:00<17:25,  2.26s/it] 19%|█▉        | 109/570 [04:02<16:51,  2.19s/it] 19%|█▉        | 110/570 [04:04<16:27,  2.15s/it] 19%|█▉        | 111/570 [04:06<16:09,  2.11s/it] 20%|█▉        | 112/570 [04:08<15:57,  2.09s/it] 20%|█▉        | 113/570 [04:10<15:49,  2.08s/it] 20%|██        | 114/570 [04:11<14:26,  1.90s/it] 20%|██        | 115/570 [04:13<14:44,  1.94s/it] 20%|██        | 116/570 [04:15<14:56,  1.97s/it] 21%|██        | 117/570 [04:17<15:10,  2.01s/it] 21%|██        | 118/570 [04:19<15:12,  2.02s/it] 21%|██        | 119/570 [04:22<15:14,  2.03s/it] 21%|██        | 120/570 [04:24<15:14,  2.03s/it] 21%|██        | 121/570 [04:26<15:20,  2.05s/it] 21%|██▏       | 122/570 [04:28<15:17,  2.05s/it] 22%|██▏       | 123/570 [04:30<15:15,  2.05s/it] 22%|██▏       | 124/570 [04:32<15:12,  2.04s/it] 22%|██▏       | 125/570 [04:34<15:16,  2.06s/it] 22%|██▏       | 126/570 [04:36<15:12,  2.05s/it] 22%|██▏       | 127/570 [04:38<15:08,  2.05s/it] 22%|██▏       | 128/570 [04:40<15:04,  2.05s/it] 23%|██▎       | 129/570 [04:42<15:08,  2.06s/it] 23%|██▎       | 130/570 [04:44<15:03,  2.05s/it] 23%|██▎       | 131/570 [04:46<14:59,  2.05s/it] 23%|██▎       | 132/570 [04:48<14:56,  2.05s/it] 23%|██▎       | 133/570 [04:50<13:40,  1.88s/it] 24%|██▎       | 134/570 [04:52<14:00,  1.93s/it] 24%|██▎       | 135/570 [04:54<14:13,  1.96s/it] 24%|██▍       | 136/570 [04:56<14:22,  1.99s/it] 24%|██▍       | 137/570 [04:58<14:29,  2.01s/it] 24%|██▍       | 138/570 [05:00<14:36,  2.03s/it] 24%|██▍       | 139/570 [05:02<14:36,  2.03s/it] 25%|██▍       | 140/570 [05:04<14:34,  2.03s/it] 25%|██▍       | 141/570 [05:06<14:33,  2.04s/it] 25%|██▍       | 142/570 [05:08<14:36,  2.05s/it] 25%|██▌       | 143/570 [05:10<14:32,  2.04s/it] 25%|██▌       | 144/570 [05:12<14:30,  2.04s/it] 25%|██▌       | 145/570 [05:14<14:28,  2.04s/it] 26%|██▌       | 146/570 [05:16<14:34,  2.06s/it] 26%|██▌       | 147/570 [05:18<14:30,  2.06s/it] 26%|██▌       | 148/570 [05:20<14:27,  2.05s/it] 26%|██▌       | 149/570 [05:23<14:23,  2.05s/it] 26%|██▋       | 150/570 [05:25<14:26,  2.06s/it]11/08/2022 14:10:47 - ***** Running Evaluation *****
11/08/2022 14:10:47 -   Num examples = 96
11/08/2022 14:10:47 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 5.26}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.89s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.89s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
                                                  26%|██▋       | 150/570 [05:31<14:26,  2.06s/it]Saving model checkpoint to models/role_gp/checkpoint-150
Configuration saved in models/role_gp/checkpoint-150/config.json
Model weights saved in models/role_gp/checkpoint-150/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-450] due to args.save_total_limit
 26%|██▋       | 151/570 [05:35<31:19,  4.49s/it] 27%|██▋       | 152/570 [05:36<24:59,  3.59s/it] 27%|██▋       | 153/570 [05:38<21:42,  3.12s/it] 27%|██▋       | 154/570 [05:40<19:30,  2.81s/it] 27%|██▋       | 155/570 [05:42<17:51,  2.58s/it] 27%|██▋       | 156/570 [05:44<16:42,  2.42s/it] 28%|██▊       | 157/570 [05:46<15:53,  2.31s/it] 28%|██▊       | 158/570 [05:49<15:19,  2.23s/it] 28%|██▊       | 159/570 [05:51<14:54,  2.18s/it] 28%|██▊       | 160/570 [05:53<14:36,  2.14s/it] 28%|██▊       | 161/570 [05:55<14:23,  2.11s/it] 28%|██▊       | 162/570 [05:57<14:13,  2.09s/it] 29%|██▊       | 163/570 [05:59<14:06,  2.08s/it] 29%|██▉       | 164/570 [06:01<14:00,  2.07s/it] 29%|██▉       | 165/570 [06:03<13:55,  2.06s/it] 29%|██▉       | 166/570 [06:05<13:51,  2.06s/it] 29%|██▉       | 167/570 [06:07<14:16,  2.13s/it] 29%|██▉       | 168/570 [06:09<14:25,  2.15s/it] 30%|██▉       | 169/570 [06:12<14:33,  2.18s/it] 30%|██▉       | 170/570 [06:14<14:35,  2.19s/it] 30%|███       | 171/570 [06:15<13:09,  1.98s/it] 30%|███       | 172/570 [06:17<13:15,  2.00s/it] 30%|███       | 173/570 [06:19<13:19,  2.01s/it] 31%|███       | 174/570 [06:21<13:20,  2.02s/it] 31%|███       | 175/570 [06:24<13:26,  2.04s/it] 31%|███       | 176/570 [06:26<13:25,  2.04s/it] 31%|███       | 177/570 [06:28<13:23,  2.05s/it] 31%|███       | 178/570 [06:30<13:21,  2.05s/it] 31%|███▏      | 179/570 [06:32<13:26,  2.06s/it] 32%|███▏      | 180/570 [06:34<13:22,  2.06s/it] 32%|███▏      | 181/570 [06:36<13:17,  2.05s/it] 32%|███▏      | 182/570 [06:38<13:13,  2.05s/it] 32%|███▏      | 183/570 [06:40<13:16,  2.06s/it] 32%|███▏      | 184/570 [06:42<13:12,  2.05s/it] 32%|███▏      | 185/570 [06:44<13:08,  2.05s/it] 33%|███▎      | 186/570 [06:46<13:05,  2.05s/it] 33%|███▎      | 187/570 [06:48<13:09,  2.06s/it] 33%|███▎      | 188/570 [06:50<13:05,  2.06s/it] 33%|███▎      | 189/570 [06:52<13:01,  2.05s/it] 33%|███▎      | 190/570 [06:54<11:53,  1.88s/it] 34%|███▎      | 191/570 [06:56<12:11,  1.93s/it] 34%|███▎      | 192/570 [06:58<12:23,  1.97s/it] 34%|███▍      | 193/570 [07:00<12:33,  2.00s/it] 34%|███▍      | 194/570 [07:02<12:38,  2.02s/it] 34%|███▍      | 195/570 [07:04<12:41,  2.03s/it] 34%|███▍      | 196/570 [07:06<12:50,  2.06s/it] 35%|███▍      | 197/570 [07:08<12:56,  2.08s/it] 35%|███▍      | 198/570 [07:11<13:04,  2.11s/it] 35%|███▍      | 199/570 [07:13<13:10,  2.13s/it] 35%|███▌      | 200/570 [07:15<13:10,  2.14s/it]11/08/2022 14:12:37 - ***** Running Evaluation *****
11/08/2022 14:12:37 -   Num examples = 96
11/08/2022 14:12:37 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 7.89}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.97s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.97s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.93s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.94s/it]
                                                  35%|███▌      | 200/570 [07:21<13:10,  2.14s/it]Saving model checkpoint to models/role_gp/checkpoint-200
Configuration saved in models/role_gp/checkpoint-200/config.json
Model weights saved in models/role_gp/checkpoint-200/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-500] due to args.save_total_limit
 35%|███▌      | 201/570 [07:25<28:05,  4.57s/it] 35%|███▌      | 202/570 [07:27<23:22,  3.81s/it] 36%|███▌      | 203/570 [07:29<20:04,  3.28s/it] 36%|███▌      | 204/570 [07:31<17:46,  2.91s/it] 36%|███▌      | 205/570 [07:33<16:12,  2.66s/it] 36%|███▌      | 206/570 [07:35<15:03,  2.48s/it] 36%|███▋      | 207/570 [07:37<14:13,  2.35s/it] 36%|███▋      | 208/570 [07:40<13:43,  2.27s/it] 37%|███▋      | 209/570 [07:41<12:15,  2.04s/it] 37%|███▋      | 210/570 [07:43<12:13,  2.04s/it] 37%|███▋      | 211/570 [07:45<12:12,  2.04s/it] 37%|███▋      | 212/570 [07:47<12:16,  2.06s/it] 37%|███▋      | 213/570 [07:49<12:12,  2.05s/it] 38%|███▊      | 214/570 [07:51<12:09,  2.05s/it] 38%|███▊      | 215/570 [07:53<12:06,  2.05s/it] 38%|███▊      | 216/570 [07:55<12:09,  2.06s/it] 38%|███▊      | 217/570 [07:57<12:05,  2.05s/it] 38%|███▊      | 218/570 [07:59<12:01,  2.05s/it] 38%|███▊      | 219/570 [08:02<11:59,  2.05s/it] 39%|███▊      | 220/570 [08:04<12:02,  2.06s/it] 39%|███▉      | 221/570 [08:06<11:59,  2.06s/it] 39%|███▉      | 222/570 [08:08<11:54,  2.05s/it] 39%|███▉      | 223/570 [08:10<11:51,  2.05s/it] 39%|███▉      | 224/570 [08:12<11:53,  2.06s/it] 39%|███▉      | 225/570 [08:14<11:48,  2.05s/it] 40%|███▉      | 226/570 [08:16<11:44,  2.05s/it] 40%|███▉      | 227/570 [08:18<11:42,  2.05s/it] 40%|████      | 228/570 [08:19<10:43,  1.88s/it] 40%|████      | 229/570 [08:22<11:03,  1.95s/it] 40%|████      | 230/570 [08:24<11:12,  1.98s/it] 41%|████      | 231/570 [08:26<11:18,  2.00s/it] 41%|████      | 232/570 [08:28<11:22,  2.02s/it] 41%|████      | 233/570 [08:30<11:30,  2.05s/it] 41%|████      | 234/570 [08:32<11:29,  2.05s/it] 41%|████      | 235/570 [08:34<11:26,  2.05s/it] 41%|████▏     | 236/570 [08:36<11:24,  2.05s/it] 42%|████▏     | 237/570 [08:38<11:25,  2.06s/it] 42%|████▏     | 238/570 [08:40<11:21,  2.05s/it] 42%|████▏     | 239/570 [08:42<11:18,  2.05s/it] 42%|████▏     | 240/570 [08:44<11:15,  2.05s/it] 42%|████▏     | 241/570 [08:46<11:25,  2.08s/it] 42%|████▏     | 242/570 [08:49<11:34,  2.12s/it] 43%|████▎     | 243/570 [08:51<11:40,  2.14s/it] 43%|████▎     | 244/570 [08:53<11:47,  2.17s/it] 43%|████▎     | 245/570 [08:55<11:42,  2.16s/it] 43%|████▎     | 246/570 [08:57<11:30,  2.13s/it] 43%|████▎     | 247/570 [08:59<10:27,  1.94s/it] 44%|████▎     | 248/570 [09:01<10:35,  1.97s/it] 44%|████▎     | 249/570 [09:03<10:44,  2.01s/it] 44%|████▍     | 250/570 [09:05<10:45,  2.02s/it]11/08/2022 14:14:27 - ***** Running Evaluation *****
11/08/2022 14:14:27 -   Num examples = 96
11/08/2022 14:14:27 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 10.53}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.87s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
                                                  44%|████▍     | 250/570 [09:11<10:45,  2.02s/it]Saving model checkpoint to models/role_gp/checkpoint-250
Configuration saved in models/role_gp/checkpoint-250/config.json
Model weights saved in models/role_gp/checkpoint-250/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-550] due to args.save_total_limit
 44%|████▍     | 251/570 [09:15<23:32,  4.43s/it] 44%|████▍     | 252/570 [09:17<19:40,  3.71s/it] 44%|████▍     | 253/570 [09:19<17:01,  3.22s/it] 45%|████▍     | 254/570 [09:21<15:06,  2.87s/it] 45%|████▍     | 255/570 [09:23<13:45,  2.62s/it] 45%|████▍     | 256/570 [09:25<12:47,  2.45s/it] 45%|████▌     | 257/570 [09:27<12:10,  2.33s/it] 45%|████▌     | 258/570 [09:29<11:40,  2.25s/it] 45%|████▌     | 259/570 [09:31<11:18,  2.18s/it] 46%|████▌     | 260/570 [09:33<11:03,  2.14s/it] 46%|████▌     | 261/570 [09:35<10:52,  2.11s/it] 46%|████▌     | 262/570 [09:37<10:44,  2.09s/it] 46%|████▌     | 263/570 [09:40<10:38,  2.08s/it] 46%|████▋     | 264/570 [09:42<10:33,  2.07s/it] 46%|████▋     | 265/570 [09:44<10:30,  2.07s/it] 47%|████▋     | 266/570 [09:45<09:36,  1.90s/it] 47%|████▋     | 267/570 [09:47<09:48,  1.94s/it] 47%|████▋     | 268/570 [09:49<09:55,  1.97s/it] 47%|████▋     | 269/570 [09:51<10:00,  1.99s/it] 47%|████▋     | 270/570 [09:53<10:06,  2.02s/it] 48%|████▊     | 271/570 [09:55<10:05,  2.03s/it] 48%|████▊     | 272/570 [09:57<10:06,  2.03s/it] 48%|████▊     | 273/570 [09:59<10:04,  2.04s/it] 48%|████▊     | 274/570 [10:02<10:07,  2.05s/it] 48%|████▊     | 275/570 [10:04<10:03,  2.05s/it] 48%|████▊     | 276/570 [10:06<10:00,  2.04s/it] 49%|████▊     | 277/570 [10:08<09:59,  2.05s/it] 49%|████▉     | 278/570 [10:10<10:02,  2.06s/it] 49%|████▉     | 279/570 [10:12<09:58,  2.06s/it] 49%|████▉     | 280/570 [10:14<09:54,  2.05s/it] 49%|████▉     | 281/570 [10:16<09:51,  2.05s/it] 49%|████▉     | 282/570 [10:18<09:54,  2.06s/it] 50%|████▉     | 283/570 [10:20<09:50,  2.06s/it] 50%|████▉     | 284/570 [10:22<09:46,  2.05s/it] 50%|█████     | 285/570 [10:24<08:56,  1.88s/it] 50%|█████     | 286/570 [10:26<09:07,  1.93s/it] 50%|█████     | 287/570 [10:28<09:17,  1.97s/it] 51%|█████     | 288/570 [10:30<09:21,  1.99s/it] 51%|█████     | 289/570 [10:32<09:23,  2.00s/it] 51%|█████     | 290/570 [10:34<09:23,  2.01s/it] 51%|█████     | 291/570 [10:36<09:27,  2.03s/it] 51%|█████     | 292/570 [10:38<09:25,  2.03s/it] 51%|█████▏    | 293/570 [10:40<09:23,  2.03s/it] 52%|█████▏    | 294/570 [10:42<09:21,  2.03s/it] 52%|█████▏    | 295/570 [10:44<09:23,  2.05s/it] 52%|█████▏    | 296/570 [10:46<09:21,  2.05s/it] 52%|█████▏    | 297/570 [10:48<09:18,  2.04s/it] 52%|█████▏    | 298/570 [10:50<09:16,  2.05s/it] 52%|█████▏    | 299/570 [10:52<09:18,  2.06s/it] 53%|█████▎    | 300/570 [10:54<09:14,  2.05s/it]11/08/2022 14:16:17 - ***** Running Evaluation *****
11/08/2022 14:16:17 -   Num examples = 96
11/08/2022 14:16:17 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 13.16}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.88s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
                                                  53%|█████▎    | 300/570 [11:01<09:14,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-300
Configuration saved in models/role_gp/checkpoint-300/config.json
Model weights saved in models/role_gp/checkpoint-300/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-50] due to args.save_total_limit
 53%|█████▎    | 301/570 [11:04<20:02,  4.47s/it] 53%|█████▎    | 302/570 [11:06<16:43,  3.74s/it] 53%|█████▎    | 303/570 [11:09<14:26,  3.25s/it] 53%|█████▎    | 304/570 [11:10<12:03,  2.72s/it] 54%|█████▎    | 305/570 [11:12<11:07,  2.52s/it] 54%|█████▎    | 306/570 [11:14<10:27,  2.38s/it] 54%|█████▍    | 307/570 [11:16<09:58,  2.28s/it] 54%|█████▍    | 308/570 [11:18<09:38,  2.21s/it] 54%|█████▍    | 309/570 [11:20<09:22,  2.16s/it] 54%|█████▍    | 310/570 [11:22<09:11,  2.12s/it] 55%|█████▍    | 311/570 [11:24<09:04,  2.10s/it] 55%|█████▍    | 312/570 [11:26<09:02,  2.10s/it] 55%|█████▍    | 313/570 [11:29<08:56,  2.09s/it] 55%|█████▌    | 314/570 [11:31<08:51,  2.08s/it] 55%|█████▌    | 315/570 [11:33<08:47,  2.07s/it] 55%|█████▌    | 316/570 [11:35<08:48,  2.08s/it] 56%|█████▌    | 317/570 [11:37<08:43,  2.07s/it] 56%|█████▌    | 318/570 [11:39<08:39,  2.06s/it] 56%|█████▌    | 319/570 [11:41<08:36,  2.06s/it] 56%|█████▌    | 320/570 [11:43<08:37,  2.07s/it] 56%|█████▋    | 321/570 [11:45<08:33,  2.06s/it] 56%|█████▋    | 322/570 [11:47<08:30,  2.06s/it] 57%|█████▋    | 323/570 [11:49<07:46,  1.89s/it] 57%|█████▋    | 324/570 [11:51<07:59,  1.95s/it] 57%|█████▋    | 325/570 [11:53<08:04,  1.98s/it] 57%|█████▋    | 326/570 [11:55<08:08,  2.00s/it] 57%|█████▋    | 327/570 [11:57<08:09,  2.01s/it] 58%|█████▊    | 328/570 [11:59<08:12,  2.04s/it] 58%|█████▊    | 329/570 [12:01<08:11,  2.04s/it] 58%|█████▊    | 330/570 [12:03<08:10,  2.04s/it] 58%|█████▊    | 331/570 [12:05<08:08,  2.04s/it] 58%|█████▊    | 332/570 [12:07<08:10,  2.06s/it] 58%|█████▊    | 333/570 [12:09<08:05,  2.05s/it] 59%|█████▊    | 334/570 [12:11<08:02,  2.05s/it] 59%|█████▉    | 335/570 [12:13<08:00,  2.04s/it] 59%|█████▉    | 336/570 [12:15<07:57,  2.04s/it] 59%|█████▉    | 337/570 [12:17<07:54,  2.04s/it] 59%|█████▉    | 338/570 [12:19<07:52,  2.04s/it] 59%|█████▉    | 339/570 [12:21<07:49,  2.03s/it] 60%|█████▉    | 340/570 [12:23<07:47,  2.03s/it] 60%|█████▉    | 341/570 [12:25<07:46,  2.04s/it] 60%|██████    | 342/570 [12:27<07:06,  1.87s/it] 60%|██████    | 343/570 [12:29<07:16,  1.92s/it] 60%|██████    | 344/570 [12:31<07:22,  1.96s/it] 61%|██████    | 345/570 [12:33<07:30,  2.00s/it] 61%|██████    | 346/570 [12:35<07:31,  2.02s/it] 61%|██████    | 347/570 [12:37<07:32,  2.03s/it] 61%|██████    | 348/570 [12:39<07:32,  2.04s/it] 61%|██████    | 349/570 [12:41<07:34,  2.06s/it] 61%|██████▏   | 350/570 [12:43<07:32,  2.06s/it]11/08/2022 14:18:06 - ***** Running Evaluation *****
11/08/2022 14:18:06 -   Num examples = 96
11/08/2022 14:18:06 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 15.79}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.88s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
                                                  61%|██████▏   | 350/570 [12:50<07:32,  2.06s/it]Saving model checkpoint to models/role_gp/checkpoint-350
Configuration saved in models/role_gp/checkpoint-350/config.json
Model weights saved in models/role_gp/checkpoint-350/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-100] due to args.save_total_limit
 62%|██████▏   | 351/570 [12:54<16:22,  4.48s/it] 62%|██████▏   | 352/570 [12:56<13:38,  3.75s/it] 62%|██████▏   | 353/570 [12:58<11:46,  3.26s/it] 62%|██████▏   | 354/570 [13:00<10:24,  2.89s/it] 62%|██████▏   | 355/570 [13:02<09:26,  2.64s/it] 62%|██████▏   | 356/570 [13:04<08:45,  2.46s/it] 63%|██████▎   | 357/570 [13:06<08:19,  2.34s/it] 63%|██████▎   | 358/570 [13:08<07:57,  2.25s/it] 63%|██████▎   | 359/570 [13:10<07:41,  2.19s/it] 63%|██████▎   | 360/570 [13:12<07:29,  2.14s/it] 63%|██████▎   | 361/570 [13:14<06:46,  1.94s/it] 64%|██████▎   | 362/570 [13:16<06:53,  1.99s/it] 64%|██████▎   | 363/570 [13:18<06:54,  2.00s/it] 64%|██████▍   | 364/570 [13:20<06:54,  2.01s/it] 64%|██████▍   | 365/570 [13:22<06:54,  2.02s/it] 64%|██████▍   | 366/570 [13:24<06:56,  2.04s/it] 64%|██████▍   | 367/570 [13:26<06:54,  2.04s/it] 65%|██████▍   | 368/570 [13:28<06:52,  2.04s/it] 65%|██████▍   | 369/570 [13:30<06:49,  2.04s/it] 65%|██████▍   | 370/570 [13:32<06:50,  2.05s/it] 65%|██████▌   | 371/570 [13:34<06:46,  2.04s/it] 65%|██████▌   | 372/570 [13:36<06:44,  2.04s/it] 65%|██████▌   | 373/570 [13:38<06:41,  2.04s/it] 66%|██████▌   | 374/570 [13:40<06:41,  2.05s/it] 66%|██████▌   | 375/570 [13:42<06:38,  2.04s/it] 66%|██████▌   | 376/570 [13:44<06:36,  2.04s/it] 66%|██████▌   | 377/570 [13:46<06:33,  2.04s/it] 66%|██████▋   | 378/570 [13:48<06:34,  2.05s/it] 66%|██████▋   | 379/570 [13:50<06:30,  2.05s/it] 67%|██████▋   | 380/570 [13:52<05:56,  1.88s/it] 67%|██████▋   | 381/570 [13:54<06:03,  1.93s/it] 67%|██████▋   | 382/570 [13:56<06:08,  1.96s/it] 67%|██████▋   | 383/570 [13:58<06:11,  1.98s/it] 67%|██████▋   | 384/570 [14:00<06:12,  2.00s/it] 68%|██████▊   | 385/570 [14:02<06:12,  2.01s/it] 68%|██████▊   | 386/570 [14:04<06:11,  2.02s/it] 68%|██████▊   | 387/570 [14:06<06:14,  2.04s/it] 68%|██████▊   | 388/570 [14:08<06:11,  2.04s/it] 68%|██████▊   | 389/570 [14:10<06:11,  2.05s/it] 68%|██████▊   | 390/570 [14:12<06:08,  2.05s/it] 69%|██████▊   | 391/570 [14:14<06:09,  2.06s/it] 69%|██████▉   | 392/570 [14:17<06:06,  2.06s/it] 69%|██████▉   | 393/570 [14:19<06:07,  2.07s/it] 69%|██████▉   | 394/570 [14:21<06:03,  2.07s/it] 69%|██████▉   | 395/570 [14:23<06:02,  2.07s/it] 69%|██████▉   | 396/570 [14:25<05:59,  2.06s/it] 70%|██████▉   | 397/570 [14:27<05:56,  2.06s/it] 70%|██████▉   | 398/570 [14:29<05:53,  2.06s/it] 70%|███████   | 399/570 [14:30<05:24,  1.90s/it] 70%|███████   | 400/570 [14:33<05:30,  1.95s/it]11/08/2022 14:19:55 - ***** Running Evaluation *****
11/08/2022 14:19:55 -   Num examples = 96
11/08/2022 14:19:55 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 18.42}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.87s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.86s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]
                                                  70%|███████   | 400/570 [14:39<05:30,  1.95s/it]Saving model checkpoint to models/role_gp/checkpoint-400
Configuration saved in models/role_gp/checkpoint-400/config.json
Model weights saved in models/role_gp/checkpoint-400/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-150] due to args.save_total_limit
 70%|███████   | 401/570 [14:43<12:22,  4.39s/it] 71%|███████   | 402/570 [14:45<10:20,  3.70s/it] 71%|███████   | 403/570 [14:47<08:57,  3.22s/it] 71%|███████   | 404/570 [14:49<07:56,  2.87s/it] 71%|███████   | 405/570 [14:51<07:13,  2.63s/it] 71%|███████   | 406/570 [14:53<06:42,  2.45s/it] 71%|███████▏  | 407/570 [14:55<06:20,  2.33s/it] 72%|███████▏  | 408/570 [14:57<06:04,  2.25s/it] 72%|███████▏  | 409/570 [14:59<05:52,  2.19s/it] 72%|███████▏  | 410/570 [15:01<05:43,  2.15s/it] 72%|███████▏  | 411/570 [15:03<05:36,  2.12s/it] 72%|███████▏  | 412/570 [15:05<05:30,  2.09s/it] 72%|███████▏  | 413/570 [15:07<05:25,  2.07s/it] 73%|███████▎  | 414/570 [15:09<05:22,  2.06s/it] 73%|███████▎  | 415/570 [15:11<05:18,  2.06s/it] 73%|███████▎  | 416/570 [15:13<05:17,  2.06s/it] 73%|███████▎  | 417/570 [15:15<05:14,  2.05s/it] 73%|███████▎  | 418/570 [15:17<04:45,  1.88s/it] 74%|███████▎  | 419/570 [15:19<04:51,  1.93s/it] 74%|███████▎  | 420/570 [15:21<04:57,  1.98s/it] 74%|███████▍  | 421/570 [15:23<04:58,  2.00s/it] 74%|███████▍  | 422/570 [15:25<04:58,  2.01s/it] 74%|███████▍  | 423/570 [15:27<04:57,  2.02s/it] 74%|███████▍  | 424/570 [15:29<04:58,  2.05s/it] 75%|███████▍  | 425/570 [15:31<04:56,  2.05s/it] 75%|███████▍  | 426/570 [15:33<04:55,  2.05s/it] 75%|███████▍  | 427/570 [15:35<04:53,  2.05s/it] 75%|███████▌  | 428/570 [15:38<04:53,  2.07s/it] 75%|███████▌  | 429/570 [15:40<04:50,  2.06s/it] 75%|███████▌  | 430/570 [15:42<04:47,  2.05s/it] 76%|███████▌  | 431/570 [15:44<04:44,  2.05s/it] 76%|███████▌  | 432/570 [15:46<04:44,  2.06s/it] 76%|███████▌  | 433/570 [15:48<04:41,  2.06s/it] 76%|███████▌  | 434/570 [15:50<04:39,  2.05s/it] 76%|███████▋  | 435/570 [15:52<04:36,  2.05s/it] 76%|███████▋  | 436/570 [15:54<04:36,  2.06s/it] 77%|███████▋  | 437/570 [15:55<04:10,  1.88s/it] 77%|███████▋  | 438/570 [15:58<04:15,  1.93s/it] 77%|███████▋  | 439/570 [16:00<04:17,  1.97s/it] 77%|███████▋  | 440/570 [16:02<04:19,  1.99s/it] 77%|███████▋  | 441/570 [16:04<04:21,  2.02s/it] 78%|███████▊  | 442/570 [16:06<04:20,  2.03s/it] 78%|███████▊  | 443/570 [16:08<04:18,  2.04s/it] 78%|███████▊  | 444/570 [16:10<04:17,  2.04s/it] 78%|███████▊  | 445/570 [16:12<04:17,  2.06s/it] 78%|███████▊  | 446/570 [16:14<04:15,  2.06s/it] 78%|███████▊  | 447/570 [16:16<04:13,  2.06s/it] 79%|███████▊  | 448/570 [16:18<04:11,  2.06s/it] 79%|███████▉  | 449/570 [16:20<04:10,  2.07s/it] 79%|███████▉  | 450/570 [16:22<04:07,  2.07s/it]11/08/2022 14:21:45 - ***** Running Evaluation *****
11/08/2022 14:21:45 -   Num examples = 96
11/08/2022 14:21:45 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 21.05}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.87s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
                                                  79%|███████▉  | 450/570 [16:28<04:07,  2.07s/it]Saving model checkpoint to models/role_gp/checkpoint-450
Configuration saved in models/role_gp/checkpoint-450/config.json
Model weights saved in models/role_gp/checkpoint-450/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-200] due to args.save_total_limit
 79%|███████▉  | 451/570 [16:32<08:51,  4.46s/it] 79%|███████▉  | 452/570 [16:34<07:21,  3.74s/it] 79%|███████▉  | 453/570 [16:37<06:20,  3.25s/it] 80%|███████▉  | 454/570 [16:39<05:35,  2.89s/it] 80%|███████▉  | 455/570 [16:41<05:03,  2.64s/it] 80%|████████  | 456/570 [16:42<04:20,  2.29s/it] 80%|████████  | 457/570 [16:44<04:10,  2.21s/it] 80%|████████  | 458/570 [16:46<04:02,  2.16s/it] 81%|████████  | 459/570 [16:48<03:56,  2.13s/it] 81%|████████  | 460/570 [16:50<03:51,  2.10s/it] 81%|████████  | 461/570 [16:52<03:47,  2.09s/it] 81%|████████  | 462/570 [16:54<03:44,  2.08s/it] 81%|████████  | 463/570 [16:56<03:41,  2.07s/it] 81%|████████▏ | 464/570 [16:58<03:39,  2.07s/it] 82%|████████▏ | 465/570 [17:01<03:36,  2.06s/it] 82%|████████▏ | 466/570 [17:03<03:35,  2.07s/it] 82%|████████▏ | 467/570 [17:05<03:33,  2.08s/it] 82%|████████▏ | 468/570 [17:07<03:31,  2.07s/it] 82%|████████▏ | 469/570 [17:09<03:28,  2.07s/it] 82%|████████▏ | 470/570 [17:11<03:28,  2.08s/it] 83%|████████▎ | 471/570 [17:13<03:25,  2.07s/it] 83%|████████▎ | 472/570 [17:15<03:22,  2.07s/it] 83%|████████▎ | 473/570 [17:17<03:20,  2.06s/it] 83%|████████▎ | 474/570 [17:19<03:19,  2.08s/it] 83%|████████▎ | 475/570 [17:21<03:00,  1.90s/it] 84%|████████▎ | 476/570 [17:23<03:03,  1.95s/it] 84%|████████▎ | 477/570 [17:25<03:04,  1.98s/it] 84%|████████▍ | 478/570 [17:27<03:06,  2.02s/it] 84%|████████▍ | 479/570 [17:29<03:05,  2.03s/it] 84%|████████▍ | 480/570 [17:31<03:03,  2.04s/it] 84%|████████▍ | 481/570 [17:33<03:01,  2.04s/it] 85%|████████▍ | 482/570 [17:35<03:01,  2.06s/it] 85%|████████▍ | 483/570 [17:37<02:59,  2.06s/it] 85%|████████▍ | 484/570 [17:39<02:56,  2.05s/it] 85%|████████▌ | 485/570 [17:41<02:54,  2.05s/it] 85%|████████▌ | 486/570 [17:43<02:54,  2.07s/it] 85%|████████▌ | 487/570 [17:46<02:51,  2.06s/it] 86%|████████▌ | 488/570 [17:48<02:48,  2.06s/it] 86%|████████▌ | 489/570 [17:50<02:46,  2.05s/it] 86%|████████▌ | 490/570 [17:52<02:45,  2.07s/it] 86%|████████▌ | 491/570 [17:54<02:42,  2.06s/it] 86%|████████▋ | 492/570 [17:56<02:40,  2.06s/it] 86%|████████▋ | 493/570 [17:58<02:38,  2.06s/it] 87%|████████▋ | 494/570 [17:59<02:23,  1.88s/it] 87%|████████▋ | 495/570 [18:01<02:26,  1.96s/it] 87%|████████▋ | 496/570 [18:04<02:28,  2.00s/it] 87%|████████▋ | 497/570 [18:06<02:28,  2.04s/it] 87%|████████▋ | 498/570 [18:08<02:28,  2.06s/it] 88%|████████▊ | 499/570 [18:10<02:28,  2.10s/it] 88%|████████▊ | 500/570 [18:12<02:27,  2.10s/it]                                                  88%|████████▊ | 500/570 [18:12<02:27,  2.10s/it]11/08/2022 14:23:35 - ***** Running Evaluation *****
11/08/2022 14:23:35 -   Num examples = 96
11/08/2022 14:23:35 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 23.68}
{'loss': 0.0213, 'learning_rate': 0.0, 'epoch': 26.32}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.87s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.86s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]
                                                  88%|████████▊ | 500/570 [18:18<02:27,  2.10s/it]Saving model checkpoint to models/role_gp/checkpoint-500
Configuration saved in models/role_gp/checkpoint-500/config.json
Model weights saved in models/role_gp/checkpoint-500/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-250] due to args.save_total_limit
 88%|████████▊ | 501/570 [18:22<05:08,  4.48s/it] 88%|████████▊ | 502/570 [18:24<04:14,  3.75s/it] 88%|████████▊ | 503/570 [18:26<03:37,  3.25s/it] 88%|████████▊ | 504/570 [18:28<03:10,  2.89s/it] 89%|████████▊ | 505/570 [18:30<02:51,  2.63s/it] 89%|████████▉ | 506/570 [18:32<02:37,  2.46s/it] 89%|████████▉ | 507/570 [18:35<02:28,  2.35s/it] 89%|████████▉ | 508/570 [18:37<02:20,  2.26s/it] 89%|████████▉ | 509/570 [18:39<02:14,  2.20s/it] 89%|████████▉ | 510/570 [18:41<02:09,  2.16s/it] 90%|████████▉ | 511/570 [18:43<02:06,  2.14s/it] 90%|████████▉ | 512/570 [18:45<02:02,  2.11s/it] 90%|█████████ | 513/570 [18:46<01:49,  1.92s/it] 90%|█████████ | 514/570 [18:48<01:49,  1.96s/it] 90%|█████████ | 515/570 [18:50<01:49,  2.00s/it] 91%|█████████ | 516/570 [18:52<01:48,  2.01s/it] 91%|█████████ | 517/570 [18:55<01:47,  2.02s/it] 91%|█████████ | 518/570 [18:57<01:45,  2.03s/it] 91%|█████████ | 519/570 [18:59<01:43,  2.03s/it] 91%|█████████ | 520/570 [19:01<01:41,  2.04s/it] 91%|█████████▏| 521/570 [19:03<01:39,  2.04s/it] 92%|█████████▏| 522/570 [19:05<01:37,  2.04s/it] 92%|█████████▏| 523/570 [19:07<01:35,  2.04s/it] 92%|█████████▏| 524/570 [19:09<01:34,  2.05s/it] 92%|█████████▏| 525/570 [19:11<01:32,  2.05s/it] 92%|█████████▏| 526/570 [19:13<01:30,  2.05s/it] 92%|█████████▏| 527/570 [19:15<01:28,  2.05s/it] 93%|█████████▎| 528/570 [19:17<01:26,  2.06s/it] 93%|█████████▎| 529/570 [19:19<01:24,  2.06s/it] 93%|█████████▎| 530/570 [19:21<01:21,  2.05s/it] 93%|█████████▎| 531/570 [19:23<01:19,  2.05s/it] 93%|█████████▎| 532/570 [19:25<01:12,  1.90s/it] 94%|█████████▎| 533/570 [19:27<01:11,  1.94s/it] 94%|█████████▎| 534/570 [19:29<01:10,  1.97s/it] 94%|█████████▍| 535/570 [19:31<01:09,  1.99s/it] 94%|█████████▍| 536/570 [19:33<01:08,  2.02s/it] 94%|█████████▍| 537/570 [19:35<01:06,  2.03s/it] 94%|█████████▍| 538/570 [19:37<01:05,  2.03s/it] 95%|█████████▍| 539/570 [19:39<01:03,  2.04s/it] 95%|█████████▍| 540/570 [19:41<01:01,  2.05s/it] 95%|█████████▍| 541/570 [19:43<00:59,  2.05s/it] 95%|█████████▌| 542/570 [19:45<00:57,  2.05s/it] 95%|█████████▌| 543/570 [19:47<00:55,  2.04s/it] 95%|█████████▌| 544/570 [19:49<00:53,  2.06s/it] 96%|█████████▌| 545/570 [19:51<00:51,  2.06s/it] 96%|█████████▌| 546/570 [19:53<00:49,  2.05s/it] 96%|█████████▌| 547/570 [19:56<00:47,  2.05s/it] 96%|█████████▌| 548/570 [19:58<00:45,  2.05s/it] 96%|█████████▋| 549/570 [20:00<00:43,  2.05s/it] 96%|█████████▋| 550/570 [20:02<00:40,  2.05s/it]11/08/2022 14:25:24 - ***** Running Evaluation *****
11/08/2022 14:25:24 -   Num examples = 96
11/08/2022 14:25:24 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 26.32}

Evaluation:   0%|          | 0/3 [00:00<?, ?it/s][A
Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.86s/it][A
Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.86s/it][A
Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it][AEvaluation: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]
                                                  96%|█████████▋| 550/570 [20:08<00:40,  2.05s/it]Saving model checkpoint to models/role_gp/checkpoint-550
Configuration saved in models/role_gp/checkpoint-550/config.json
Model weights saved in models/role_gp/checkpoint-550/pytorch_model.bin
Deleting older checkpoint [models/role_gp/checkpoint-300] due to args.save_total_limit
 97%|█████████▋| 551/570 [20:11<01:20,  4.26s/it] 97%|█████████▋| 552/570 [20:13<01:04,  3.59s/it] 97%|█████████▋| 553/570 [20:15<00:53,  3.14s/it] 97%|█████████▋| 554/570 [20:17<00:44,  2.81s/it] 97%|█████████▋| 555/570 [20:19<00:38,  2.58s/it] 98%|█████████▊| 556/570 [20:21<00:33,  2.42s/it] 98%|█████████▊| 557/570 [20:23<00:30,  2.31s/it] 98%|█████████▊| 558/570 [20:25<00:26,  2.23s/it] 98%|█████████▊| 559/570 [20:27<00:23,  2.18s/it] 98%|█████████▊| 560/570 [20:30<00:21,  2.14s/it] 98%|█████████▊| 561/570 [20:32<00:19,  2.12s/it] 99%|█████████▊| 562/570 [20:34<00:16,  2.09s/it] 99%|█████████▉| 563/570 [20:36<00:14,  2.08s/it] 99%|█████████▉| 564/570 [20:38<00:12,  2.07s/it] 99%|█████████▉| 565/570 [20:40<00:10,  2.07s/it] 99%|█████████▉| 566/570 [20:42<00:08,  2.08s/it] 99%|█████████▉| 567/570 [20:44<00:06,  2.07s/it]100%|█████████▉| 568/570 [20:46<00:04,  2.06s/it]100%|█████████▉| 569/570 [20:48<00:02,  2.06s/it]100%|██████████| 570/570 [20:50<00:00,  1.89s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 570/570 [20:50<00:00,  1.89s/it]100%|██████████| 570/570 [20:50<00:00,  2.19s/it]
Saving model checkpoint to models/role_gp/best
Configuration saved in models/role_gp/best/config.json
Model weights saved in models/role_gp/best/pytorch_model.bin
11/08/2022 14:26:13 - *** Evaluate ***
11/08/2022 14:26:13 - ***** Running Evaluation *****
11/08/2022 14:26:13 -   Num examples = 96
11/08/2022 14:26:13 -   Batch size = 32
{'eval_loss': 1.879099448521932, 'eval_precision': 0.6493506493506493, 'eval_recall': 0.6410256410256411, 'eval_f1': 0.6451612903225806, 'epoch': 28.95}
{'train_runtime': 1250.0367, 'train_samples_per_second': 14.376, 'train_steps_per_second': 0.456, 'train_loss': 0.021391594200803523, 'epoch': 30.0}
***** train metrics *****
  epoch                    =       30.0
  train_loss               =     0.0214
  train_runtime            = 0:20:50.03
  train_samples_per_second =     14.376
  train_steps_per_second   =      0.456
Evaluation:   0%|          | 0/3 [00:00<?, ?it/s]Evaluation:  33%|███▎      | 1/3 [00:01<00:03,  1.86s/it]Evaluation:  67%|██████▋   | 2/3 [00:03<00:01,  1.86s/it]Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]Evaluation: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]
11/08/2022 14:26:19 - ***** Eval results *****
11/08/2022 14:26:19 -   eval_loss = 1.879099448521932
11/08/2022 14:26:19 -   eval_precision = 0.6493506493506493
11/08/2022 14:26:19 -   eval_recall = 0.6410256410256411
11/08/2022 14:26:19 -   eval_f1 = 0.6451612903225806
11/08/2022 14:26:19 -   epoch = 30.0
0it [00:00, ?it/s]2460it [00:00, 379952.42it/s]
11/08/2022 14:26:19 - Creating features from dataset file at tests/data/role/test.txt
11/08/2022 14:26:19 - Writing example 0 of 111
11/08/2022 14:26:19 - *** Example ***
11/08/2022 14:26:19 - guid: 1 (length: 57)
11/08/2022 14:26:19 - tokens: [CLS] Re ##action of dip ##hen ##yla ##ce ##ty with complex 19 ##A led to only [Prod] c ##y ##c ##lo ##he [/Prod] 23 ##A in 30 % yield ; with ( p ##hen ##yl ##cy car ##ben ##e complex 19 ##B , c ##y ##c ##lo ##he 25 was produced in 53 % yield . [SEP]
11/08/2022 14:26:19 - input_ids: 101 11336 15022 1104 20866 10436 22948 2093 2340 1114 2703 1627 1592 1521 1106 1178 28996 172 1183 1665 2858 4638 28997 1695 1592 1107 1476 110 10972 132 1114 113 185 10436 7777 3457 1610 9672 1162 2703 1627 2064 117 172 1183 1665 2858 4638 1512 1108 1666 1107 4389 110 10972 119 102
11/08/2022 14:26:19 - label_ids: -100 0 -100 0 1 -100 -100 -100 -100 0 0 1 -100 0 0 0 -100 -100 -100 -100 -100 -100 -100 0 -100 0 11 12 0 0 0 0 -100 -100 -100 -100 0 -100 -100 0 0 -100 0 0 -100 -100 -100 -100 0 0 0 0 0 0 0 -100 -100
11/08/2022 14:26:19 - label_matrix: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
11/08/2022 14:26:19 - decoder_mask: False True False True True False False False False True True True False True True True False False False False False False False True False True True True True True True True False False False False True False False True True False True True False False False False True True True True True True True False False
11/08/2022 14:26:19 - Saving features into cached file tests/data/role/cached_test.txt_BertTokenizerFast_256
11/08/2022 14:26:22 - ***** Running Prediction *****
11/08/2022 14:26:22 -   Num examples = 111
11/08/2022 14:26:22 -   Batch size = 32
Prediction:   0%|          | 0/4 [00:00<?, ?it/s]Prediction:  25%|██▌       | 1/4 [00:01<00:05,  1.85s/it]Prediction:  50%|█████     | 2/4 [00:03<00:03,  1.85s/it]Prediction:  75%|███████▌  | 3/4 [00:05<00:01,  1.86s/it]Prediction: 100%|██████████| 4/4 [00:06<00:00,  1.47s/it]Prediction: 100%|██████████| 4/4 [00:06<00:00,  1.61s/it]
11/08/2022 14:26:29 -   eval_loss = 1.5720282047986984
11/08/2022 14:26:29 -   eval_precision = 0.7097791798107256
11/08/2022 14:26:29 -   eval_recall = 0.6923076923076923
11/08/2022 14:26:29 -   eval_f1 = 0.7009345794392523
0it [00:00, ?it/s]2396it [00:00, 382141.32it/s]
